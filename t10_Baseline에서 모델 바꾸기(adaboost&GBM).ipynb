{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0c732c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings; warnings.filterwarnings(action='ignore')\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "c407cb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed) #파이썬 자체 모듈 random 모듈의 시드 고정\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) \n",
    "    np.random.seed(seed) #넘파이를 사용할 경우\n",
    "\n",
    "seed_everything(37) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33209ff9",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "864c76d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터프레임 불러오기\n",
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')\n",
    "sub4 = pd.read_csv('./sample_submission.csv')\n",
    "sub5 = pd.read_csv('./sample_submission.csv')\n",
    "sub6 = pd.read_csv('./sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8c203758",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission5 = pd.read_csv('./sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "defc1d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission6 = pd.read_csv('./sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7c0bf518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>Y_Class</th>\n",
       "      <th>Y_Quality</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>LINE</th>\n",
       "      <th>PRODUCT_CODE</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>...</th>\n",
       "      <th>X_2866</th>\n",
       "      <th>X_2867</th>\n",
       "      <th>X_2868</th>\n",
       "      <th>X_2869</th>\n",
       "      <th>X_2870</th>\n",
       "      <th>X_2871</th>\n",
       "      <th>X_2872</th>\n",
       "      <th>X_2873</th>\n",
       "      <th>X_2874</th>\n",
       "      <th>X_2875</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533433</td>\n",
       "      <td>2022-06-13 5:14</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>39.34</td>\n",
       "      <td>40.89</td>\n",
       "      <td>32.56</td>\n",
       "      <td>34.09</td>\n",
       "      <td>77.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.541819</td>\n",
       "      <td>2022-06-13 5:22</td>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38.89</td>\n",
       "      <td>42.82</td>\n",
       "      <td>43.92</td>\n",
       "      <td>35.34</td>\n",
       "      <td>72.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531267</td>\n",
       "      <td>2022-06-13 5:30</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>39.19</td>\n",
       "      <td>36.65</td>\n",
       "      <td>42.47</td>\n",
       "      <td>36.53</td>\n",
       "      <td>78.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_003</td>\n",
       "      <td>2</td>\n",
       "      <td>0.537325</td>\n",
       "      <td>2022-06-13 5:39</td>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>37.74</td>\n",
       "      <td>39.17</td>\n",
       "      <td>52.17</td>\n",
       "      <td>30.58</td>\n",
       "      <td>71.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_004</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531590</td>\n",
       "      <td>2022-06-13 5:47</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38.70</td>\n",
       "      <td>41.89</td>\n",
       "      <td>46.93</td>\n",
       "      <td>33.09</td>\n",
       "      <td>76.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>TRAIN_593</td>\n",
       "      <td>1</td>\n",
       "      <td>0.526546</td>\n",
       "      <td>2022-09-08 14:30</td>\n",
       "      <td>T100306</td>\n",
       "      <td>T_31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>TRAIN_594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524022</td>\n",
       "      <td>2022-09-08 22:38</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>49.47</td>\n",
       "      <td>53.07</td>\n",
       "      <td>50.89</td>\n",
       "      <td>55.10</td>\n",
       "      <td>66.49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>TRAIN_595</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521289</td>\n",
       "      <td>2022-09-08 22:47</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>TRAIN_596</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531375</td>\n",
       "      <td>2022-09-08 14:38</td>\n",
       "      <td>T100304</td>\n",
       "      <td>O_31</td>\n",
       "      <td>40.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>TRAIN_597</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533702</td>\n",
       "      <td>2022-09-08 14:46</td>\n",
       "      <td>T100306</td>\n",
       "      <td>O_31</td>\n",
       "      <td>21.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>598 rows × 2881 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PRODUCT_ID  Y_Class  Y_Quality         TIMESTAMP     LINE PRODUCT_CODE  \\\n",
       "0    TRAIN_000        1   0.533433   2022-06-13 5:14  T050304         A_31   \n",
       "1    TRAIN_001        2   0.541819   2022-06-13 5:22  T050307         A_31   \n",
       "2    TRAIN_002        1   0.531267   2022-06-13 5:30  T050304         A_31   \n",
       "3    TRAIN_003        2   0.537325   2022-06-13 5:39  T050307         A_31   \n",
       "4    TRAIN_004        1   0.531590   2022-06-13 5:47  T050304         A_31   \n",
       "..         ...      ...        ...               ...      ...          ...   \n",
       "593  TRAIN_593        1   0.526546  2022-09-08 14:30  T100306         T_31   \n",
       "594  TRAIN_594        0   0.524022  2022-09-08 22:38  T050304         A_31   \n",
       "595  TRAIN_595        0   0.521289  2022-09-08 22:47  T050304         A_31   \n",
       "596  TRAIN_596        1   0.531375  2022-09-08 14:38  T100304         O_31   \n",
       "597  TRAIN_597        1   0.533702  2022-09-08 14:46  T100306         O_31   \n",
       "\n",
       "      X_1   X_2  X_3   X_4  ...  X_2866  X_2867  X_2868  X_2869  X_2870  \\\n",
       "0     NaN   NaN  NaN   NaN  ...   39.34   40.89   32.56   34.09   77.77   \n",
       "1     NaN   NaN  NaN   NaN  ...   38.89   42.82   43.92   35.34   72.55   \n",
       "2     NaN   NaN  NaN   NaN  ...   39.19   36.65   42.47   36.53   78.35   \n",
       "3     NaN   NaN  NaN   NaN  ...   37.74   39.17   52.17   30.58   71.78   \n",
       "4     NaN   NaN  NaN   NaN  ...   38.70   41.89   46.93   33.09   76.97   \n",
       "..    ...   ...  ...   ...  ...     ...     ...     ...     ...     ...   \n",
       "593   2.0  95.0  0.0  45.0  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "594   NaN   NaN  NaN   NaN  ...   49.47   53.07   50.89   55.10   66.49   \n",
       "595   NaN   NaN  NaN   NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "596  40.0  94.0  0.0  45.0  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "597  21.0  87.0  0.0  45.0  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "     X_2871  X_2872  X_2873  X_2874  X_2875  \n",
       "0       NaN     NaN     NaN     NaN     NaN  \n",
       "1       NaN     NaN     NaN     NaN     NaN  \n",
       "2       NaN     NaN     NaN     NaN     NaN  \n",
       "3       NaN     NaN     NaN     NaN     NaN  \n",
       "4       NaN     NaN     NaN     NaN     NaN  \n",
       "..      ...     ...     ...     ...     ...  \n",
       "593     NaN     NaN     NaN     NaN     NaN  \n",
       "594     1.0     NaN     NaN     NaN     NaN  \n",
       "595     1.0     NaN     NaN     NaN     NaN  \n",
       "596     NaN     NaN     NaN     NaN     NaN  \n",
       "597     NaN     NaN     NaN     NaN     NaN  \n",
       "\n",
       "[598 rows x 2881 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "dbb736f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>Y_Class</th>\n",
       "      <th>Y_Quality</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>LINE</th>\n",
       "      <th>PRODUCT_CODE</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>...</th>\n",
       "      <th>X_2866</th>\n",
       "      <th>X_2867</th>\n",
       "      <th>X_2868</th>\n",
       "      <th>X_2869</th>\n",
       "      <th>X_2870</th>\n",
       "      <th>X_2871</th>\n",
       "      <th>X_2872</th>\n",
       "      <th>X_2873</th>\n",
       "      <th>X_2874</th>\n",
       "      <th>X_2875</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533433</td>\n",
       "      <td>2022-06-13 5:14</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>39.34</td>\n",
       "      <td>40.89</td>\n",
       "      <td>32.56</td>\n",
       "      <td>34.09</td>\n",
       "      <td>77.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.541819</td>\n",
       "      <td>2022-06-13 5:22</td>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38.89</td>\n",
       "      <td>42.82</td>\n",
       "      <td>43.92</td>\n",
       "      <td>35.34</td>\n",
       "      <td>72.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531267</td>\n",
       "      <td>2022-06-13 5:30</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>39.19</td>\n",
       "      <td>36.65</td>\n",
       "      <td>42.47</td>\n",
       "      <td>36.53</td>\n",
       "      <td>78.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_003</td>\n",
       "      <td>2</td>\n",
       "      <td>0.537325</td>\n",
       "      <td>2022-06-13 5:39</td>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>37.74</td>\n",
       "      <td>39.17</td>\n",
       "      <td>52.17</td>\n",
       "      <td>30.58</td>\n",
       "      <td>71.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_004</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531590</td>\n",
       "      <td>2022-06-13 5:47</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38.70</td>\n",
       "      <td>41.89</td>\n",
       "      <td>46.93</td>\n",
       "      <td>33.09</td>\n",
       "      <td>76.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>TRAIN_583</td>\n",
       "      <td>0</td>\n",
       "      <td>0.522340</td>\n",
       "      <td>2022-09-05 8:34</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>51.71</td>\n",
       "      <td>59.64</td>\n",
       "      <td>54.61</td>\n",
       "      <td>57.05</td>\n",
       "      <td>63.18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>TRAIN_584</td>\n",
       "      <td>0</td>\n",
       "      <td>0.519519</td>\n",
       "      <td>2022-09-05 11:09</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>TRAIN_585</td>\n",
       "      <td>0</td>\n",
       "      <td>0.515214</td>\n",
       "      <td>2022-09-05 11:17</td>\n",
       "      <td>T010306</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>TRAIN_594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524022</td>\n",
       "      <td>2022-09-08 22:38</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>49.47</td>\n",
       "      <td>53.07</td>\n",
       "      <td>50.89</td>\n",
       "      <td>55.10</td>\n",
       "      <td>66.49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>TRAIN_595</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521289</td>\n",
       "      <td>2022-09-08 22:47</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 2881 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PRODUCT_ID  Y_Class  Y_Quality         TIMESTAMP     LINE PRODUCT_CODE  \\\n",
       "0    TRAIN_000        1   0.533433   2022-06-13 5:14  T050304         A_31   \n",
       "1    TRAIN_001        2   0.541819   2022-06-13 5:22  T050307         A_31   \n",
       "2    TRAIN_002        1   0.531267   2022-06-13 5:30  T050304         A_31   \n",
       "3    TRAIN_003        2   0.537325   2022-06-13 5:39  T050307         A_31   \n",
       "4    TRAIN_004        1   0.531590   2022-06-13 5:47  T050304         A_31   \n",
       "..         ...      ...        ...               ...      ...          ...   \n",
       "583  TRAIN_583        0   0.522340   2022-09-05 8:34  T050304         A_31   \n",
       "584  TRAIN_584        0   0.519519  2022-09-05 11:09  T010305         A_31   \n",
       "585  TRAIN_585        0   0.515214  2022-09-05 11:17  T010306         A_31   \n",
       "594  TRAIN_594        0   0.524022  2022-09-08 22:38  T050304         A_31   \n",
       "595  TRAIN_595        0   0.521289  2022-09-08 22:47  T050304         A_31   \n",
       "\n",
       "     X_1  X_2  X_3  X_4  ...  X_2866  X_2867  X_2868  X_2869  X_2870  X_2871  \\\n",
       "0    NaN  NaN  NaN  NaN  ...   39.34   40.89   32.56   34.09   77.77     NaN   \n",
       "1    NaN  NaN  NaN  NaN  ...   38.89   42.82   43.92   35.34   72.55     NaN   \n",
       "2    NaN  NaN  NaN  NaN  ...   39.19   36.65   42.47   36.53   78.35     NaN   \n",
       "3    NaN  NaN  NaN  NaN  ...   37.74   39.17   52.17   30.58   71.78     NaN   \n",
       "4    NaN  NaN  NaN  NaN  ...   38.70   41.89   46.93   33.09   76.97     NaN   \n",
       "..   ...  ...  ...  ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "583  NaN  NaN  NaN  NaN  ...   51.71   59.64   54.61   57.05   63.18     1.0   \n",
       "584  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "585  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "594  NaN  NaN  NaN  NaN  ...   49.47   53.07   50.89   55.10   66.49     1.0   \n",
       "595  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     1.0   \n",
       "\n",
       "     X_2872  X_2873  X_2874  X_2875  \n",
       "0       NaN     NaN     NaN     NaN  \n",
       "1       NaN     NaN     NaN     NaN  \n",
       "2       NaN     NaN     NaN     NaN  \n",
       "3       NaN     NaN     NaN     NaN  \n",
       "4       NaN     NaN     NaN     NaN  \n",
       "..      ...     ...     ...     ...  \n",
       "583     NaN     NaN     NaN     NaN  \n",
       "584     NaN     NaN     NaN     NaN  \n",
       "585     NaN     NaN     NaN     NaN  \n",
       "594     NaN     NaN     NaN     NaN  \n",
       "595     NaN     NaN     NaN     NaN  \n",
       "\n",
       "[249 rows x 2881 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['X_1'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1230dced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRODUCT_CODE  LINE   \n",
       "A_31          T010305    0\n",
       "              T010306    0\n",
       "              T050304    0\n",
       "              T050307    0\n",
       "Name: X_1, dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hier = train_df[train_df['X_1'].isnull()].groupby(['PRODUCT_CODE', 'LINE'])['X_1'].count()\n",
    "hier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4d5945fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>Y_Class</th>\n",
       "      <th>Y_Quality</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>LINE</th>\n",
       "      <th>PRODUCT_CODE</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>...</th>\n",
       "      <th>X_2866</th>\n",
       "      <th>X_2867</th>\n",
       "      <th>X_2868</th>\n",
       "      <th>X_2869</th>\n",
       "      <th>X_2870</th>\n",
       "      <th>X_2871</th>\n",
       "      <th>X_2872</th>\n",
       "      <th>X_2873</th>\n",
       "      <th>X_2874</th>\n",
       "      <th>X_2875</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>TRAIN_028</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521249</td>\n",
       "      <td>2022-06-19 20:26</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>TRAIN_033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.526656</td>\n",
       "      <td>2022-06-21 7:14</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>TRAIN_039</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531583</td>\n",
       "      <td>2022-06-22 4:45</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>TRAIN_040</td>\n",
       "      <td>1</td>\n",
       "      <td>0.530829</td>\n",
       "      <td>2022-06-22 12:26</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TRAIN_041</td>\n",
       "      <td>1</td>\n",
       "      <td>0.528270</td>\n",
       "      <td>2022-06-22 12:34</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>TRAIN_048</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533273</td>\n",
       "      <td>2022-06-23 15:50</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>TRAIN_052</td>\n",
       "      <td>2</td>\n",
       "      <td>0.555514</td>\n",
       "      <td>2022-06-24 4:13</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>TRAIN_057</td>\n",
       "      <td>2</td>\n",
       "      <td>0.535741</td>\n",
       "      <td>2022-06-24 21:38</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>TRAIN_058</td>\n",
       "      <td>2</td>\n",
       "      <td>0.537122</td>\n",
       "      <td>2022-06-24 21:46</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>TRAIN_059</td>\n",
       "      <td>2</td>\n",
       "      <td>0.536859</td>\n",
       "      <td>2022-06-24 22:39</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>TRAIN_064</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533179</td>\n",
       "      <td>2022-06-25 18:44</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>TRAIN_065</td>\n",
       "      <td>1</td>\n",
       "      <td>0.527910</td>\n",
       "      <td>2022-06-25 18:52</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>TRAIN_066</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524408</td>\n",
       "      <td>2022-06-25 21:38</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>TRAIN_069</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531522</td>\n",
       "      <td>2022-06-26 6:06</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>TRAIN_071</td>\n",
       "      <td>1</td>\n",
       "      <td>0.534486</td>\n",
       "      <td>2022-06-26 7:24</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>TRAIN_075</td>\n",
       "      <td>1</td>\n",
       "      <td>0.534376</td>\n",
       "      <td>2022-06-27 8:07</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>TRAIN_077</td>\n",
       "      <td>1</td>\n",
       "      <td>0.534448</td>\n",
       "      <td>2022-06-29 16:59</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>TRAIN_084</td>\n",
       "      <td>1</td>\n",
       "      <td>0.529740</td>\n",
       "      <td>2022-07-01 8:02</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>TRAIN_090</td>\n",
       "      <td>1</td>\n",
       "      <td>0.534403</td>\n",
       "      <td>2022-07-02 19:25</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>TRAIN_094</td>\n",
       "      <td>2</td>\n",
       "      <td>0.536433</td>\n",
       "      <td>2022-07-03 10:39</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>TRAIN_095</td>\n",
       "      <td>2</td>\n",
       "      <td>0.536041</td>\n",
       "      <td>2022-07-03 10:47</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>TRAIN_116</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523714</td>\n",
       "      <td>2022-07-07 15:40</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>TRAIN_118</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521083</td>\n",
       "      <td>2022-07-07 17:24</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>TRAIN_123</td>\n",
       "      <td>0</td>\n",
       "      <td>0.518024</td>\n",
       "      <td>2022-07-08 13:55</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>TRAIN_129</td>\n",
       "      <td>1</td>\n",
       "      <td>0.528856</td>\n",
       "      <td>2022-07-09 17:25</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>TRAIN_179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.526741</td>\n",
       "      <td>2022-07-17 21:10</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>TRAIN_190</td>\n",
       "      <td>1</td>\n",
       "      <td>0.528190</td>\n",
       "      <td>2022-07-19 14:28</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>TRAIN_208</td>\n",
       "      <td>1</td>\n",
       "      <td>0.530048</td>\n",
       "      <td>2022-07-21 15:31</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>TRAIN_220</td>\n",
       "      <td>1</td>\n",
       "      <td>0.529254</td>\n",
       "      <td>2022-07-22 13:17</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>TRAIN_230</td>\n",
       "      <td>1</td>\n",
       "      <td>0.530497</td>\n",
       "      <td>2022-07-23 2:34</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>TRAIN_235</td>\n",
       "      <td>1</td>\n",
       "      <td>0.530514</td>\n",
       "      <td>2022-07-23 16:42</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>TRAIN_239</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523694</td>\n",
       "      <td>2022-07-24 0:21</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>TRAIN_244</td>\n",
       "      <td>1</td>\n",
       "      <td>0.527486</td>\n",
       "      <td>2022-07-24 2:32</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>TRAIN_281</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533960</td>\n",
       "      <td>2022-07-29 19:52</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>TRAIN_283</td>\n",
       "      <td>2</td>\n",
       "      <td>0.538614</td>\n",
       "      <td>2022-07-29 20:00</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>TRAIN_287</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531037</td>\n",
       "      <td>2022-07-30 5:12</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>TRAIN_291</td>\n",
       "      <td>2</td>\n",
       "      <td>0.558568</td>\n",
       "      <td>2022-07-30 10:07</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>TRAIN_292</td>\n",
       "      <td>2</td>\n",
       "      <td>0.558770</td>\n",
       "      <td>2022-07-30 10:34</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>TRAIN_295</td>\n",
       "      <td>1</td>\n",
       "      <td>0.532890</td>\n",
       "      <td>2022-07-30 15:44</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>TRAIN_299</td>\n",
       "      <td>2</td>\n",
       "      <td>0.536951</td>\n",
       "      <td>2022-07-31 2:55</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>TRAIN_300</td>\n",
       "      <td>2</td>\n",
       "      <td>0.537116</td>\n",
       "      <td>2022-07-31 3:03</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>TRAIN_312</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523830</td>\n",
       "      <td>2022-07-31 9:54</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>TRAIN_332</td>\n",
       "      <td>1</td>\n",
       "      <td>0.534065</td>\n",
       "      <td>2022-08-02 23:18</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>TRAIN_334</td>\n",
       "      <td>1</td>\n",
       "      <td>0.529070</td>\n",
       "      <td>2022-08-02 23:34</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>TRAIN_404</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500856</td>\n",
       "      <td>2022-08-09 14:42</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>TRAIN_410</td>\n",
       "      <td>0</td>\n",
       "      <td>0.520625</td>\n",
       "      <td>2022-08-10 4:08</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>TRAIN_436</td>\n",
       "      <td>1</td>\n",
       "      <td>0.526241</td>\n",
       "      <td>2022-08-12 18:54</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>TRAIN_449</td>\n",
       "      <td>1</td>\n",
       "      <td>0.529624</td>\n",
       "      <td>2022-08-14 14:44</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>TRAIN_455</td>\n",
       "      <td>1</td>\n",
       "      <td>0.530303</td>\n",
       "      <td>2022-08-14 12:54</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>TRAIN_456</td>\n",
       "      <td>1</td>\n",
       "      <td>0.527278</td>\n",
       "      <td>2022-08-14 13:02</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>TRAIN_480</td>\n",
       "      <td>1</td>\n",
       "      <td>0.530625</td>\n",
       "      <td>2022-08-16 15:36</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>TRAIN_490</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523173</td>\n",
       "      <td>2022-08-17 21:08</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>TRAIN_491</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524808</td>\n",
       "      <td>2022-08-17 21:16</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>TRAIN_500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.532032</td>\n",
       "      <td>2022-08-19 15:49</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>TRAIN_521</td>\n",
       "      <td>1</td>\n",
       "      <td>0.529171</td>\n",
       "      <td>2022-08-21 10:31</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>TRAIN_530</td>\n",
       "      <td>1</td>\n",
       "      <td>0.532754</td>\n",
       "      <td>2022-08-22 15:30</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>TRAIN_553</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524686</td>\n",
       "      <td>2022-08-26 11:23</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>TRAIN_554</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531106</td>\n",
       "      <td>2022-08-26 11:31</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>TRAIN_584</td>\n",
       "      <td>0</td>\n",
       "      <td>0.519519</td>\n",
       "      <td>2022-09-05 11:09</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59 rows × 2881 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PRODUCT_ID  Y_Class  Y_Quality         TIMESTAMP     LINE PRODUCT_CODE  \\\n",
       "28   TRAIN_028        0   0.521249  2022-06-19 20:26  T010305         A_31   \n",
       "33   TRAIN_033        1   0.526656   2022-06-21 7:14  T010305         A_31   \n",
       "39   TRAIN_039        1   0.531583   2022-06-22 4:45  T010305         A_31   \n",
       "40   TRAIN_040        1   0.530829  2022-06-22 12:26  T010305         A_31   \n",
       "41   TRAIN_041        1   0.528270  2022-06-22 12:34  T010305         A_31   \n",
       "48   TRAIN_048        1   0.533273  2022-06-23 15:50  T010305         A_31   \n",
       "52   TRAIN_052        2   0.555514   2022-06-24 4:13  T010305         A_31   \n",
       "57   TRAIN_057        2   0.535741  2022-06-24 21:38  T010305         A_31   \n",
       "58   TRAIN_058        2   0.537122  2022-06-24 21:46  T010305         A_31   \n",
       "59   TRAIN_059        2   0.536859  2022-06-24 22:39  T010305         A_31   \n",
       "64   TRAIN_064        1   0.533179  2022-06-25 18:44  T010305         A_31   \n",
       "65   TRAIN_065        1   0.527910  2022-06-25 18:52  T010305         A_31   \n",
       "66   TRAIN_066        0   0.524408  2022-06-25 21:38  T010305         A_31   \n",
       "69   TRAIN_069        1   0.531522   2022-06-26 6:06  T010305         A_31   \n",
       "71   TRAIN_071        1   0.534486   2022-06-26 7:24  T010305         A_31   \n",
       "75   TRAIN_075        1   0.534376   2022-06-27 8:07  T010305         A_31   \n",
       "77   TRAIN_077        1   0.534448  2022-06-29 16:59  T010305         A_31   \n",
       "84   TRAIN_084        1   0.529740   2022-07-01 8:02  T010305         A_31   \n",
       "90   TRAIN_090        1   0.534403  2022-07-02 19:25  T010305         A_31   \n",
       "94   TRAIN_094        2   0.536433  2022-07-03 10:39  T010305         A_31   \n",
       "95   TRAIN_095        2   0.536041  2022-07-03 10:47  T010305         A_31   \n",
       "116  TRAIN_116        0   0.523714  2022-07-07 15:40  T010305         A_31   \n",
       "118  TRAIN_118        0   0.521083  2022-07-07 17:24  T010305         A_31   \n",
       "123  TRAIN_123        0   0.518024  2022-07-08 13:55  T010305         A_31   \n",
       "129  TRAIN_129        1   0.528856  2022-07-09 17:25  T010305         A_31   \n",
       "179  TRAIN_179        1   0.526741  2022-07-17 21:10  T010305         A_31   \n",
       "190  TRAIN_190        1   0.528190  2022-07-19 14:28  T010305         A_31   \n",
       "208  TRAIN_208        1   0.530048  2022-07-21 15:31  T010305         A_31   \n",
       "220  TRAIN_220        1   0.529254  2022-07-22 13:17  T010305         A_31   \n",
       "230  TRAIN_230        1   0.530497   2022-07-23 2:34  T010305         A_31   \n",
       "235  TRAIN_235        1   0.530514  2022-07-23 16:42  T010305         A_31   \n",
       "239  TRAIN_239        0   0.523694   2022-07-24 0:21  T010305         A_31   \n",
       "244  TRAIN_244        1   0.527486   2022-07-24 2:32  T010305         A_31   \n",
       "281  TRAIN_281        1   0.533960  2022-07-29 19:52  T010305         A_31   \n",
       "283  TRAIN_283        2   0.538614  2022-07-29 20:00  T010305         A_31   \n",
       "287  TRAIN_287        1   0.531037   2022-07-30 5:12  T010305         A_31   \n",
       "291  TRAIN_291        2   0.558568  2022-07-30 10:07  T010305         A_31   \n",
       "292  TRAIN_292        2   0.558770  2022-07-30 10:34  T010305         A_31   \n",
       "295  TRAIN_295        1   0.532890  2022-07-30 15:44  T010305         A_31   \n",
       "299  TRAIN_299        2   0.536951   2022-07-31 2:55  T010305         A_31   \n",
       "300  TRAIN_300        2   0.537116   2022-07-31 3:03  T010305         A_31   \n",
       "312  TRAIN_312        0   0.523830   2022-07-31 9:54  T010305         A_31   \n",
       "332  TRAIN_332        1   0.534065  2022-08-02 23:18  T010305         A_31   \n",
       "334  TRAIN_334        1   0.529070  2022-08-02 23:34  T010305         A_31   \n",
       "404  TRAIN_404        0   0.500856  2022-08-09 14:42  T010305         A_31   \n",
       "410  TRAIN_410        0   0.520625   2022-08-10 4:08  T010305         A_31   \n",
       "436  TRAIN_436        1   0.526241  2022-08-12 18:54  T010305         A_31   \n",
       "449  TRAIN_449        1   0.529624  2022-08-14 14:44  T010305         A_31   \n",
       "455  TRAIN_455        1   0.530303  2022-08-14 12:54  T010305         A_31   \n",
       "456  TRAIN_456        1   0.527278  2022-08-14 13:02  T010305         A_31   \n",
       "480  TRAIN_480        1   0.530625  2022-08-16 15:36  T010305         A_31   \n",
       "490  TRAIN_490        0   0.523173  2022-08-17 21:08  T010305         A_31   \n",
       "491  TRAIN_491        0   0.524808  2022-08-17 21:16  T010305         A_31   \n",
       "500  TRAIN_500        1   0.532032  2022-08-19 15:49  T010305         A_31   \n",
       "521  TRAIN_521        1   0.529171  2022-08-21 10:31  T010305         A_31   \n",
       "530  TRAIN_530        1   0.532754  2022-08-22 15:30  T010305         A_31   \n",
       "553  TRAIN_553        0   0.524686  2022-08-26 11:23  T010305         A_31   \n",
       "554  TRAIN_554        1   0.531106  2022-08-26 11:31  T010305         A_31   \n",
       "584  TRAIN_584        0   0.519519  2022-09-05 11:09  T010305         A_31   \n",
       "\n",
       "     X_1  X_2  X_3  X_4  ...  X_2866  X_2867  X_2868  X_2869  X_2870  X_2871  \\\n",
       "28   NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "33   NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "39   NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "40   NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "41   NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "48   NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "52   NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "57   NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "58   NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "59   NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "64   NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "65   NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "66   NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "69   NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "71   NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "75   NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "77   NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "84   NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "90   NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "94   NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "95   NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "116  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "118  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "123  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "129  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "179  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "190  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "208  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "220  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "230  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "235  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "239  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "244  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "281  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "283  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "287  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "291  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "292  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "295  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "299  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "300  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "312  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "332  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "334  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "404  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "410  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "436  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "449  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "455  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "456  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "480  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "490  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "491  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "500  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "521  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "530  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "553  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "554  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "584  NaN  NaN  NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "     X_2872  X_2873  X_2874  X_2875  \n",
       "28      NaN     NaN     NaN     NaN  \n",
       "33      NaN     NaN     NaN     NaN  \n",
       "39      NaN     NaN     NaN     NaN  \n",
       "40      NaN     NaN     NaN     NaN  \n",
       "41      NaN     NaN     NaN     NaN  \n",
       "48      NaN     NaN     NaN     NaN  \n",
       "52      NaN     NaN     NaN     NaN  \n",
       "57      NaN     NaN     NaN     NaN  \n",
       "58      NaN     NaN     NaN     NaN  \n",
       "59      NaN     NaN     NaN     NaN  \n",
       "64      NaN     NaN     NaN     NaN  \n",
       "65      NaN     NaN     NaN     NaN  \n",
       "66      NaN     NaN     NaN     NaN  \n",
       "69      NaN     NaN     NaN     NaN  \n",
       "71      NaN     NaN     NaN     NaN  \n",
       "75      NaN     NaN     NaN     NaN  \n",
       "77      NaN     NaN     NaN     NaN  \n",
       "84      NaN     NaN     NaN     NaN  \n",
       "90      NaN     NaN     NaN     NaN  \n",
       "94      NaN     NaN     NaN     NaN  \n",
       "95      NaN     NaN     NaN     NaN  \n",
       "116     NaN     NaN     NaN     NaN  \n",
       "118     NaN     NaN     NaN     NaN  \n",
       "123     NaN     NaN     NaN     NaN  \n",
       "129     NaN     NaN     NaN     NaN  \n",
       "179     NaN     NaN     NaN     NaN  \n",
       "190     NaN     NaN     NaN     NaN  \n",
       "208     NaN     NaN     NaN     NaN  \n",
       "220     NaN     NaN     NaN     NaN  \n",
       "230     NaN     NaN     NaN     NaN  \n",
       "235     NaN     NaN     NaN     NaN  \n",
       "239     NaN     NaN     NaN     NaN  \n",
       "244     NaN     NaN     NaN     NaN  \n",
       "281     NaN     NaN     NaN     NaN  \n",
       "283     NaN     NaN     NaN     NaN  \n",
       "287     NaN     NaN     NaN     NaN  \n",
       "291     NaN     NaN     NaN     NaN  \n",
       "292     NaN     NaN     NaN     NaN  \n",
       "295     NaN     NaN     NaN     NaN  \n",
       "299     NaN     NaN     NaN     NaN  \n",
       "300     NaN     NaN     NaN     NaN  \n",
       "312     NaN     NaN     NaN     NaN  \n",
       "332     NaN     NaN     NaN     NaN  \n",
       "334     NaN     NaN     NaN     NaN  \n",
       "404     NaN     NaN     NaN     NaN  \n",
       "410     NaN     NaN     NaN     NaN  \n",
       "436     NaN     NaN     NaN     NaN  \n",
       "449     NaN     NaN     NaN     NaN  \n",
       "455     NaN     NaN     NaN     NaN  \n",
       "456     NaN     NaN     NaN     NaN  \n",
       "480     NaN     NaN     NaN     NaN  \n",
       "490     NaN     NaN     NaN     NaN  \n",
       "491     NaN     NaN     NaN     NaN  \n",
       "500     NaN     NaN     NaN     NaN  \n",
       "521     NaN     NaN     NaN     NaN  \n",
       "530     NaN     NaN     NaN     NaN  \n",
       "553     NaN     NaN     NaN     NaN  \n",
       "554     NaN     NaN     NaN     NaN  \n",
       "584     NaN     NaN     NaN     NaN  \n",
       "\n",
       "[59 rows x 2881 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_pl = train_df[(train_df['PRODUCT_CODE']=='A_31') & (train_df['LINE']=='T010305')]\n",
    "train_df_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "b60be6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>LINE</th>\n",
       "      <th>PRODUCT_CODE</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>X_5</th>\n",
       "      <th>X_6</th>\n",
       "      <th>...</th>\n",
       "      <th>X_2866</th>\n",
       "      <th>X_2867</th>\n",
       "      <th>X_2868</th>\n",
       "      <th>X_2869</th>\n",
       "      <th>X_2870</th>\n",
       "      <th>X_2871</th>\n",
       "      <th>X_2872</th>\n",
       "      <th>X_2873</th>\n",
       "      <th>X_2874</th>\n",
       "      <th>X_2875</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>2022-09-09 10:56</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>2022-09-09 11:04</td>\n",
       "      <td>T010306</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TEST_005</td>\n",
       "      <td>2022-09-09 19:35</td>\n",
       "      <td>T010306</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TEST_006</td>\n",
       "      <td>2022-09-09 19:43</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TEST_007</td>\n",
       "      <td>2022-09-10 12:27</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>57.74</td>\n",
       "      <td>52.51</td>\n",
       "      <td>54.45</td>\n",
       "      <td>57.99</td>\n",
       "      <td>63.16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>TEST_284</td>\n",
       "      <td>2022-11-03 9:53</td>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>52.97</td>\n",
       "      <td>58.06</td>\n",
       "      <td>44.11</td>\n",
       "      <td>56.33</td>\n",
       "      <td>62.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>263.4</td>\n",
       "      <td>257.5</td>\n",
       "      <td>261.0</td>\n",
       "      <td>236.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>TEST_285</td>\n",
       "      <td>2022-11-03 10:01</td>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>54.24</td>\n",
       "      <td>55.55</td>\n",
       "      <td>51.60</td>\n",
       "      <td>48.53</td>\n",
       "      <td>61.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>267.6</td>\n",
       "      <td>278.6</td>\n",
       "      <td>271.4</td>\n",
       "      <td>243.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>TEST_286</td>\n",
       "      <td>2022-11-03 11:31</td>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>58.06</td>\n",
       "      <td>57.92</td>\n",
       "      <td>49.06</td>\n",
       "      <td>48.26</td>\n",
       "      <td>62.77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>223.8</td>\n",
       "      <td>169.7</td>\n",
       "      <td>198.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>TEST_292</td>\n",
       "      <td>2022-11-04 0:31</td>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>53.55</td>\n",
       "      <td>52.68</td>\n",
       "      <td>49.97</td>\n",
       "      <td>56.66</td>\n",
       "      <td>63.52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>210.5</td>\n",
       "      <td>214.6</td>\n",
       "      <td>201.6</td>\n",
       "      <td>191.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>TEST_293</td>\n",
       "      <td>2022-11-04 0:39</td>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>53.94</td>\n",
       "      <td>57.38</td>\n",
       "      <td>42.37</td>\n",
       "      <td>51.67</td>\n",
       "      <td>65.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>247.1</td>\n",
       "      <td>253.9</td>\n",
       "      <td>262.6</td>\n",
       "      <td>236.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 2879 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PRODUCT_ID         TIMESTAMP     LINE PRODUCT_CODE  X_1  X_2  X_3  X_4  \\\n",
       "3     TEST_003  2022-09-09 10:56  T010305         A_31  NaN  NaN  NaN  NaN   \n",
       "4     TEST_004  2022-09-09 11:04  T010306         A_31  NaN  NaN  NaN  NaN   \n",
       "5     TEST_005  2022-09-09 19:35  T010306         A_31  NaN  NaN  NaN  NaN   \n",
       "6     TEST_006  2022-09-09 19:43  T010305         A_31  NaN  NaN  NaN  NaN   \n",
       "7     TEST_007  2022-09-10 12:27  T050304         A_31  NaN  NaN  NaN  NaN   \n",
       "..         ...               ...      ...          ...  ...  ...  ...  ...   \n",
       "284   TEST_284   2022-11-03 9:53  T050307         A_31  NaN  NaN  NaN  NaN   \n",
       "285   TEST_285  2022-11-03 10:01  T050307         A_31  NaN  NaN  NaN  NaN   \n",
       "286   TEST_286  2022-11-03 11:31  T050307         A_31  NaN  NaN  NaN  NaN   \n",
       "292   TEST_292   2022-11-04 0:31  T050307         A_31  NaN  NaN  NaN  NaN   \n",
       "293   TEST_293   2022-11-04 0:39  T050307         A_31  NaN  NaN  NaN  NaN   \n",
       "\n",
       "     X_5  X_6  ...  X_2866  X_2867  X_2868  X_2869  X_2870  X_2871  X_2872  \\\n",
       "3    NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "4    NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "5    NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "6    NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "7    NaN  NaN  ...   57.74   52.51   54.45   57.99   63.16     1.0     NaN   \n",
       "..   ...  ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "284  NaN  NaN  ...   52.97   58.06   44.11   56.33   62.00     1.0   263.4   \n",
       "285  NaN  NaN  ...   54.24   55.55   51.60   48.53   61.95     1.0   267.6   \n",
       "286  NaN  NaN  ...   58.06   57.92   49.06   48.26   62.77     1.0   199.0   \n",
       "292  NaN  NaN  ...   53.55   52.68   49.97   56.66   63.52     1.0   210.5   \n",
       "293  NaN  NaN  ...   53.94   57.38   42.37   51.67   65.05     1.0   247.1   \n",
       "\n",
       "     X_2873  X_2874  X_2875  \n",
       "3       NaN     NaN     NaN  \n",
       "4       NaN     NaN     NaN  \n",
       "5       NaN     NaN     NaN  \n",
       "6       NaN     NaN     NaN  \n",
       "7       NaN     NaN     NaN  \n",
       "..      ...     ...     ...  \n",
       "284   257.5   261.0   236.3  \n",
       "285   278.6   271.4   243.3  \n",
       "286   223.8   169.7   198.7  \n",
       "292   214.6   201.6   191.9  \n",
       "293   253.9   262.6   236.5  \n",
       "\n",
       "[67 rows x 2879 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df['PRODUCT_CODE']=='A_31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "122d568c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>Y_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PRODUCT_ID  Y_Class\n",
       "0   TEST_000        0\n",
       "1   TEST_001        0\n",
       "2   TEST_002        0\n",
       "3   TEST_003        0\n",
       "4   TEST_004        0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9fd307",
   "metadata": {},
   "source": [
    "위 세 가지 데이터 프레임을 보고 우리가 무엇을 예측해야하는지 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6486caa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.23157894736845"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y0 = train_df['X_300'][train_df['Y_Class']==0].mean()\n",
    "y0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8c7839",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "데이터 전처리(Data preprocessing)의 목적은 \n",
    "\n",
    "주어진원본 데이터를 신경망에 적용하기 쉽도록 만드는 것이다.\n",
    "\n",
    "벡터화(vectorization), 정규화(normalization), \n",
    "\n",
    "특성 추출(Feature Engineering)등이 포함된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d37689b",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b92435",
   "metadata": {},
   "source": [
    "**train data 필요없는 column 삭제** (점수가 더 낮아진다. 이제 사용 x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acde58aa",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>Y_Class</th>\n",
       "      <th>Y_Quality</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>LINE</th>\n",
       "      <th>PRODUCT_CODE</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>...</th>\n",
       "      <th>X_2862</th>\n",
       "      <th>X_2863</th>\n",
       "      <th>X_2864</th>\n",
       "      <th>X_2865</th>\n",
       "      <th>X_2866</th>\n",
       "      <th>X_2867</th>\n",
       "      <th>X_2868</th>\n",
       "      <th>X_2869</th>\n",
       "      <th>X_2870</th>\n",
       "      <th>X_2871</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533433</td>\n",
       "      <td>2022-06-13 5:14</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>189.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>368.296296</td>\n",
       "      <td>353.0</td>\n",
       "      <td>39.34</td>\n",
       "      <td>40.89</td>\n",
       "      <td>32.56</td>\n",
       "      <td>34.09</td>\n",
       "      <td>77.77</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.541819</td>\n",
       "      <td>2022-06-13 5:22</td>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>185.6</td>\n",
       "      <td>383.0</td>\n",
       "      <td>367.735849</td>\n",
       "      <td>353.0</td>\n",
       "      <td>38.89</td>\n",
       "      <td>42.82</td>\n",
       "      <td>43.92</td>\n",
       "      <td>35.34</td>\n",
       "      <td>72.55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531267</td>\n",
       "      <td>2022-06-13 5:30</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>165.5</td>\n",
       "      <td>383.0</td>\n",
       "      <td>367.320755</td>\n",
       "      <td>353.0</td>\n",
       "      <td>39.19</td>\n",
       "      <td>36.65</td>\n",
       "      <td>42.47</td>\n",
       "      <td>36.53</td>\n",
       "      <td>78.35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_003</td>\n",
       "      <td>2</td>\n",
       "      <td>0.537325</td>\n",
       "      <td>2022-06-13 5:39</td>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>165.8</td>\n",
       "      <td>384.0</td>\n",
       "      <td>369.188679</td>\n",
       "      <td>353.0</td>\n",
       "      <td>37.74</td>\n",
       "      <td>39.17</td>\n",
       "      <td>52.17</td>\n",
       "      <td>30.58</td>\n",
       "      <td>71.78</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_004</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531590</td>\n",
       "      <td>2022-06-13 5:47</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>182.6</td>\n",
       "      <td>383.0</td>\n",
       "      <td>367.351852</td>\n",
       "      <td>352.0</td>\n",
       "      <td>38.70</td>\n",
       "      <td>41.89</td>\n",
       "      <td>46.93</td>\n",
       "      <td>33.09</td>\n",
       "      <td>76.97</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2799 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PRODUCT_ID  Y_Class  Y_Quality        TIMESTAMP     LINE PRODUCT_CODE  X_1  \\\n",
       "0  TRAIN_000        1   0.533433  2022-06-13 5:14  T050304         A_31  NaN   \n",
       "1  TRAIN_001        2   0.541819  2022-06-13 5:22  T050307         A_31  NaN   \n",
       "2  TRAIN_002        1   0.531267  2022-06-13 5:30  T050304         A_31  NaN   \n",
       "3  TRAIN_003        2   0.537325  2022-06-13 5:39  T050307         A_31  NaN   \n",
       "4  TRAIN_004        1   0.531590  2022-06-13 5:47  T050304         A_31  NaN   \n",
       "\n",
       "   X_2  X_3  X_4  ...  X_2862  X_2863      X_2864  X_2865  X_2866  X_2867  \\\n",
       "0  NaN  NaN  NaN  ...   189.0   383.0  368.296296   353.0   39.34   40.89   \n",
       "1  NaN  NaN  NaN  ...   185.6   383.0  367.735849   353.0   38.89   42.82   \n",
       "2  NaN  NaN  NaN  ...   165.5   383.0  367.320755   353.0   39.19   36.65   \n",
       "3  NaN  NaN  NaN  ...   165.8   384.0  369.188679   353.0   37.74   39.17   \n",
       "4  NaN  NaN  NaN  ...   182.6   383.0  367.351852   352.0   38.70   41.89   \n",
       "\n",
       "   X_2868  X_2869  X_2870  X_2871  \n",
       "0   32.56   34.09   77.77     NaN  \n",
       "1   43.92   35.34   72.55     NaN  \n",
       "2   42.47   36.53   78.35     NaN  \n",
       "3   52.17   30.58   71.78     NaN  \n",
       "4   46.93   33.09   76.97     NaN  \n",
       "\n",
       "[5 rows x 2799 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del_allnull = []\n",
    "# for i in train_df.columns:\n",
    "#     if train_df[i].isnull().sum() == 598:\n",
    "# #         print(i)\n",
    "#         del_allnull.append(i)\n",
    "#         del train_df[i]\n",
    "        \n",
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "438dc535",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_Class</th>\n",
       "      <th>Y_Quality</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_4</th>\n",
       "      <th>X_5</th>\n",
       "      <th>X_7</th>\n",
       "      <th>X_8</th>\n",
       "      <th>X_9</th>\n",
       "      <th>X_10</th>\n",
       "      <th>...</th>\n",
       "      <th>X_2862</th>\n",
       "      <th>X_2863</th>\n",
       "      <th>X_2864</th>\n",
       "      <th>X_2865</th>\n",
       "      <th>X_2866</th>\n",
       "      <th>X_2867</th>\n",
       "      <th>X_2868</th>\n",
       "      <th>X_2869</th>\n",
       "      <th>X_2870</th>\n",
       "      <th>X_2871</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>598.000000</td>\n",
       "      <td>598.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>349.0</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>349.0</td>\n",
       "      <td>...</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.025084</td>\n",
       "      <td>0.530896</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.392550</td>\n",
       "      <td>48.802292</td>\n",
       "      <td>10.048711</td>\n",
       "      <td>41.469914</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>163.290763</td>\n",
       "      <td>423.558233</td>\n",
       "      <td>406.088187</td>\n",
       "      <td>388.064257</td>\n",
       "      <td>50.807300</td>\n",
       "      <td>53.60770</td>\n",
       "      <td>49.606200</td>\n",
       "      <td>51.659800</td>\n",
       "      <td>66.64970</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.565069</td>\n",
       "      <td>0.007401</td>\n",
       "      <td>5.895256</td>\n",
       "      <td>4.107640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.489019</td>\n",
       "      <td>4.373824</td>\n",
       "      <td>0.215571</td>\n",
       "      <td>10.515032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.514477</td>\n",
       "      <td>38.335184</td>\n",
       "      <td>37.299901</td>\n",
       "      <td>36.054561</td>\n",
       "      <td>7.011828</td>\n",
       "      <td>8.13899</td>\n",
       "      <td>7.158917</td>\n",
       "      <td>8.913065</td>\n",
       "      <td>4.52781</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500856</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>125.700000</td>\n",
       "      <td>373.000000</td>\n",
       "      <td>357.698113</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>32.120000</td>\n",
       "      <td>31.70000</td>\n",
       "      <td>32.560000</td>\n",
       "      <td>30.490000</td>\n",
       "      <td>61.67000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.527535</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>157.200000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>368.296296</td>\n",
       "      <td>352.000000</td>\n",
       "      <td>49.485000</td>\n",
       "      <td>52.20000</td>\n",
       "      <td>42.160000</td>\n",
       "      <td>49.915000</td>\n",
       "      <td>63.64500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.530436</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>163.300000</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>427.867925</td>\n",
       "      <td>406.000000</td>\n",
       "      <td>53.425000</td>\n",
       "      <td>55.92500</td>\n",
       "      <td>51.460000</td>\n",
       "      <td>56.175000</td>\n",
       "      <td>65.14000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.533433</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>169.100000</td>\n",
       "      <td>465.000000</td>\n",
       "      <td>443.807692</td>\n",
       "      <td>423.000000</td>\n",
       "      <td>55.287500</td>\n",
       "      <td>58.97500</td>\n",
       "      <td>55.030000</td>\n",
       "      <td>57.175000</td>\n",
       "      <td>67.11500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.578841</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>194.600000</td>\n",
       "      <td>473.000000</td>\n",
       "      <td>450.692308</td>\n",
       "      <td>434.000000</td>\n",
       "      <td>60.240000</td>\n",
       "      <td>68.66000</td>\n",
       "      <td>60.410000</td>\n",
       "      <td>59.930000</td>\n",
       "      <td>79.75000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 2596 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Y_Class   Y_Quality         X_1         X_2    X_4         X_5  \\\n",
       "count  598.000000  598.000000  349.000000  349.000000  349.0  349.000000   \n",
       "mean     1.025084    0.530896    2.409742   95.123209   45.0   10.392550   \n",
       "std      0.565069    0.007401    5.895256    4.107640    0.0    0.489019   \n",
       "min      0.000000    0.500856    1.000000   87.000000   45.0   10.000000   \n",
       "25%      1.000000    0.527535    2.000000   93.000000   45.0   10.000000   \n",
       "50%      1.000000    0.530436    2.000000   95.000000   45.0   10.000000   \n",
       "75%      1.000000    0.533433    2.000000   98.000000   45.0   11.000000   \n",
       "max      2.000000    0.578841  103.000000  102.000000   45.0   11.000000   \n",
       "\n",
       "              X_7         X_8         X_9   X_10  ...      X_2862      X_2863  \\\n",
       "count  349.000000  349.000000  349.000000  349.0  ...  249.000000  249.000000   \n",
       "mean    48.802292   10.048711   41.469914    2.0  ...  163.290763  423.558233   \n",
       "std      4.373824    0.215571   10.515032    0.0  ...   11.514477   38.335184   \n",
       "min     45.000000   10.000000   31.000000    2.0  ...  125.700000  373.000000   \n",
       "25%     45.000000   10.000000   31.000000    2.0  ...  157.200000  384.000000   \n",
       "50%     45.000000   10.000000   31.000000    2.0  ...  163.300000  446.000000   \n",
       "75%     51.000000   10.000000   52.000000    2.0  ...  169.100000  465.000000   \n",
       "max     62.000000   11.000000   52.000000    2.0  ...  194.600000  473.000000   \n",
       "\n",
       "           X_2864      X_2865      X_2866     X_2867      X_2868      X_2869  \\\n",
       "count  249.000000  249.000000  100.000000  100.00000  100.000000  100.000000   \n",
       "mean   406.088187  388.064257   50.807300   53.60770   49.606200   51.659800   \n",
       "std     37.299901   36.054561    7.011828    8.13899    7.158917    8.913065   \n",
       "min    357.698113  342.000000   32.120000   31.70000   32.560000   30.490000   \n",
       "25%    368.296296  352.000000   49.485000   52.20000   42.160000   49.915000   \n",
       "50%    427.867925  406.000000   53.425000   55.92500   51.460000   56.175000   \n",
       "75%    443.807692  423.000000   55.287500   58.97500   55.030000   57.175000   \n",
       "max    450.692308  434.000000   60.240000   68.66000   60.410000   59.930000   \n",
       "\n",
       "          X_2870  X_2871  \n",
       "count  100.00000    99.0  \n",
       "mean    66.64970     1.0  \n",
       "std      4.52781     0.0  \n",
       "min     61.67000     1.0  \n",
       "25%     63.64500     1.0  \n",
       "50%     65.14000     1.0  \n",
       "75%     67.11500     1.0  \n",
       "max     79.75000     1.0  \n",
       "\n",
       "[8 rows x 2596 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del_allzero = []\n",
    "# for i in train_df.columns:\n",
    "#     if train_df[i].sum() == 0.0:\n",
    "# #         print(i)\n",
    "#         del_allzero.append(i)\n",
    "#         del train_df[i]\n",
    "        \n",
    "# train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d767dcb8",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457cd531",
   "metadata": {},
   "source": [
    "데이터 전처리. 결측값을 각 column의 평균값으로 채운다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "8b75b069",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.fillna(-100) #결측치를 평균값으로 채운다.\n",
    "test_df = test_df.fillna(-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ae41a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_df['Y_Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eeb706",
   "metadata": {},
   "source": [
    "학습에 쓰이지 않을 column들을 제거한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "606f458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_df.drop(columns = ['PRODUCT_ID', 'TIMESTAMP', 'Y_Class', 'Y_Quality'])\n",
    "#모델 학습이 끝나고 예측에 쓰일 test데이터\n",
    "test_x = test_df.drop(columns=['PRODUCT_ID', 'TIMESTAMP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd74ac6",
   "metadata": {},
   "source": [
    "범주형 데이터를 수치 데이터로 전환하기 위해 LabelEncoder 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "53adcf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# qualitative to quantitative\n",
    "qual_col = ['LINE', 'PRODUCT_CODE']\n",
    "\n",
    "for i in qual_col:\n",
    "    le = LabelEncoder()\n",
    "    le = le.fit(train_x[i]) #원래 column 값을 기준으로 fit.\n",
    "    train_x[i] = le.transform(train_x[i]) #수치화, 수치로 변형\n",
    "    \n",
    "    for label in np.unique(test_x[i]): \n",
    "        if label not in le.classes_: \n",
    "            le.classes_ = np.append(le.classes_, label)\n",
    "    test_x[i] = le.transform(test_x[i]) \n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "689de03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LINE</th>\n",
       "      <th>PRODUCT_CODE</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>X_5</th>\n",
       "      <th>X_6</th>\n",
       "      <th>X_7</th>\n",
       "      <th>X_8</th>\n",
       "      <th>...</th>\n",
       "      <th>X_2866</th>\n",
       "      <th>X_2867</th>\n",
       "      <th>X_2868</th>\n",
       "      <th>X_2869</th>\n",
       "      <th>X_2870</th>\n",
       "      <th>X_2871</th>\n",
       "      <th>X_2872</th>\n",
       "      <th>X_2873</th>\n",
       "      <th>X_2874</th>\n",
       "      <th>X_2875</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.39255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.802292</td>\n",
       "      <td>10.048711</td>\n",
       "      <td>...</td>\n",
       "      <td>39.3400</td>\n",
       "      <td>40.8900</td>\n",
       "      <td>32.5600</td>\n",
       "      <td>34.0900</td>\n",
       "      <td>77.7700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.39255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.802292</td>\n",
       "      <td>10.048711</td>\n",
       "      <td>...</td>\n",
       "      <td>38.8900</td>\n",
       "      <td>42.8200</td>\n",
       "      <td>43.9200</td>\n",
       "      <td>35.3400</td>\n",
       "      <td>72.5500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.39255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.802292</td>\n",
       "      <td>10.048711</td>\n",
       "      <td>...</td>\n",
       "      <td>39.1900</td>\n",
       "      <td>36.6500</td>\n",
       "      <td>42.4700</td>\n",
       "      <td>36.5300</td>\n",
       "      <td>78.3500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.39255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.802292</td>\n",
       "      <td>10.048711</td>\n",
       "      <td>...</td>\n",
       "      <td>37.7400</td>\n",
       "      <td>39.1700</td>\n",
       "      <td>52.1700</td>\n",
       "      <td>30.5800</td>\n",
       "      <td>71.7800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.39255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.802292</td>\n",
       "      <td>10.048711</td>\n",
       "      <td>...</td>\n",
       "      <td>38.7000</td>\n",
       "      <td>41.8900</td>\n",
       "      <td>46.9300</td>\n",
       "      <td>33.0900</td>\n",
       "      <td>76.9700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.8073</td>\n",
       "      <td>53.6077</td>\n",
       "      <td>49.6062</td>\n",
       "      <td>51.6598</td>\n",
       "      <td>66.6497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.39255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.802292</td>\n",
       "      <td>10.048711</td>\n",
       "      <td>...</td>\n",
       "      <td>49.4700</td>\n",
       "      <td>53.0700</td>\n",
       "      <td>50.8900</td>\n",
       "      <td>55.1000</td>\n",
       "      <td>66.4900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.39255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.802292</td>\n",
       "      <td>10.048711</td>\n",
       "      <td>...</td>\n",
       "      <td>50.8073</td>\n",
       "      <td>53.6077</td>\n",
       "      <td>49.6062</td>\n",
       "      <td>51.6598</td>\n",
       "      <td>66.6497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.8073</td>\n",
       "      <td>53.6077</td>\n",
       "      <td>49.6062</td>\n",
       "      <td>51.6598</td>\n",
       "      <td>66.6497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.8073</td>\n",
       "      <td>53.6077</td>\n",
       "      <td>49.6062</td>\n",
       "      <td>51.6598</td>\n",
       "      <td>66.6497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>598 rows × 2877 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LINE  PRODUCT_CODE        X_1        X_2  X_3   X_4       X_5  X_6  \\\n",
       "0       2             0   2.409742  95.123209  0.0  45.0  10.39255  0.0   \n",
       "1       3             0   2.409742  95.123209  0.0  45.0  10.39255  0.0   \n",
       "2       2             0   2.409742  95.123209  0.0  45.0  10.39255  0.0   \n",
       "3       3             0   2.409742  95.123209  0.0  45.0  10.39255  0.0   \n",
       "4       2             0   2.409742  95.123209  0.0  45.0  10.39255  0.0   \n",
       "..    ...           ...        ...        ...  ...   ...       ...  ...   \n",
       "593     5             2   2.000000  95.000000  0.0  45.0  10.00000  0.0   \n",
       "594     2             0   2.409742  95.123209  0.0  45.0  10.39255  0.0   \n",
       "595     2             0   2.409742  95.123209  0.0  45.0  10.39255  0.0   \n",
       "596     4             1  40.000000  94.000000  0.0  45.0  11.00000  0.0   \n",
       "597     5             1  21.000000  87.000000  0.0  45.0  10.00000  0.0   \n",
       "\n",
       "           X_7        X_8  ...   X_2866   X_2867   X_2868   X_2869   X_2870  \\\n",
       "0    48.802292  10.048711  ...  39.3400  40.8900  32.5600  34.0900  77.7700   \n",
       "1    48.802292  10.048711  ...  38.8900  42.8200  43.9200  35.3400  72.5500   \n",
       "2    48.802292  10.048711  ...  39.1900  36.6500  42.4700  36.5300  78.3500   \n",
       "3    48.802292  10.048711  ...  37.7400  39.1700  52.1700  30.5800  71.7800   \n",
       "4    48.802292  10.048711  ...  38.7000  41.8900  46.9300  33.0900  76.9700   \n",
       "..         ...        ...  ...      ...      ...      ...      ...      ...   \n",
       "593  50.000000  10.000000  ...  50.8073  53.6077  49.6062  51.6598  66.6497   \n",
       "594  48.802292  10.048711  ...  49.4700  53.0700  50.8900  55.1000  66.4900   \n",
       "595  48.802292  10.048711  ...  50.8073  53.6077  49.6062  51.6598  66.6497   \n",
       "596  45.000000  10.000000  ...  50.8073  53.6077  49.6062  51.6598  66.6497   \n",
       "597  61.000000  10.000000  ...  50.8073  53.6077  49.6062  51.6598  66.6497   \n",
       "\n",
       "     X_2871  X_2872  X_2873  X_2874  X_2875  \n",
       "0       1.0     0.0     0.0     0.0     0.0  \n",
       "1       1.0     0.0     0.0     0.0     0.0  \n",
       "2       1.0     0.0     0.0     0.0     0.0  \n",
       "3       1.0     0.0     0.0     0.0     0.0  \n",
       "4       1.0     0.0     0.0     0.0     0.0  \n",
       "..      ...     ...     ...     ...     ...  \n",
       "593     1.0     0.0     0.0     0.0     0.0  \n",
       "594     1.0     0.0     0.0     0.0     0.0  \n",
       "595     1.0     0.0     0.0     0.0     0.0  \n",
       "596     1.0     0.0     0.0     0.0     0.0  \n",
       "597     1.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[598 rows x 2877 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c9e89b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LINE</th>\n",
       "      <th>PRODUCT_CODE</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>X_5</th>\n",
       "      <th>X_6</th>\n",
       "      <th>X_7</th>\n",
       "      <th>X_8</th>\n",
       "      <th>...</th>\n",
       "      <th>X_2866</th>\n",
       "      <th>X_2867</th>\n",
       "      <th>X_2868</th>\n",
       "      <th>X_2869</th>\n",
       "      <th>X_2870</th>\n",
       "      <th>X_2871</th>\n",
       "      <th>X_2872</th>\n",
       "      <th>X_2873</th>\n",
       "      <th>X_2874</th>\n",
       "      <th>X_2875</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.8073</td>\n",
       "      <td>53.6077</td>\n",
       "      <td>49.6062</td>\n",
       "      <td>51.6598</td>\n",
       "      <td>66.6497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.8073</td>\n",
       "      <td>53.6077</td>\n",
       "      <td>49.6062</td>\n",
       "      <td>51.6598</td>\n",
       "      <td>66.6497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.8073</td>\n",
       "      <td>53.6077</td>\n",
       "      <td>49.6062</td>\n",
       "      <td>51.6598</td>\n",
       "      <td>66.6497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.39255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.802292</td>\n",
       "      <td>10.048711</td>\n",
       "      <td>...</td>\n",
       "      <td>50.8073</td>\n",
       "      <td>53.6077</td>\n",
       "      <td>49.6062</td>\n",
       "      <td>51.6598</td>\n",
       "      <td>66.6497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.39255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.802292</td>\n",
       "      <td>10.048711</td>\n",
       "      <td>...</td>\n",
       "      <td>50.8073</td>\n",
       "      <td>53.6077</td>\n",
       "      <td>49.6062</td>\n",
       "      <td>51.6598</td>\n",
       "      <td>66.6497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.8073</td>\n",
       "      <td>53.6077</td>\n",
       "      <td>49.6062</td>\n",
       "      <td>51.6598</td>\n",
       "      <td>66.6497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.8073</td>\n",
       "      <td>53.6077</td>\n",
       "      <td>49.6062</td>\n",
       "      <td>51.6598</td>\n",
       "      <td>66.6497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.8073</td>\n",
       "      <td>53.6077</td>\n",
       "      <td>49.6062</td>\n",
       "      <td>51.6598</td>\n",
       "      <td>66.6497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.8073</td>\n",
       "      <td>53.6077</td>\n",
       "      <td>49.6062</td>\n",
       "      <td>51.6598</td>\n",
       "      <td>66.6497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.8073</td>\n",
       "      <td>53.6077</td>\n",
       "      <td>49.6062</td>\n",
       "      <td>51.6598</td>\n",
       "      <td>66.6497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310 rows × 2877 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LINE  PRODUCT_CODE       X_1        X_2  X_3   X_4       X_5  X_6  \\\n",
       "0       5             2  2.000000  94.000000  0.0  45.0  10.00000  0.0   \n",
       "1       4             2  2.000000  93.000000  0.0  45.0  11.00000  0.0   \n",
       "2       4             2  2.000000  95.000000  0.0  45.0  11.00000  0.0   \n",
       "3       0             0  2.409742  95.123209  0.0  45.0  10.39255  0.0   \n",
       "4       1             0  2.409742  95.123209  0.0  45.0  10.39255  0.0   \n",
       "..    ...           ...       ...        ...  ...   ...       ...  ...   \n",
       "305     5             2  2.000000  91.000000  0.0  45.0  10.00000  0.0   \n",
       "306     4             2  2.000000  96.000000  0.0  45.0  11.00000  0.0   \n",
       "307     5             2  2.000000  91.000000  0.0  45.0  10.00000  0.0   \n",
       "308     5             2  2.000000  95.000000  0.0  45.0  10.00000  0.0   \n",
       "309     5             2  2.000000  87.000000  0.0  45.0  10.00000  0.0   \n",
       "\n",
       "           X_7        X_8  ...   X_2866   X_2867   X_2868   X_2869   X_2870  \\\n",
       "0    51.000000  10.000000  ...  50.8073  53.6077  49.6062  51.6598  66.6497   \n",
       "1    45.000000  10.000000  ...  50.8073  53.6077  49.6062  51.6598  66.6497   \n",
       "2    45.000000  10.000000  ...  50.8073  53.6077  49.6062  51.6598  66.6497   \n",
       "3    48.802292  10.048711  ...  50.8073  53.6077  49.6062  51.6598  66.6497   \n",
       "4    48.802292  10.048711  ...  50.8073  53.6077  49.6062  51.6598  66.6497   \n",
       "..         ...        ...  ...      ...      ...      ...      ...      ...   \n",
       "305  51.000000  10.000000  ...  50.8073  53.6077  49.6062  51.6598  66.6497   \n",
       "306  45.000000  10.000000  ...  50.8073  53.6077  49.6062  51.6598  66.6497   \n",
       "307  50.000000  10.000000  ...  50.8073  53.6077  49.6062  51.6598  66.6497   \n",
       "308  51.000000  10.000000  ...  50.8073  53.6077  49.6062  51.6598  66.6497   \n",
       "309  51.000000  10.000000  ...  50.8073  53.6077  49.6062  51.6598  66.6497   \n",
       "\n",
       "     X_2871  X_2872  X_2873  X_2874  X_2875  \n",
       "0       1.0     0.0     0.0     0.0     0.0  \n",
       "1       1.0     0.0     0.0     0.0     0.0  \n",
       "2       1.0     0.0     0.0     0.0     0.0  \n",
       "3       1.0     0.0     0.0     0.0     0.0  \n",
       "4       1.0     0.0     0.0     0.0     0.0  \n",
       "..      ...     ...     ...     ...     ...  \n",
       "305     1.0     0.0     0.0     0.0     0.0  \n",
       "306     1.0     0.0     0.0     0.0     0.0  \n",
       "307     1.0     0.0     0.0     0.0     0.0  \n",
       "308     1.0     0.0     0.0     0.0     0.0  \n",
       "309     1.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[310 rows x 2877 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55a73f6",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e960f3f1",
   "metadata": {},
   "source": [
    "1.모델 선택 - sklearn라이브러리 활용 - RandomForest \n",
    "\n",
    "2.모델 학습 - train_df를 활용하여 1번에서 정의한 모델로 학습\n",
    "\n",
    "3.예측 - 학습된 모델을 바탕으로 test 데이터를 예측\n",
    "\n",
    "4.정답 파일 생성 - 정답 파일 생성 및 제출 필요(경진대회를 위해 필요한 과정.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3c2495",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a5a08131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "Adab_clf = AdaBoostClassifier(n_estimators=1, \n",
    "                        random_state=37, \n",
    "                        learning_rate=0.005)\n",
    "Adab_clf.fit(train_x, train_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d08136",
   "metadata": {},
   "source": [
    "### GridSearchCV 파라미터 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c9a2dfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 35 candidates, totalling 70 fits\n",
      "최적 하이퍼 파라미터: \n",
      " {'learning_rate': 0.005, 'n_estimators': 1}\n",
      "최고 예측 정확도: 0.6438\n"
     ]
    }
   ],
   "source": [
    "#Adaboost 파라미터 최적화를 위한 GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param = {\n",
    "    'n_estimators' : [1,2,3,4,5,10,20],\n",
    "    'learning_rate' : [0.005, 0.01,0.015, 0.02,0.03]\n",
    "}\n",
    "\n",
    "grid_cv = GridSearchCV(Adab_clf, param_grid=param, cv=2, verbose=1, n_jobs=-1)\n",
    "grid_cv.fit(train_x, train_y.values)\n",
    "preds = grid_cv.predict(test_x)\n",
    "submission['Y_Class'] = preds\n",
    "submission.to_csv('./t11_adaboost.csv', index=False)\n",
    "print('최적 하이퍼 파라미터: \\n', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2abe8c",
   "metadata": {},
   "source": [
    "# GBM gradient boosting machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91036c20",
   "metadata": {},
   "source": [
    "### default 파라미터 값으로 모델 학습 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6d4a575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GBM Gradient Boosting Machine\n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "\n",
    "# 예시 데이터셋 불러오기\n",
    "GBM_clf = GradientBoostingClassifier(random_state=37)\n",
    "GBM_clf.fit(train_x, train_y.values)\n",
    "preds = GBM_clf.predict(test_x)\n",
    "submission['Y_Class'] == preds\n",
    "submission.to_csv('./t11_GBM_defualt.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c4cc21",
   "metadata": {},
   "source": [
    "### RamdomSearchCV 파라미터 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "3b5c5109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78333333 0.79166667 0.78333333 0.78991597 0.76470588]\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "최적 하이퍼 파라미터: {'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 157}\n",
      "최고 예측 정확도: 41.3178\n",
      "time elapsed: 1106.4138910770416\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "\n",
    "param_distribs = {\n",
    "    'n_estimators' : randint(low=1, high=200),\n",
    "    #'learning_rate' : randint(low=0.01, high=0.1),\n",
    "    'min_samples_split': randint(low = 1, high = 10),\n",
    "    'min_samples_leaf': randint(low = 1, high = 17)\n",
    "}\n",
    "\n",
    "GBM= GradientBoostingClassifier(random_state=37)\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=37)\n",
    "results = cross_val_score(GBM, train_x, train_y, cv=kfold)\n",
    "print(results)\n",
    "start = time.time()\n",
    "rand_cv = RandomizedSearchCV(GBM, \n",
    "                            param_distributions=param_distribs,\n",
    "                            cv = 5, \n",
    "                            n_iter = 50,\n",
    "                            scoring = 'f1_macro',\n",
    "                            n_jobs = -1,\n",
    "                            verbose=3)\n",
    "rand_cv.fit(train_x, train_y)\n",
    "preds = rand_cv.predict(test_x)\n",
    "end = time.time()\n",
    "sub3['Y_Class'] = preds\n",
    "sub3.to_csv('./t10_GBM_RandomSearchCV_niter15_dpo-1000_niter50.csv', index=False)\n",
    "\n",
    "print(f'최적 하이퍼 파라미터: {rand_cv.best_params_}')\n",
    "print(f'최고 예측 정확도: {(rand_cv.best_score_)*100:.4f}')\n",
    "print(f'time elapsed: {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "94ea32af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GBMrandom60</th>\n",
       "      <th>Y_Class0</th>\n",
       "      <th>GBMrandom64</th>\n",
       "      <th>Y_Class1</th>\n",
       "      <th>GBMrandomf-1000</th>\n",
       "      <th>Y_Class4</th>\n",
       "      <th>GBMrandomf-100</th>\n",
       "      <th>Y_Class7</th>\n",
       "      <th>XGBrandomf-100</th>\n",
       "      <th>Y_Class8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_000</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_000</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_000</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_001</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_001</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_001</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_002</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_002</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_002</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_003</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_003</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_003</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_004</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_004</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_004</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>TEST_305</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_305</td>\n",
       "      <td>2</td>\n",
       "      <td>TEST_305</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_305</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_305</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>TEST_306</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_306</td>\n",
       "      <td>2</td>\n",
       "      <td>TEST_306</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_306</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>TEST_307</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_307</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_307</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_307</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_307</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>TEST_308</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_308</td>\n",
       "      <td>2</td>\n",
       "      <td>TEST_308</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_308</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_308</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>TEST_309</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_309</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_309</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_309</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    GBMrandom60  Y_Class0 GBMrandom64  Y_Class1 GBMrandomf-1000  Y_Class4  \\\n",
       "0      TEST_000         1    TEST_000         1        TEST_000         1   \n",
       "1      TEST_001         1    TEST_001         1        TEST_001         1   \n",
       "2      TEST_002         1    TEST_002         1        TEST_002         1   \n",
       "3      TEST_003         1    TEST_003         1        TEST_003         1   \n",
       "4      TEST_004         1    TEST_004         0        TEST_004         1   \n",
       "..          ...       ...         ...       ...             ...       ...   \n",
       "305    TEST_305         1    TEST_305         2        TEST_305         1   \n",
       "306    TEST_306         1    TEST_306         2        TEST_306         0   \n",
       "307    TEST_307         1    TEST_307         1        TEST_307         1   \n",
       "308    TEST_308         1    TEST_308         2        TEST_308         1   \n",
       "309    TEST_309         1    TEST_309         1        TEST_309         1   \n",
       "\n",
       "    GBMrandomf-100  Y_Class7 XGBrandomf-100  Y_Class8  \n",
       "0         TEST_000         1       TEST_000         1  \n",
       "1         TEST_001         1       TEST_001         1  \n",
       "2         TEST_002         1       TEST_002         1  \n",
       "3         TEST_003         1       TEST_003         1  \n",
       "4         TEST_004         1       TEST_004         1  \n",
       "..             ...       ...            ...       ...  \n",
       "305       TEST_305         1       TEST_305         1  \n",
       "306       TEST_306         1       TEST_306         1  \n",
       "307       TEST_307         1       TEST_307         1  \n",
       "308       TEST_308         1       TEST_308         1  \n",
       "309       TEST_309         1       TEST_309         1  \n",
       "\n",
       "[310 rows x 10 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub0 = pd.read_csv('./t10_GBM_RandomSearchCV.csv')\n",
    "sub1 = pd.read_csv('./t10_GBM_RandomSearchCV_niter50.csv')\n",
    "sub2 = pd.read_csv('./t10_GBM_RandomSearchCV_niter50_re.csv')\n",
    "# sub3 = pd.read_csv('./t14_GBM_RandomSearchCV_niter50_dpo.csv') #결과가 다 1로 나옴\n",
    "sub4 = pd.read_csv('./t10_GBM_RandomSearchCV_niter50_dpo-1000.csv') #그냥 모든 결측치 -1000로 채우기\n",
    "# sub5 = pd.read_csv('./t15_GBM_RandomSearchCV_niter50_dpo2-1000.csv') #모든행 결측치 -1000 나머지는 평균값 채우기\n",
    "# sub6 = pd.read_csv('./t15_GBM_RandomSearchCV_niter50_dpo3-1000.csv')# 모든 결측치-1000으로 채우기\n",
    "sub7 = pd.read_csv('./t15_XGBoost_RandomSearchCV_niter50_dpo4-100.csv')\n",
    "sub8 = pd.read_csv('./t15_GBMXGBVotingsoft_RandomSearchCV_niter50_dpo4-100.csv')\n",
    "# sub9 = pd.read_csv()\n",
    "sub = pd.concat([sub0, sub1, sub4, sub7, sub8], axis = 1)\n",
    "sub.columns = ['GBMrandom60', 'Y_Class0', 'GBMrandom64', 'Y_Class1', 'GBMrandomf-1000', 'Y_Class4', \n",
    "               'GBMrandomf-100', 'Y_Class7', 'XGBrandomf-100', 'Y_Class8']\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "349903ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>310.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.883871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.376577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Y_Class\n",
       "count  310.000000\n",
       "mean     0.883871\n",
       "std      0.376577\n",
       "min      0.000000\n",
       "25%      1.000000\n",
       "50%      1.000000\n",
       "75%      1.000000\n",
       "max      2.000000"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub8.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cc9234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "63e2c79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GBMrandom60</th>\n",
       "      <th>Y_Class0</th>\n",
       "      <th>GBMrandom64</th>\n",
       "      <th>Y_Class1</th>\n",
       "      <th>GBMrandomf-1000</th>\n",
       "      <th>Y_Class4</th>\n",
       "      <th>GBMrandomf-100</th>\n",
       "      <th>Y_Class7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>TEST_020</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_020</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_020</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TEST_021</td>\n",
       "      <td>2</td>\n",
       "      <td>TEST_021</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_021</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>TEST_022</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_022</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_022</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>TEST_023</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_023</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_023</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>TEST_024</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_024</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_024</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TEST_025</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_025</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_025</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>TEST_026</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_026</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_026</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_026</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TEST_027</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_027</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_027</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_027</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>TEST_028</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_028</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_028</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>TEST_029</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_029</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_029</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>TEST_030</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_030</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_030</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_030</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>TEST_031</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_031</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_031</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>TEST_032</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_032</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_032</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>TEST_033</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_033</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_033</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_033</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>TEST_034</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_034</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_034</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_034</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>TEST_035</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_035</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_035</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>TEST_036</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_036</td>\n",
       "      <td>2</td>\n",
       "      <td>TEST_036</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_036</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TEST_037</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_037</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_037</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_037</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>TEST_038</td>\n",
       "      <td>2</td>\n",
       "      <td>TEST_038</td>\n",
       "      <td>2</td>\n",
       "      <td>TEST_038</td>\n",
       "      <td>2</td>\n",
       "      <td>TEST_038</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>TEST_039</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_039</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_039</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GBMrandom60  Y_Class0 GBMrandom64  Y_Class1 GBMrandomf-1000  Y_Class4  \\\n",
       "20    TEST_020         1    TEST_020         1        TEST_020         1   \n",
       "21    TEST_021         2    TEST_021         1        TEST_021         1   \n",
       "22    TEST_022         1    TEST_022         1        TEST_022         1   \n",
       "23    TEST_023         1    TEST_023         1        TEST_023         1   \n",
       "24    TEST_024         1    TEST_024         1        TEST_024         1   \n",
       "25    TEST_025         1    TEST_025         1        TEST_025         1   \n",
       "26    TEST_026         1    TEST_026         1        TEST_026         1   \n",
       "27    TEST_027         1    TEST_027         1        TEST_027         1   \n",
       "28    TEST_028         1    TEST_028         1        TEST_028         1   \n",
       "29    TEST_029         1    TEST_029         1        TEST_029         1   \n",
       "30    TEST_030         1    TEST_030         1        TEST_030         1   \n",
       "31    TEST_031         1    TEST_031         1        TEST_031         1   \n",
       "32    TEST_032         1    TEST_032         1        TEST_032         1   \n",
       "33    TEST_033         1    TEST_033         1        TEST_033         1   \n",
       "34    TEST_034         1    TEST_034         1        TEST_034         1   \n",
       "35    TEST_035         0    TEST_035         0        TEST_035         0   \n",
       "36    TEST_036         0    TEST_036         2        TEST_036         0   \n",
       "37    TEST_037         0    TEST_037         0        TEST_037         0   \n",
       "38    TEST_038         2    TEST_038         2        TEST_038         2   \n",
       "39    TEST_039         0    TEST_039         0        TEST_039         0   \n",
       "\n",
       "   GBMrandomf-100  Y_Class7  \n",
       "20       TEST_020         1  \n",
       "21       TEST_021         1  \n",
       "22       TEST_022         1  \n",
       "23       TEST_023         1  \n",
       "24       TEST_024         1  \n",
       "25       TEST_025         1  \n",
       "26       TEST_026         1  \n",
       "27       TEST_027         1  \n",
       "28       TEST_028         1  \n",
       "29       TEST_029         1  \n",
       "30       TEST_030         1  \n",
       "31       TEST_031         1  \n",
       "32       TEST_032         1  \n",
       "33       TEST_033         1  \n",
       "34       TEST_034         1  \n",
       "35       TEST_035         0  \n",
       "36       TEST_036         2  \n",
       "37       TEST_037         1  \n",
       "38       TEST_038         1  \n",
       "39       TEST_039         1  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.iloc[20:40, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "c9a6f30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>310.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.016129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.363903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Y_Class\n",
       "count  310.000000\n",
       "mean     1.016129\n",
       "std      0.363903\n",
       "min      0.000000\n",
       "25%      1.000000\n",
       "50%      1.000000\n",
       "75%      1.000000\n",
       "max      2.000000"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub7.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f734f97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>Y_Class</th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>Y_Class</th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>Y_Class</th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>Y_Class</th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>Y_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>TEST_040</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_040</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_040</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_040</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_040</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TEST_041</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_041</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_041</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_041</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_041</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>TEST_042</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_042</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_042</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_042</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_042</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>TEST_043</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_043</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_043</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_043</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_043</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>TEST_044</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_044</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_044</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_044</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>TEST_045</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_045</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_045</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_045</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_045</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>TEST_046</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_046</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_046</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_046</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_046</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>TEST_047</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_047</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_047</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_047</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_047</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>TEST_048</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_048</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_048</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_048</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_048</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>TEST_049</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_049</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_049</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_049</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_049</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>TEST_050</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_050</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_050</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_050</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>TEST_051</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_051</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_051</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_051</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_051</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>TEST_052</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_052</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_052</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_052</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_052</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>TEST_053</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_053</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_053</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_053</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_053</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>TEST_054</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_054</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_054</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_054</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_054</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>TEST_055</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_055</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_055</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_055</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_055</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>TEST_056</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_056</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_056</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_056</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_056</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>TEST_057</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_057</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_057</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_057</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_057</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>TEST_058</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_058</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_058</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_058</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_058</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>TEST_059</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_059</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_059</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_059</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_059</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PRODUCT_ID  Y_Class PRODUCT_ID  Y_Class PRODUCT_ID  Y_Class PRODUCT_ID  \\\n",
       "40   TEST_040        0   TEST_040        0   TEST_040        0   TEST_040   \n",
       "41   TEST_041        0   TEST_041        0   TEST_041        0   TEST_041   \n",
       "42   TEST_042        0   TEST_042        0   TEST_042        0   TEST_042   \n",
       "43   TEST_043        1   TEST_043        0   TEST_043        1   TEST_043   \n",
       "44   TEST_044        1   TEST_044        0   TEST_044        0   TEST_044   \n",
       "45   TEST_045        1   TEST_045        1   TEST_045        1   TEST_045   \n",
       "46   TEST_046        1   TEST_046        0   TEST_046        1   TEST_046   \n",
       "47   TEST_047        1   TEST_047        0   TEST_047        1   TEST_047   \n",
       "48   TEST_048        1   TEST_048        1   TEST_048        1   TEST_048   \n",
       "49   TEST_049        1   TEST_049        0   TEST_049        1   TEST_049   \n",
       "50   TEST_050        1   TEST_050        1   TEST_050        1   TEST_050   \n",
       "51   TEST_051        1   TEST_051        0   TEST_051        1   TEST_051   \n",
       "52   TEST_052        0   TEST_052        0   TEST_052        0   TEST_052   \n",
       "53   TEST_053        0   TEST_053        0   TEST_053        1   TEST_053   \n",
       "54   TEST_054        0   TEST_054        0   TEST_054        1   TEST_054   \n",
       "55   TEST_055        1   TEST_055        0   TEST_055        1   TEST_055   \n",
       "56   TEST_056        1   TEST_056        0   TEST_056        1   TEST_056   \n",
       "57   TEST_057        1   TEST_057        0   TEST_057        1   TEST_057   \n",
       "58   TEST_058        1   TEST_058        0   TEST_058        0   TEST_058   \n",
       "59   TEST_059        1   TEST_059        0   TEST_059        0   TEST_059   \n",
       "\n",
       "    Y_Class PRODUCT_ID  Y_Class  \n",
       "40        1   TEST_040        0  \n",
       "41        1   TEST_041        0  \n",
       "42        1   TEST_042        0  \n",
       "43        1   TEST_043        1  \n",
       "44        1   TEST_044        0  \n",
       "45        1   TEST_045        1  \n",
       "46        1   TEST_046        1  \n",
       "47        1   TEST_047        1  \n",
       "48        1   TEST_048        1  \n",
       "49        1   TEST_049        1  \n",
       "50        1   TEST_050        1  \n",
       "51        1   TEST_051        1  \n",
       "52        1   TEST_052        0  \n",
       "53        1   TEST_053        1  \n",
       "54        1   TEST_054        1  \n",
       "55        1   TEST_055        1  \n",
       "56        1   TEST_056        1  \n",
       "57        1   TEST_057        1  \n",
       "58        1   TEST_058        1  \n",
       "59        1   TEST_059        1  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.iloc[40:60,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ee303c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GBM Gradient Boosting Machine\n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "\n",
    "# 예시 데이터셋 불러오기\n",
    "GBM_clf4 = GradientBoostingClassifier(random_state=37, \n",
    "                                      min_samples_leaf = 16, \n",
    "                                      min_samples_split = 2, \n",
    "                                      n_estimators = 88)\n",
    "GBM_clf4.fit(train_x, train_y.values)\n",
    "preds = GBM_clf4.predict(test_x)\n",
    "submission6 = pd.read_csv('./sample_submission.csv')\n",
    "submission6['Y_Class'] == preds\n",
    "submission6.to_csv('./t11_GBM_grid_refit.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db67155",
   "metadata": {},
   "source": [
    "### GridSearchCV 파라미터 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e8350884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 240 candidates, totalling 480 fits\n",
      "최적 하이퍼 파라미터: \n",
      " {'learning_rate': 0.05, 'min_samples_leaf': 17, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "최고 예측 정확도: 0.6906\n"
     ]
    }
   ],
   "source": [
    "#GBM 파라미터 최적화를 위한 GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param = {\n",
    "    'n_estimators' : [10,20,30,50],\n",
    "    'learning_rate' : [0.01, 0.02, 0.05],\n",
    "    'min_samples_split':[1,2,3,4,8],\n",
    "    'min_samples_leaf':[1,8,16,17]\n",
    "    \n",
    "}\n",
    "GBM_clf3 = GradientBoostingClassifier(random_state=37)\n",
    "\n",
    "grid_cv = GridSearchCV(GBM_clf3, param_grid=param, cv=2, verbose=1, n_jobs=-1)\n",
    "grid_cv.fit(train_x, train_y.values)\n",
    "preds = grid_cv.predict(test_x)\n",
    "submission3['Y_Class'] = preds\n",
    "submission3.to_csv('./t11_GBM_GridSearchCV.csv', index=False)\n",
    "print('최적 하이퍼 파라미터: \\n', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435b1a66",
   "metadata": {},
   "source": [
    "### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "aea8f083",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bayesian-optimization\n",
      "  Downloading bayesian_optimization-1.4.2-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages (from bayesian-optimization) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in /Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages (from bayesian-optimization) (1.0.2)\n",
      "Collecting colorama>=0.4.6\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages (from bayesian-optimization) (1.21.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.1.0)\n",
      "Installing collected packages: colorama, bayesian-optimization\n",
      "Successfully installed bayesian-optimization-1.4.2 colorama-0.4.6\n"
     ]
    }
   ],
   "source": [
    "import sys   \n",
    "!{sys.executable} -m pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c7211b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | n_esti... | subsample |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.975    \u001b[0m | \u001b[0m2.889    \u001b[0m | \u001b[0m62.49    \u001b[0m | \u001b[0m0.5964   \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.9417   \u001b[0m | \u001b[0m2.164    \u001b[0m | \u001b[0m73.41    \u001b[0m | \u001b[0m0.8421   \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.8917   \u001b[0m | \u001b[0m1.207    \u001b[0m | \u001b[0m82.18    \u001b[0m | \u001b[0m0.641    \u001b[0m |\n",
      "| \u001b[95m4        \u001b[0m | \u001b[95m0.9917   \u001b[0m | \u001b[95m2.507    \u001b[0m | \u001b[95m85.49    \u001b[0m | \u001b[95m0.8137   \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.9417   \u001b[0m | \u001b[0m1.887    \u001b[0m | \u001b[0m97.44    \u001b[0m | \u001b[0m0.9485   \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.9417   \u001b[0m | \u001b[0m2.972    \u001b[0m | \u001b[0m33.21    \u001b[0m | \u001b[0m0.8043   \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.9333   \u001b[0m | \u001b[0m2.837    \u001b[0m | \u001b[0m59.74    \u001b[0m | \u001b[0m0.6364   \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.9      \u001b[0m | \u001b[0m1.779    \u001b[0m | \u001b[0m73.77    \u001b[0m | \u001b[0m0.9963   \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.9417   \u001b[0m | \u001b[0m2.778    \u001b[0m | \u001b[0m38.93    \u001b[0m | \u001b[0m0.7149   \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.9333   \u001b[0m | \u001b[0m2.948    \u001b[0m | \u001b[0m62.54    \u001b[0m | \u001b[0m0.6005   \u001b[0m |\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "gbm_parameter_bounds = {\n",
    "                      'n_estimators' : (30,100),\n",
    "                      'max_depth' : (1,3), # 나무의 깊이\n",
    "                      'subsample' : (0.5,1)\n",
    "                      }\n",
    " \n",
    " \n",
    "def gbm_bo(n_estimators, max_depth, subsample):\n",
    "\n",
    "    gbm_params = {\n",
    "              'n_estimators' : int(round(n_estimators)),\n",
    "              'max_depth' : int(round(max_depth)),\n",
    "               'subsample' : int(round(subsample)),      \n",
    "              }\n",
    "\n",
    "    gbm = GradientBoostingClassifier(**gbm_params)\n",
    "    train_xx, valid_x, train_yy, valid_y = train_test_split(train_x, train_y, test_size = 0.2)\n",
    "    gbm.fit(train_x,train_y)\n",
    "\n",
    "    score = accuracy_score(valid_y, gbm.predict(valid_x))\n",
    "\n",
    "    return score\n",
    " \n",
    "BO_gbm = BayesianOptimization(f = gbm_bo, pbounds = gbm_parameter_bounds, random_state = 37)\n",
    " \n",
    "BO_gbm.maximize(init_points = 5, n_iter = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5657728f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | n_esti... | subsample |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.9524   \u001b[0m | \u001b[0m2.889    \u001b[0m | \u001b[0m62.49    \u001b[0m | \u001b[0m0.5964   \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.9256   \u001b[0m | \u001b[0m2.164    \u001b[0m | \u001b[0m73.41    \u001b[0m | \u001b[0m0.8421   \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.8747   \u001b[0m | \u001b[0m1.207    \u001b[0m | \u001b[0m82.18    \u001b[0m | \u001b[0m0.641    \u001b[0m |\n",
      "| \u001b[95m4        \u001b[0m | \u001b[95m0.9552   \u001b[0m | \u001b[95m2.507    \u001b[0m | \u001b[95m85.49    \u001b[0m | \u001b[95m0.8137   \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.9466   \u001b[0m | \u001b[0m1.887    \u001b[0m | \u001b[0m97.44    \u001b[0m | \u001b[0m0.9485   \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.8841   \u001b[0m | \u001b[0m2.972    \u001b[0m | \u001b[0m33.21    \u001b[0m | \u001b[0m0.8043   \u001b[0m |\n",
      "| \u001b[95m7        \u001b[0m | \u001b[95m0.9662   \u001b[0m | \u001b[95m2.837    \u001b[0m | \u001b[95m59.74    \u001b[0m | \u001b[95m0.6364   \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.8973   \u001b[0m | \u001b[0m1.605    \u001b[0m | \u001b[0m60.82    \u001b[0m | \u001b[0m0.535    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.8932   \u001b[0m | \u001b[0m2.778    \u001b[0m | \u001b[0m38.93    \u001b[0m | \u001b[0m0.7149   \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.9628   \u001b[0m | \u001b[0m2.828    \u001b[0m | \u001b[0m59.79    \u001b[0m | \u001b[0m0.6291   \u001b[0m |\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "gbm_parameter_bounds = {\n",
    "                      'n_estimators' : (30,100),\n",
    "                      'max_depth' : (1,3), # 나무의 깊이\n",
    "                      'subsample' : (0.5,1)\n",
    "                      }\n",
    "\n",
    " \n",
    "def gbm_bo(n_estimators, max_depth, subsample):\n",
    "    \n",
    "\n",
    "    gbm_params = {\n",
    "              'n_estimators' : int(round(n_estimators)),\n",
    "              'max_depth' : int(round(max_depth)),\n",
    "               'subsample' : int(round(subsample)),      \n",
    "              }\n",
    "\n",
    "    gbm = GradientBoostingClassifier(**gbm_params)\n",
    "    train_xx, valid_x, train_yy, valid_y = train_test_split(train_x, train_y, test_size = 0.2)\n",
    "    gbm.fit(train_x,train_y)\n",
    "\n",
    "    score = f1_score(valid_y, gbm.predict(valid_x), average = 'macro')\n",
    "\n",
    "    return score\n",
    " \n",
    "BO_gbm = BayesianOptimization(f = gbm_bo, pbounds = gbm_parameter_bounds, random_state = 37)\n",
    " \n",
    "BO_gbm.maximize(init_points = 5, n_iter = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62693e7e",
   "metadata": {},
   "source": [
    "### Bayesian Optimization으로 최적화한 파라미터로 학습 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e4f5702e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy acore\n",
    "gbm_tune = GradientBoostingClassifier(random_state = 37, max_depth = 3, n_estimators = 85, subsample = 0.8137)\n",
    "\n",
    "gbm_tune.fit(train_x,train_y)\n",
    "preds = gbm_tune.predict(test_x)\n",
    "submission5['Y_Class']==preds\n",
    "submission5.to_csv('./t11_GBM_BayesianOptimization.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b687e523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#macro_f1_score\n",
    "gbm_tune_macrof1 = GradientBoostingClassifier(random_state = 37, max_depth = 3, n_estimators = 60, subsample = 0.6364)\n",
    "\n",
    "gbm_tune_macrof1.fit(train_x,train_y)\n",
    "preds = gbm_tune_macrof1.predict(test_x)\n",
    "submission7 = pd.read_csv('./sample_submission.csv')\n",
    "submission7['Y_Class'] == preds\n",
    "submission7.to_csv('./t11_GBM_bayesian_macro_f1_score.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bcc3cb",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8289c2d8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.6.2-py3-none-macosx_10_15_x86_64.macosx_11_0_x86_64.macosx_12_0_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages (from xgboost) (1.7.3)\n",
      "Requirement already satisfied: numpy in /Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages (from xgboost) (1.21.5)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.6.2\n"
     ]
    }
   ],
   "source": [
    "import sys   \n",
    "!{sys.executable} -m pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "cc91286d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97524023 0.76055276 0.9606851  0.95079786 0.9355792  0.8795549\n",
      " 0.95528793 0.46537116 0.57488114 0.80534035 0.965471   0.9708265\n",
      " 0.88220626 0.03002537 0.01907506 0.9649205  0.95604277 0.9392911\n",
      " 0.9634336  0.8019514  0.98246014 0.8210974  0.8700386  0.9577024\n",
      " 0.9890794  0.99138993 0.6456624  0.91189444 0.86897516 0.52156276\n",
      " 0.9948606  0.981547   0.9819785  0.9711051  0.914436   0.00345837\n",
      " 0.31155488 0.08863046 0.25241718 0.01709741 0.22607182 0.02521303\n",
      " 0.03220967 0.87542164 0.9421753  0.8426447  0.44357598 0.7881315\n",
      " 0.96640676 0.9117605  0.9703321  0.94064844 0.14653385 0.4524743\n",
      " 0.507756   0.97005504 0.9735975  0.97739786 0.90497744 0.96379215\n",
      " 0.9240928  0.5828189  0.01357585 0.00361323 0.00428094 0.0172539\n",
      " 0.37333807 0.9789605  0.9739865  0.85416245 0.9575315  0.23603052\n",
      " 0.38589    0.98211664 0.99259335 0.93764794 0.984728   0.9586333\n",
      " 0.7138484  0.8380824  0.9480742  0.78690207 0.94963205 0.9701517\n",
      " 0.83516604 0.98546046 0.55133325 0.9904743  0.5138626  0.8482526\n",
      " 0.9173515  0.96130323 0.8873601  0.86052054 0.9804914  0.96285903\n",
      " 0.84743756 0.84493905 0.9680113  0.9296645  0.9535166  0.91833687\n",
      " 0.9386371  0.9210298  0.93349224 0.91413707 0.8665748  0.7158062\n",
      " 0.85056216 0.9255698  0.8993548  0.9623932  0.87268037 0.9537048\n",
      " 0.9296145  0.91331524 0.89007133 0.88729703 0.98081964 0.97551876\n",
      " 0.97468907 0.9927114  0.8549225  0.85040206 0.9365182  0.9076699\n",
      " 0.94521827 0.98623264 0.81120133 0.5091917  0.45468685 0.6390063\n",
      " 0.08372732 0.9889206  0.9847343  0.99163777 0.87880856 0.8644156\n",
      " 0.82228607 0.9618578  0.9380445  0.9412702  0.9615334  0.7122868\n",
      " 0.8241061  0.9452461  0.98805606 0.7054897  0.9635797  0.87906325\n",
      " 0.92169076 0.8288489  0.82635075 0.8899901  0.99366117 0.9590975\n",
      " 0.9897698  0.9516205  0.518714   0.88833725 0.41796532 0.3782406\n",
      " 0.93765    0.9444814  0.91719645 0.7921142  0.89461464 0.95202875\n",
      " 0.8002251  0.9562564  0.9678289  0.76524585 0.8630265  0.9940931\n",
      " 0.98742443 0.9561826  0.94056344 0.7991426  0.994007   0.9435188\n",
      " 0.9639849  0.96384907 0.9262437  0.9789667  0.9914404  0.9753084\n",
      " 0.99639136 0.9014081  0.96237767 0.98077285 0.9690336  0.95526916\n",
      " 0.9814077  0.99590683 0.96988374 0.9970547  0.9909021  0.9916586\n",
      " 0.97991747 0.99130905 0.97337794 0.9924138  0.9887135  0.99106324\n",
      " 0.9830142  0.99443495 0.98959315 0.9843694  0.8579384  0.9554811\n",
      " 0.987087   0.9415488  0.9880669  0.9333943  0.96001804 0.9839438\n",
      " 0.92803186 0.97924465 0.8001392  0.9815431  0.9788344  0.9898443\n",
      " 0.9437396  0.98264366 0.9821945  0.9925218  0.99067044 0.99294925\n",
      " 0.95112634 0.97042286 0.98950166 0.99622524 0.9678583  0.99148095\n",
      " 0.99442804 0.98192745 0.98375064 0.9846956  0.9845762  0.9524279\n",
      " 0.9940544  0.99600285 0.9891361  0.9885106  0.99749506 0.99212027\n",
      " 0.98797965 0.99627054 0.46072546 0.1085158  0.12536696 0.1324755\n",
      " 0.17938788 0.07444587 0.05440565 0.56538326 0.99726653 0.99566036\n",
      " 0.9971445  0.9975274  0.19015172 0.9970703  0.99557424 0.6539052\n",
      " 0.9898706  0.9838853  0.9685301  0.9584884  0.9928831  0.91257954\n",
      " 0.98494154 0.98085475 0.92660356 0.96966267 0.9794573  0.92716205\n",
      " 0.98040444 0.9904951  0.98018    0.9499137  0.85626394 0.5908394\n",
      " 0.40585905 0.12762536 0.5814143  0.4075007  0.30216905 0.9636736\n",
      " 0.9882824  0.996552   0.99325585 0.9766649  0.39536497 0.5742923\n",
      " 0.9945675  0.9821493  0.9457172  0.980198   0.8974556  0.9834728\n",
      " 0.9957255  0.9883632  0.9953707  0.9904145  0.9842206  0.9681105\n",
      " 0.9807376  0.99714077 0.95701665 0.99044156]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import plot_importance\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# Train the model\n",
    "xgboost = XGBClassifier(seed=seed_everything).fit(train_x,train_y)\n",
    "# Make prediction\n",
    "preds = xgboost.predict(test_x)\n",
    "\n",
    "# Get predicted probability\n",
    "xgboost_predict_prob = xgboost.predict_proba(test_x)[:,1]\n",
    "print(xgboost_predict_prob)\n",
    "print(xgboost_predict_prob)\n",
    "# submission6['Y_Class'] = preds\n",
    "# submission6.to_csv('./t10_XGBoost.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "2eb4813e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247\n",
      "[23:32:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END alpha=5, colsample_bytree=0, eta=0, gamma=3, lambda=3, max_depth=9, min_child_weight=4, num_boost_around=14, sub_sample=0;, score=0.321 total time=   2.6s\n",
      "[23:32:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END alpha=9, colsample_bytree=0, eta=0, gamma=6, lambda=5, max_depth=6, min_child_weight=4, num_boost_around=11, sub_sample=0;, score=0.397 total time=   2.6s\n",
      "[23:32:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END alpha=4, colsample_bytree=0, eta=0, gamma=4, lambda=8, max_depth=6, min_child_weight=7, num_boost_around=11, sub_sample=0;, score=0.294 total time=   2.8s\n",
      "[23:32:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END alpha=3, colsample_bytree=0, eta=0, gamma=2, lambda=4, max_depth=9, min_child_weight=5, num_boost_around=12, sub_sample=0;, score=0.414 total time=   2.5s\n",
      "[23:32:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END alpha=2, colsample_bytree=0, eta=0, gamma=9, lambda=5, max_depth=9, min_child_weight=1, num_boost_around=15, sub_sample=0;, score=0.294 total time=   2.7s\n",
      "[23:32:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END alpha=7, colsample_bytree=0, eta=0, gamma=6, lambda=4, max_depth=6, min_child_weight=2, num_boost_around=11, sub_sample=0;, score=0.270 total time=   2.6s\n",
      "[23:32:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END alpha=6, colsample_bytree=0, eta=0, gamma=2, lambda=1, max_depth=6, min_child_weight=7, num_boost_around=15, sub_sample=0;, score=0.394 total time=   2.6s\n",
      "[23:32:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END alpha=1, colsample_bytree=0, eta=0, gamma=5, lambda=2, max_depth=6, min_child_weight=3, num_boost_around=18, sub_sample=0;, score=0.329 total time=   2.6s\n",
      "[23:32:59] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END alpha=6, colsample_bytree=0, eta=0, gamma=3, lambda=9, max_depth=9, min_child_weight=9, num_boost_around=16, sub_sample=0;, score=0.321 total time=   2.5s\n",
      "[CV 5/5] END alpha=6, colsample_bytree=0, eta=0, gamma=9, lambda=6, max_depth=9, min_child_weight=6;, score=0.270 total time=   2.5s\n",
      "[CV 2/5] END alpha=1, colsample_bytree=0, eta=0, gamma=7, lambda=4, max_depth=9, min_child_weight=5;, score=0.356 total time=   2.5s\n",
      "[CV 1/5] END alpha=1, colsample_bytree=0, eta=0, gamma=7, lambda=5, max_depth=9, min_child_weight=8;, score=0.297 total time=   2.5s\n",
      "[CV 5/5] END alpha=4, colsample_bytree=0, eta=0, gamma=8, lambda=7, max_depth=9, min_child_weight=2;, score=0.307 total time=   2.6s\n",
      "[CV 2/5] END alpha=3, colsample_bytree=0, eta=0, gamma=6, lambda=6, max_depth=6, min_child_weight=5;, score=0.329 total time=   2.6s\n",
      "[CV 1/5] END alpha=7, colsample_bytree=0, eta=0, gamma=5, lambda=5, max_depth=9, min_child_weight=4;, score=0.516 total time=   2.5s\n",
      "[CV 3/5] END alpha=5, colsample_bytree=0, eta=0, gamma=2, lambda=6, max_depth=6, min_child_weight=3;, score=0.281 total time=   2.5s\n",
      "[CV 5/5] END alpha=9, colsample_bytree=0, eta=0, gamma=9, lambda=1, max_depth=5, min_child_weight=1;, score=0.294 total time=   2.7s\n",
      "[CV 3/5] END alpha=6, colsample_bytree=0, eta=0, gamma=2, lambda=6, max_depth=6, min_child_weight=3;, score=0.281 total time=   2.6s\n",
      "[23:32:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END alpha=5, colsample_bytree=0, eta=0, gamma=3, lambda=3, max_depth=9, min_child_weight=4, num_boost_around=14, sub_sample=0;, score=0.418 total time=   2.6s\n",
      "[23:32:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END alpha=9, colsample_bytree=0, eta=0, gamma=6, lambda=5, max_depth=6, min_child_weight=4, num_boost_around=11, sub_sample=0;, score=0.445 total time=   2.7s\n",
      "[23:32:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END alpha=8, colsample_bytree=0, eta=0, gamma=8, lambda=4, max_depth=6, min_child_weight=7, num_boost_around=12, sub_sample=0;, score=0.271 total time=   2.8s\n",
      "[23:32:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END alpha=3, colsample_bytree=0, eta=0, gamma=2, lambda=4, max_depth=9, min_child_weight=5, num_boost_around=12, sub_sample=0;, score=0.333 total time=   2.5s\n",
      "[23:32:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END alpha=4, colsample_bytree=0, eta=0, gamma=8, lambda=7, max_depth=8, min_child_weight=7, num_boost_around=17, sub_sample=0;, score=0.357 total time=   2.7s\n",
      "[23:32:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END alpha=4, colsample_bytree=0, eta=0, gamma=4, lambda=5, max_depth=5, min_child_weight=7, num_boost_around=15, sub_sample=0;, score=0.414 total time=   2.5s\n",
      "[23:32:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END alpha=6, colsample_bytree=0, eta=0, gamma=2, lambda=1, max_depth=6, min_child_weight=7, num_boost_around=15, sub_sample=0;, score=0.346 total time=   2.6s\n",
      "[23:32:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END alpha=6, colsample_bytree=0, eta=0, gamma=5, lambda=4, max_depth=7, min_child_weight=8, num_boost_around=19, sub_sample=0;, score=0.270 total time=   2.6s\n",
      "[23:32:59] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END alpha=6, colsample_bytree=0, eta=0, gamma=3, lambda=9, max_depth=9, min_child_weight=9, num_boost_around=16, sub_sample=0;, score=0.351 total time=   2.5s\n",
      "[CV 1/5] END alpha=6, colsample_bytree=0, eta=0, gamma=9, lambda=6, max_depth=9, min_child_weight=6;, score=0.271 total time=   2.5s\n",
      "[CV 3/5] END alpha=1, colsample_bytree=0, eta=0, gamma=7, lambda=4, max_depth=9, min_child_weight=5;, score=0.298 total time=   2.4s\n",
      "[CV 5/5] END alpha=2, colsample_bytree=0, eta=0, gamma=6, lambda=7, max_depth=6, min_child_weight=6;, score=0.294 total time=   2.5s\n",
      "[CV 3/5] END alpha=4, colsample_bytree=0, eta=0, gamma=8, lambda=7, max_depth=9, min_child_weight=2;, score=0.269 total time=   2.7s\n",
      "[CV 1/5] END alpha=3, colsample_bytree=0, eta=0, gamma=6, lambda=6, max_depth=6, min_child_weight=5;, score=0.297 total time=   2.6s\n",
      "[CV 4/5] END alpha=4, colsample_bytree=0, eta=0, gamma=9, lambda=1, max_depth=7, min_child_weight=2;, score=0.270 total time=   2.5s\n",
      "[CV 2/5] END alpha=5, colsample_bytree=0, eta=0, gamma=2, lambda=6, max_depth=6, min_child_weight=3;, score=0.368 total time=   2.5s\n",
      "[CV 1/5] END alpha=5, colsample_bytree=0, eta=0, gamma=3, lambda=1, max_depth=6, min_child_weight=2;, score=0.471 total time=   2.7s\n",
      "[CV 4/5] END alpha=6, colsample_bytree=0, eta=0, gamma=2, lambda=6, max_depth=6, min_child_weight=3;, score=0.356 total time=   2.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:32:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END alpha=5, colsample_bytree=0, eta=0, gamma=3, lambda=3, max_depth=9, min_child_weight=4, num_boost_around=14, sub_sample=0;, score=0.464 total time=   2.6s\n",
      "[23:32:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END alpha=9, colsample_bytree=0, eta=0, gamma=6, lambda=5, max_depth=6, min_child_weight=4, num_boost_around=11, sub_sample=0;, score=0.270 total time=   2.7s\n",
      "[23:32:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END alpha=8, colsample_bytree=0, eta=0, gamma=8, lambda=4, max_depth=6, min_child_weight=7, num_boost_around=12, sub_sample=0;, score=0.270 total time=   2.8s\n",
      "[23:32:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END alpha=2, colsample_bytree=0, eta=0, gamma=9, lambda=5, max_depth=9, min_child_weight=1, num_boost_around=15, sub_sample=0;, score=0.271 total time=   2.5s\n",
      "[23:32:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END alpha=4, colsample_bytree=0, eta=0, gamma=8, lambda=7, max_depth=8, min_child_weight=7, num_boost_around=17, sub_sample=0;, score=0.270 total time=   2.8s\n",
      "[23:32:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END alpha=4, colsample_bytree=0, eta=0, gamma=4, lambda=5, max_depth=5, min_child_weight=7, num_boost_around=15, sub_sample=0;, score=0.351 total time=   2.5s\n",
      "[23:32:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END alpha=6, colsample_bytree=0, eta=0, gamma=2, lambda=1, max_depth=6, min_child_weight=7, num_boost_around=15, sub_sample=0;, score=0.321 total time=   2.6s\n",
      "[23:32:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END alpha=1, colsample_bytree=0, eta=0, gamma=5, lambda=2, max_depth=6, min_child_weight=3, num_boost_around=18, sub_sample=0;, score=0.356 total time=   2.7s\n",
      "[23:32:59] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END alpha=8, colsample_bytree=0, eta=0, gamma=6, lambda=6, max_depth=6, min_child_weight=6, num_boost_around=12, sub_sample=0;, score=0.297 total time=   2.5s\n",
      "[CV 3/5] END alpha=6, colsample_bytree=0, eta=0, gamma=9, lambda=6, max_depth=9, min_child_weight=6;, score=0.300 total time=   2.5s\n",
      "[CV 1/5] END alpha=2, colsample_bytree=0, eta=0, gamma=6, lambda=7, max_depth=6, min_child_weight=6;, score=0.297 total time=   2.5s\n",
      "[CV 3/5] END alpha=1, colsample_bytree=0, eta=0, gamma=7, lambda=5, max_depth=9, min_child_weight=8;, score=0.297 total time=   2.5s\n",
      "[CV 1/5] END alpha=8, colsample_bytree=0, eta=0, gamma=1, lambda=3, max_depth=5, min_child_weight=7;, score=0.432 total time=   2.6s\n",
      "[CV 3/5] END alpha=3, colsample_bytree=0, eta=0, gamma=6, lambda=6, max_depth=6, min_child_weight=5;, score=0.411 total time=   2.6s\n",
      "[CV 2/5] END alpha=7, colsample_bytree=0, eta=0, gamma=5, lambda=5, max_depth=9, min_child_weight=4;, score=0.329 total time=   2.5s\n",
      "[CV 5/5] END alpha=5, colsample_bytree=0, eta=0, gamma=2, lambda=6, max_depth=6, min_child_weight=3;, score=0.361 total time=   2.5s\n",
      "[CV 2/5] END alpha=5, colsample_bytree=0, eta=0, gamma=3, lambda=1, max_depth=6, min_child_weight=2;, score=0.400 total time=   2.7s\n",
      "[CV 5/5] END alpha=6, colsample_bytree=0, eta=0, gamma=2, lambda=6, max_depth=6, min_child_weight=3;, score=0.361 total time=   2.6s\n",
      "[23:32:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END alpha=8, colsample_bytree=0, eta=0, gamma=8, lambda=7, max_depth=5, min_child_weight=8, num_boost_around=14, sub_sample=0;, score=0.332 total time=   2.6s\n",
      "[23:32:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END alpha=8, colsample_bytree=0, eta=0, gamma=8, lambda=7, max_depth=5, min_child_weight=8, num_boost_around=14, sub_sample=0;, score=0.270 total time=   2.6s\n",
      "[23:32:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END alpha=4, colsample_bytree=0, eta=0, gamma=4, lambda=8, max_depth=6, min_child_weight=7, num_boost_around=11, sub_sample=0;, score=0.382 total time=   2.8s\n",
      "[23:32:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END alpha=3, colsample_bytree=0, eta=0, gamma=2, lambda=4, max_depth=9, min_child_weight=5, num_boost_around=12, sub_sample=0;, score=0.360 total time=   2.6s\n",
      "[23:32:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END alpha=4, colsample_bytree=0, eta=0, gamma=8, lambda=7, max_depth=8, min_child_weight=7, num_boost_around=17, sub_sample=0;, score=0.271 total time=   2.7s\n",
      "[23:32:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END alpha=7, colsample_bytree=0, eta=0, gamma=6, lambda=4, max_depth=6, min_child_weight=2, num_boost_around=11, sub_sample=0;, score=0.400 total time=   2.5s\n",
      "[23:32:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END alpha=6, colsample_bytree=0, eta=0, gamma=2, lambda=1, max_depth=6, min_child_weight=7, num_boost_around=15, sub_sample=0;, score=0.469 total time=   2.6s\n",
      "[23:32:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END alpha=1, colsample_bytree=0, eta=0, gamma=5, lambda=2, max_depth=6, min_child_weight=3, num_boost_around=18, sub_sample=0;, score=0.441 total time=   2.6s\n",
      "[23:32:59] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END alpha=6, colsample_bytree=0, eta=0, gamma=3, lambda=9, max_depth=9, min_child_weight=9, num_boost_around=16, sub_sample=0;, score=0.331 total time=   2.5s\n",
      "[CV 2/5] END alpha=9, colsample_bytree=0, eta=0, gamma=1, lambda=7, max_depth=7, min_child_weight=8;, score=0.351 total time=   2.5s\n",
      "[CV 5/5] END alpha=1, colsample_bytree=0, eta=0, gamma=7, lambda=4, max_depth=9, min_child_weight=5;, score=0.294 total time=   2.5s\n",
      "[CV 2/5] END alpha=1, colsample_bytree=0, eta=0, gamma=7, lambda=5, max_depth=9, min_child_weight=8;, score=0.357 total time=   2.5s\n",
      "[CV 4/5] END alpha=4, colsample_bytree=0, eta=0, gamma=8, lambda=7, max_depth=9, min_child_weight=2;, score=0.270 total time=   2.7s\n",
      "[CV 4/5] END alpha=3, colsample_bytree=0, eta=0, gamma=6, lambda=6, max_depth=6, min_child_weight=5;, score=0.270 total time=   2.6s\n",
      "[CV 5/5] END alpha=4, colsample_bytree=0, eta=0, gamma=9, lambda=1, max_depth=7, min_child_weight=2;, score=0.294 total time=   2.5s\n",
      "[CV 4/5] END alpha=5, colsample_bytree=0, eta=0, gamma=2, lambda=6, max_depth=6, min_child_weight=3;, score=0.356 total time=   2.6s\n",
      "[CV 3/5] END alpha=5, colsample_bytree=0, eta=0, gamma=3, lambda=1, max_depth=6, min_child_weight=2;, score=0.389 total time=   2.7s\n",
      "[CV 1/5] END alpha=8, colsample_bytree=0, eta=0, gamma=8, lambda=2, max_depth=9, min_child_weight=1;, score=0.271 total time=   2.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:32:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END alpha=8, colsample_bytree=0, eta=0, gamma=8, lambda=7, max_depth=5, min_child_weight=8, num_boost_around=14, sub_sample=0;, score=0.271 total time=   2.7s\n",
      "[23:32:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END alpha=4, colsample_bytree=0, eta=0, gamma=4, lambda=8, max_depth=6, min_child_weight=7, num_boost_around=11, sub_sample=0;, score=0.414 total time=   2.7s\n",
      "[23:32:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END alpha=8, colsample_bytree=0, eta=0, gamma=8, lambda=4, max_depth=6, min_child_weight=7, num_boost_around=12, sub_sample=0;, score=0.300 total time=   2.8s\n",
      "[23:32:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END alpha=2, colsample_bytree=0, eta=0, gamma=9, lambda=5, max_depth=9, min_child_weight=1, num_boost_around=15, sub_sample=0;, score=0.323 total time=   2.5s\n",
      "[23:32:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END alpha=4, colsample_bytree=0, eta=0, gamma=8, lambda=7, max_depth=8, min_child_weight=7, num_boost_around=17, sub_sample=0;, score=0.270 total time=   2.8s\n",
      "[23:32:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END alpha=4, colsample_bytree=0, eta=0, gamma=4, lambda=5, max_depth=5, min_child_weight=7, num_boost_around=15, sub_sample=0;, score=0.407 total time=   2.6s\n",
      "[23:32:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END alpha=6, colsample_bytree=0, eta=0, gamma=5, lambda=4, max_depth=7, min_child_weight=8, num_boost_around=19, sub_sample=0;, score=0.328 total time=   2.6s\n",
      "[23:32:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END alpha=1, colsample_bytree=0, eta=0, gamma=5, lambda=2, max_depth=6, min_child_weight=3, num_boost_around=18, sub_sample=0;, score=0.300 total time=   2.7s\n",
      "[23:33:00] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END alpha=8, colsample_bytree=0, eta=0, gamma=6, lambda=6, max_depth=6, min_child_weight=6, num_boost_around=12, sub_sample=0;, score=0.348 total time=   2.5s\n",
      "[CV 3/5] END alpha=9, colsample_bytree=0, eta=0, gamma=1, lambda=7, max_depth=7, min_child_weight=8;, score=0.500 total time=   2.5s\n",
      "[CV 4/5] END alpha=1, colsample_bytree=0, eta=0, gamma=7, lambda=4, max_depth=9, min_child_weight=5;, score=0.270 total time=   2.5s\n",
      "[CV 4/5] END alpha=1, colsample_bytree=0, eta=0, gamma=7, lambda=5, max_depth=9, min_child_weight=8;, score=0.270 total time=   2.5s\n",
      "[CV 2/5] END alpha=8, colsample_bytree=0, eta=0, gamma=1, lambda=3, max_depth=5, min_child_weight=7;, score=0.374 total time=   2.7s\n",
      "[CV 5/5] END alpha=3, colsample_bytree=0, eta=0, gamma=6, lambda=6, max_depth=6, min_child_weight=5;, score=0.294 total time=   2.7s\n",
      "[CV 3/5] END alpha=7, colsample_bytree=0, eta=0, gamma=5, lambda=5, max_depth=9, min_child_weight=4;, score=0.377 total time=   2.5s\n",
      "[CV 1/5] END alpha=9, colsample_bytree=0, eta=0, gamma=9, lambda=1, max_depth=5, min_child_weight=1;, score=0.271 total time=   2.6s\n",
      "[CV 4/5] END alpha=5, colsample_bytree=0, eta=0, gamma=3, lambda=1, max_depth=6, min_child_weight=2;, score=0.329 total time=   2.7s\n",
      "[CV 2/5] END alpha=8, colsample_bytree=0, eta=0, gamma=8, lambda=2, max_depth=9, min_child_weight=1;, score=0.348 total time=   2.6s\n",
      "[23:32:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END alpha=5, colsample_bytree=0, eta=0, gamma=3, lambda=3, max_depth=9, min_child_weight=4, num_boost_around=14, sub_sample=0;, score=0.298 total time=   2.6s\n",
      "[23:32:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END alpha=8, colsample_bytree=0, eta=0, gamma=8, lambda=7, max_depth=5, min_child_weight=8, num_boost_around=14, sub_sample=0;, score=0.270 total time=   2.6s\n",
      "[23:32:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END alpha=4, colsample_bytree=0, eta=0, gamma=4, lambda=8, max_depth=6, min_child_weight=7, num_boost_around=11, sub_sample=0;, score=0.351 total time=   2.8s\n",
      "[23:32:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END alpha=8, colsample_bytree=0, eta=0, gamma=8, lambda=4, max_depth=6, min_child_weight=7, num_boost_around=12, sub_sample=0;, score=0.270 total time=   2.5s\n",
      "[23:32:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END alpha=2, colsample_bytree=0, eta=0, gamma=9, lambda=5, max_depth=9, min_child_weight=1, num_boost_around=15, sub_sample=0;, score=0.381 total time=   2.7s\n",
      "[23:32:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END alpha=7, colsample_bytree=0, eta=0, gamma=6, lambda=4, max_depth=6, min_child_weight=2, num_boost_around=11, sub_sample=0;, score=0.408 total time=   2.6s\n",
      "[23:32:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END alpha=4, colsample_bytree=0, eta=0, gamma=4, lambda=5, max_depth=5, min_child_weight=7, num_boost_around=15, sub_sample=0;, score=0.382 total time=   2.6s\n",
      "[23:32:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END alpha=6, colsample_bytree=0, eta=0, gamma=5, lambda=4, max_depth=7, min_child_weight=8, num_boost_around=19, sub_sample=0;, score=0.352 total time=   2.6s\n",
      "[23:32:59] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END alpha=1, colsample_bytree=0, eta=0, gamma=5, lambda=2, max_depth=6, min_child_weight=3, num_boost_around=18, sub_sample=0;, score=0.294 total time=   2.5s\n",
      "[23:33:02] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END alpha=8, colsample_bytree=0, eta=0, gamma=6, lambda=6, max_depth=6, min_child_weight=6, num_boost_around=12, sub_sample=0;, score=0.464 total time=   1.6s\n",
      "[CV 4/5] END alpha=6, colsample_bytree=0, eta=0, gamma=9, lambda=6, max_depth=9, min_child_weight=6;, score=0.270 total time=   2.5s\n",
      "[CV 4/5] END alpha=9, colsample_bytree=0, eta=0, gamma=1, lambda=7, max_depth=7, min_child_weight=8;, score=0.420 total time=   2.4s\n",
      "[CV 2/5] END alpha=2, colsample_bytree=0, eta=0, gamma=6, lambda=7, max_depth=6, min_child_weight=6;, score=0.348 total time=   2.4s\n",
      "[CV 5/5] END alpha=1, colsample_bytree=0, eta=0, gamma=7, lambda=5, max_depth=9, min_child_weight=8;, score=0.270 total time=   2.6s\n",
      "[CV 3/5] END alpha=8, colsample_bytree=0, eta=0, gamma=1, lambda=3, max_depth=5, min_child_weight=7;, score=0.484 total time=   2.6s\n",
      "[CV 1/5] END alpha=4, colsample_bytree=0, eta=0, gamma=9, lambda=1, max_depth=7, min_child_weight=2;, score=0.271 total time=   2.5s\n",
      "[CV 4/5] END alpha=7, colsample_bytree=0, eta=0, gamma=5, lambda=5, max_depth=9, min_child_weight=4;, score=0.302 total time=   2.5s\n",
      "[CV 2/5] END alpha=9, colsample_bytree=0, eta=0, gamma=9, lambda=1, max_depth=5, min_child_weight=1;, score=0.323 total time=   2.6s\n",
      "[CV 5/5] END alpha=5, colsample_bytree=0, eta=0, gamma=3, lambda=1, max_depth=6, min_child_weight=2;, score=0.321 total time=   2.6s\n",
      "[CV 3/5] END alpha=8, colsample_bytree=0, eta=0, gamma=8, lambda=2, max_depth=9, min_child_weight=1;, score=0.269 total time=   1.6s\n",
      "[23:32:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END alpha=5, colsample_bytree=0, eta=0, gamma=3, lambda=3, max_depth=9, min_child_weight=4, num_boost_around=14, sub_sample=0;, score=0.365 total time=   2.6s\n",
      "[23:32:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END alpha=9, colsample_bytree=0, eta=0, gamma=6, lambda=5, max_depth=6, min_child_weight=4, num_boost_around=11, sub_sample=0;, score=0.346 total time=   2.6s\n",
      "[23:32:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END alpha=4, colsample_bytree=0, eta=0, gamma=4, lambda=8, max_depth=6, min_child_weight=7, num_boost_around=11, sub_sample=0;, score=0.407 total time=   2.7s\n",
      "[23:32:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END alpha=3, colsample_bytree=0, eta=0, gamma=2, lambda=4, max_depth=9, min_child_weight=5, num_boost_around=12, sub_sample=0;, score=0.468 total time=   2.5s\n",
      "[23:32:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END alpha=2, colsample_bytree=0, eta=0, gamma=9, lambda=5, max_depth=9, min_child_weight=1, num_boost_around=15, sub_sample=0;, score=0.270 total time=   2.7s\n",
      "[23:32:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END alpha=7, colsample_bytree=0, eta=0, gamma=6, lambda=4, max_depth=6, min_child_weight=2, num_boost_around=11, sub_sample=0;, score=0.346 total time=   2.6s\n",
      "[23:32:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END alpha=4, colsample_bytree=0, eta=0, gamma=4, lambda=5, max_depth=5, min_child_weight=7, num_boost_around=15, sub_sample=0;, score=0.294 total time=   2.6s\n",
      "[23:32:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END alpha=6, colsample_bytree=0, eta=0, gamma=5, lambda=4, max_depth=7, min_child_weight=8, num_boost_around=19, sub_sample=0;, score=0.435 total time=   2.7s\n",
      "[23:32:59] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END alpha=6, colsample_bytree=0, eta=0, gamma=3, lambda=9, max_depth=9, min_child_weight=9, num_boost_around=16, sub_sample=0;, score=0.370 total time=   2.5s\n",
      "[23:33:02] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END alpha=8, colsample_bytree=0, eta=0, gamma=6, lambda=6, max_depth=6, min_child_weight=6, num_boost_around=12, sub_sample=0;, score=0.270 total time=   1.6s\n",
      "[CV 2/5] END alpha=6, colsample_bytree=0, eta=0, gamma=9, lambda=6, max_depth=9, min_child_weight=6;, score=0.331 total time=   2.5s\n",
      "[CV 5/5] END alpha=9, colsample_bytree=0, eta=0, gamma=1, lambda=7, max_depth=7, min_child_weight=8;, score=0.367 total time=   2.4s\n",
      "[CV 4/5] END alpha=2, colsample_bytree=0, eta=0, gamma=6, lambda=7, max_depth=6, min_child_weight=6;, score=0.270 total time=   2.5s\n",
      "[CV 2/5] END alpha=4, colsample_bytree=0, eta=0, gamma=8, lambda=7, max_depth=9, min_child_weight=2;, score=0.348 total time=   2.6s\n",
      "[CV 4/5] END alpha=8, colsample_bytree=0, eta=0, gamma=1, lambda=3, max_depth=5, min_child_weight=7;, score=0.383 total time=   2.6s\n",
      "[CV 3/5] END alpha=4, colsample_bytree=0, eta=0, gamma=9, lambda=1, max_depth=7, min_child_weight=2;, score=0.381 total time=   2.5s\n",
      "[CV 5/5] END alpha=7, colsample_bytree=0, eta=0, gamma=5, lambda=5, max_depth=9, min_child_weight=4;, score=0.321 total time=   2.5s\n",
      "[CV 3/5] END alpha=9, colsample_bytree=0, eta=0, gamma=9, lambda=1, max_depth=5, min_child_weight=1;, score=0.381 total time=   2.6s\n",
      "[CV 1/5] END alpha=6, colsample_bytree=0, eta=0, gamma=2, lambda=6, max_depth=6, min_child_weight=3;, score=0.476 total time=   2.6s\n",
      "[CV 4/5] END alpha=8, colsample_bytree=0, eta=0, gamma=8, lambda=2, max_depth=9, min_child_weight=1;, score=0.270 total time=   1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:32:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END alpha=8, colsample_bytree=0, eta=0, gamma=8, lambda=7, max_depth=5, min_child_weight=8, num_boost_around=14, sub_sample=0;, score=0.294 total time=   2.7s\n",
      "[23:32:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END alpha=9, colsample_bytree=0, eta=0, gamma=6, lambda=5, max_depth=6, min_child_weight=4, num_boost_around=11, sub_sample=0;, score=0.294 total time=   2.6s\n",
      "[23:32:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END alpha=8, colsample_bytree=0, eta=0, gamma=8, lambda=4, max_depth=6, min_child_weight=7, num_boost_around=12, sub_sample=0;, score=0.357 total time=   2.8s\n",
      "[23:32:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END alpha=3, colsample_bytree=0, eta=0, gamma=2, lambda=4, max_depth=9, min_child_weight=5, num_boost_around=12, sub_sample=0;, score=0.341 total time=   2.5s\n",
      "[23:32:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END alpha=4, colsample_bytree=0, eta=0, gamma=8, lambda=7, max_depth=8, min_child_weight=7, num_boost_around=17, sub_sample=0;, score=0.300 total time=   2.7s\n",
      "[23:32:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END alpha=7, colsample_bytree=0, eta=0, gamma=6, lambda=4, max_depth=6, min_child_weight=2, num_boost_around=11, sub_sample=0;, score=0.294 total time=   2.5s\n",
      "[23:32:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END alpha=6, colsample_bytree=0, eta=0, gamma=2, lambda=1, max_depth=6, min_child_weight=7, num_boost_around=15, sub_sample=0;, score=0.421 total time=   2.6s\n",
      "[23:32:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END alpha=6, colsample_bytree=0, eta=0, gamma=5, lambda=4, max_depth=7, min_child_weight=8, num_boost_around=19, sub_sample=0;, score=0.297 total time=   2.6s\n",
      "[23:32:59] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END alpha=6, colsample_bytree=0, eta=0, gamma=3, lambda=9, max_depth=9, min_child_weight=9, num_boost_around=16, sub_sample=0;, score=0.436 total time=   2.5s\n",
      "[23:33:02] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_around\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END alpha=8, colsample_bytree=0, eta=0, gamma=6, lambda=6, max_depth=6, min_child_weight=6, num_boost_around=12, sub_sample=0;, score=0.294 total time=   1.6s\n",
      "[CV 1/5] END alpha=9, colsample_bytree=0, eta=0, gamma=1, lambda=7, max_depth=7, min_child_weight=8;, score=0.487 total time=   2.5s\n",
      "[CV 1/5] END alpha=1, colsample_bytree=0, eta=0, gamma=7, lambda=4, max_depth=9, min_child_weight=5;, score=0.325 total time=   2.4s\n",
      "[CV 3/5] END alpha=2, colsample_bytree=0, eta=0, gamma=6, lambda=7, max_depth=6, min_child_weight=6;, score=0.464 total time=   2.5s\n",
      "[CV 1/5] END alpha=4, colsample_bytree=0, eta=0, gamma=8, lambda=7, max_depth=9, min_child_weight=2;, score=0.271 total time=   2.7s\n",
      "[CV 5/5] END alpha=8, colsample_bytree=0, eta=0, gamma=1, lambda=3, max_depth=5, min_child_weight=7;, score=0.346 total time=   2.6s\n",
      "[CV 2/5] END alpha=4, colsample_bytree=0, eta=0, gamma=9, lambda=1, max_depth=7, min_child_weight=2;, score=0.323 total time=   2.5s\n",
      "[CV 1/5] END alpha=5, colsample_bytree=0, eta=0, gamma=2, lambda=6, max_depth=6, min_child_weight=3;, score=0.476 total time=   2.5s\n",
      "[CV 4/5] END alpha=9, colsample_bytree=0, eta=0, gamma=9, lambda=1, max_depth=5, min_child_weight=1;, score=0.270 total time=   2.7s\n",
      "[CV 2/5] END alpha=6, colsample_bytree=0, eta=0, gamma=2, lambda=6, max_depth=6, min_child_weight=3;, score=0.368 total time=   2.6s\n",
      "[CV 5/5] END alpha=8, colsample_bytree=0, eta=0, gamma=8, lambda=2, max_depth=9, min_child_weight=1;, score=0.307 total time=   1.6s\n"
     ]
    }
   ],
   "source": [
    "print(len(xgboost_predict_prob[xgboost_predict_prob>0.8]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c06e352",
   "metadata": {},
   "source": [
    "### RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "981887e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "최적 하이퍼 파라미터: {'alpha': 9, 'colsample_bytree': 0, 'eta': 0, 'gamma': 1, 'lambda': 7, 'max_depth': 7, 'min_child_weight': 8}\n",
      "최고 예측 정확도: 42.4913\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distribs = {\n",
    "    'eta' : randint(low=0, high=1),\n",
    "    'min_child_weight': randint(low = 1, high = 10),\n",
    "    'gamma': randint(low = 1, high = 10),\n",
    "    'max_depth': randint(low = 5, high = 10),\n",
    "    'colsample_bytree' : randint(low = 0, high = 1),\n",
    "    'lambda' : randint(low = 1, high = 10),\n",
    "    'alpha' : randint(low = 1, high = 10)\n",
    "}\n",
    "\n",
    "xgboost_r = XGBClassifier(seed=37).fit(train_x,train_y)\n",
    "rand_cv = RandomizedSearchCV(xgboost_r, \n",
    "                            param_distributions=param_distribs,\n",
    "                            cv = 5, \n",
    "                            n_iter = 15,\n",
    "                            scoring = 'f1_macro',\n",
    "                            n_jobs = -1,\n",
    "                            verbose=3)\n",
    "rand_cv.fit(train_x, train_y)\n",
    "preds = rand_cv.predict(test_x)\n",
    "submission8 = pd.read_csv('./sample_submission.csv')\n",
    "submission8['Y_Class'] = preds\n",
    "submission8.to_csv('./t11_XGB_Random_niter15.csv', index=False)\n",
    "\n",
    "print(f'최적 하이퍼 파라미터: {rand_cv.best_params_}')\n",
    "print(f'최고 예측 정확도: {(rand_cv.best_score_)*100:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04488b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235b40dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "\n",
    "import xgboost as xgb \n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train) \n",
    "dtest = xgb.DMatrix(X_test, label=y_test) \n",
    "\n",
    "import xgboost as xgb \n",
    "from sklearn.datasets import dump_svmlight_file \n",
    "\n",
    "dump_svmlight_file(X_train, y_train, 'dtrain.svm', zero_based=True) \n",
    "dump_svmlight_file(X_test, y_test, 'dtest.svm', zero_based=True) \n",
    "dtrain_svm = xgb.DMatrix('dtrain.svm') \n",
    "dtest_svm = xgb.DMatrix('dtest.svm') \n",
    "\n",
    "param = { \n",
    "    'max_depth': 3,  # the maximum depth of each tree \n",
    "    'eta': 0.3,  # the training step for each iteration \n",
    "    'silent': 1,  # logging mode - quiet \n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training \n",
    "    'num_class': 3}  # the number of classes that exist in this datset \n",
    "num_round = 20  # the number of training iterations \n",
    "\n",
    "\"\"\"==================== train ====================\"\"\" \n",
    "\n",
    "\n",
    "bst = xgb.train(param, dtrain, num_round) \n",
    "\n",
    "bst.dump_model('dump.raw.txt') \n",
    "\n",
    "\"\"\"==================== test ====================\"\"\" \n",
    "\n",
    "preds = bst.predict(dtest) \n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7989f085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default_param</th>\n",
       "      <th>Y_Class</th>\n",
       "      <th>RandomSearch</th>\n",
       "      <th>Y_Class</th>\n",
       "      <th>GridSearch</th>\n",
       "      <th>Y_Class</th>\n",
       "      <th>submit</th>\n",
       "      <th>Y_Class</th>\n",
       "      <th>Bayesian</th>\n",
       "      <th>Y_Class</th>\n",
       "      <th>random_refit</th>\n",
       "      <th>Y_Class</th>\n",
       "      <th>bayesian_macrof1</th>\n",
       "      <th>Y_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_000</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_000</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_000</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_000</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_000</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_001</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_001</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_001</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_001</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_001</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_002</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_002</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_002</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_002</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_002</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_003</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_003</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_003</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_003</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_003</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_004</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_004</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_004</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_004</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_004</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TEST_005</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_005</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_005</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_005</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_005</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_005</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TEST_006</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_006</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_006</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_006</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_006</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_006</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TEST_007</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_007</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_007</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_007</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_007</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_007</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TEST_008</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_008</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_008</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_008</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_008</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_008</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEST_009</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_009</td>\n",
       "      <td>2</td>\n",
       "      <td>TEST_009</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_009</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_009</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_009</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  default_param  Y_Class RandomSearch  Y_Class GridSearch  Y_Class    submit  \\\n",
       "0      TEST_000        0     TEST_000        1   TEST_000        1  TEST_000   \n",
       "1      TEST_001        0     TEST_001        1   TEST_001        1  TEST_001   \n",
       "2      TEST_002        0     TEST_002        1   TEST_002        1  TEST_002   \n",
       "3      TEST_003        0     TEST_003        1   TEST_003        1  TEST_003   \n",
       "4      TEST_004        0     TEST_004        1   TEST_004        1  TEST_004   \n",
       "5      TEST_005        0     TEST_005        1   TEST_005        1  TEST_005   \n",
       "6      TEST_006        0     TEST_006        1   TEST_006        1  TEST_006   \n",
       "7      TEST_007        0     TEST_007        1   TEST_007        1  TEST_007   \n",
       "8      TEST_008        0     TEST_008        1   TEST_008        1  TEST_008   \n",
       "9      TEST_009        0     TEST_009        2   TEST_009        1  TEST_009   \n",
       "\n",
       "   Y_Class  Bayesian  Y_Class random_refit  Y_Class bayesian_macrof1  Y_Class  \n",
       "0        1  TEST_000        0     TEST_000        0         TEST_000        0  \n",
       "1        1  TEST_001        0     TEST_001        0         TEST_001        0  \n",
       "2        1  TEST_002        0     TEST_002        0         TEST_002        0  \n",
       "3        1  TEST_003        0     TEST_003        0         TEST_003        0  \n",
       "4        1  TEST_004        0     TEST_004        0         TEST_004        0  \n",
       "5        1  TEST_005        0     TEST_005        0         TEST_005        0  \n",
       "6        1  TEST_006        0     TEST_006        0         TEST_006        0  \n",
       "7        1  TEST_007        0     TEST_007        0         TEST_007        0  \n",
       "8        1  TEST_008        0     TEST_008        0         TEST_008        0  \n",
       "9        1  TEST_009        0     TEST_009        0         TEST_009        0  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_GBM_total = pd.concat([submission, submission2, submission3, submission4, submission5, submission6, submission7], \n",
    "                                 axis = 1) # axis = 1(옆으로 붙이기)\n",
    "submission_GBM_total.columns = ['default_param', 'Y_Class', 'RandomSearch', 'Y_Class', 'GridSearch', 'Y_Class', \n",
    "                                'submit', 'Y_Class', 'Bayesian', 'Y_Class', 'random_refit', 'Y_Class', \n",
    "                                'bayesian_macrof1', 'Y_Class']\n",
    "submission_GBM_total.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fd1bbe34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default_param</th>\n",
       "      <th>Y_Class</th>\n",
       "      <th>RandomSearch</th>\n",
       "      <th>Y_Class</th>\n",
       "      <th>GridSearch</th>\n",
       "      <th>Y_Class</th>\n",
       "      <th>submit</th>\n",
       "      <th>Y_Class</th>\n",
       "      <th>Bayesian</th>\n",
       "      <th>Y_Class</th>\n",
       "      <th>random_refit</th>\n",
       "      <th>Y_Class</th>\n",
       "      <th>bayesian_macrof1</th>\n",
       "      <th>Y_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>TEST_140</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_140</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_140</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_140</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_140</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_140</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>TEST_141</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_141</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_141</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_141</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_141</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_141</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_141</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>TEST_142</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_142</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_142</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_142</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_142</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_142</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_142</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>TEST_143</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_143</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_143</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_143</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_143</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_143</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>TEST_144</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_144</td>\n",
       "      <td>2</td>\n",
       "      <td>TEST_144</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_144</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_144</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_144</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_144</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>TEST_145</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_145</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_145</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_145</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_145</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_145</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>TEST_146</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_146</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_146</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_146</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_146</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_146</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_146</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>TEST_147</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_147</td>\n",
       "      <td>2</td>\n",
       "      <td>TEST_147</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_147</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_147</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_147</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>TEST_148</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_148</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_148</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_148</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_148</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_148</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>TEST_149</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_149</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_149</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_149</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_149</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_149</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>TEST_150</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_150</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_150</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_150</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_150</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_150</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>TEST_151</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_151</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_151</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_151</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_151</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_151</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_151</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>TEST_152</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_152</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_152</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_152</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_152</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_152</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_152</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>TEST_153</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_153</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_153</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_153</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_153</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_153</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>TEST_154</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_154</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_154</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_154</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_154</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_154</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_154</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>TEST_155</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_155</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_155</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_155</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_155</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_155</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>TEST_156</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_156</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_156</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_156</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_156</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_156</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>TEST_157</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_157</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_157</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_157</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_157</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_157</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>TEST_158</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_158</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_158</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_158</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_158</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_158</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>TEST_159</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_159</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_159</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_159</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_159</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_159</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_159</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>TEST_160</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_160</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_160</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_160</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_160</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_160</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>TEST_161</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_161</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_161</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_161</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_161</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_161</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>TEST_162</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_162</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_162</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_162</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_162</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_162</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>TEST_163</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_163</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_163</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_163</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_163</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_163</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_163</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>TEST_164</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_164</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_164</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_164</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_164</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_164</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_164</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>TEST_165</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_165</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_165</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_165</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_165</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_165</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>TEST_166</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_166</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_166</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_166</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_166</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_166</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_166</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>TEST_167</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_167</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_167</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_167</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_167</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_167</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>TEST_168</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_168</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_168</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_168</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_168</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_168</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_168</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>TEST_169</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_169</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_169</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_169</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_169</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_169</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>TEST_170</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_170</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_170</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_170</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST_170</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_170</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    default_param  Y_Class RandomSearch  Y_Class GridSearch  Y_Class  \\\n",
       "140      TEST_140        0     TEST_140        1   TEST_140        1   \n",
       "141      TEST_141        0     TEST_141        1   TEST_141        1   \n",
       "142      TEST_142        0     TEST_142        1   TEST_142        1   \n",
       "143      TEST_143        0     TEST_143        1   TEST_143        1   \n",
       "144      TEST_144        0     TEST_144        2   TEST_144        1   \n",
       "145      TEST_145        0     TEST_145        1   TEST_145        1   \n",
       "146      TEST_146        0     TEST_146        1   TEST_146        1   \n",
       "147      TEST_147        0     TEST_147        2   TEST_147        1   \n",
       "148      TEST_148        0     TEST_148        1   TEST_148        1   \n",
       "149      TEST_149        0     TEST_149        1   TEST_149        1   \n",
       "150      TEST_150        0     TEST_150        1   TEST_150        1   \n",
       "151      TEST_151        0     TEST_151        1   TEST_151        1   \n",
       "152      TEST_152        0     TEST_152        1   TEST_152        1   \n",
       "153      TEST_153        0     TEST_153        1   TEST_153        1   \n",
       "154      TEST_154        0     TEST_154        1   TEST_154        1   \n",
       "155      TEST_155        0     TEST_155        1   TEST_155        1   \n",
       "156      TEST_156        0     TEST_156        1   TEST_156        1   \n",
       "157      TEST_157        0     TEST_157        1   TEST_157        1   \n",
       "158      TEST_158        0     TEST_158        1   TEST_158        1   \n",
       "159      TEST_159        0     TEST_159        1   TEST_159        1   \n",
       "160      TEST_160        0     TEST_160        1   TEST_160        1   \n",
       "161      TEST_161        0     TEST_161        0   TEST_161        1   \n",
       "162      TEST_162        0     TEST_162        1   TEST_162        1   \n",
       "163      TEST_163        0     TEST_163        1   TEST_163        1   \n",
       "164      TEST_164        0     TEST_164        1   TEST_164        1   \n",
       "165      TEST_165        0     TEST_165        1   TEST_165        1   \n",
       "166      TEST_166        0     TEST_166        1   TEST_166        1   \n",
       "167      TEST_167        0     TEST_167        1   TEST_167        1   \n",
       "168      TEST_168        0     TEST_168        1   TEST_168        1   \n",
       "169      TEST_169        0     TEST_169        1   TEST_169        1   \n",
       "170      TEST_170        0     TEST_170        1   TEST_170        1   \n",
       "\n",
       "       submit  Y_Class  Bayesian  Y_Class random_refit  Y_Class  \\\n",
       "140  TEST_140        1  TEST_140        0     TEST_140        0   \n",
       "141  TEST_141        1  TEST_141        0     TEST_141        0   \n",
       "142  TEST_142        1  TEST_142        0     TEST_142        0   \n",
       "143  TEST_143        1  TEST_143        0     TEST_143        0   \n",
       "144  TEST_144        1  TEST_144        0     TEST_144        0   \n",
       "145  TEST_145        1  TEST_145        0     TEST_145        0   \n",
       "146  TEST_146        1  TEST_146        0     TEST_146        0   \n",
       "147  TEST_147        1  TEST_147        0     TEST_147        0   \n",
       "148  TEST_148        1  TEST_148        0     TEST_148        0   \n",
       "149  TEST_149        1  TEST_149        0     TEST_149        0   \n",
       "150  TEST_150        1  TEST_150        0     TEST_150        0   \n",
       "151  TEST_151        1  TEST_151        0     TEST_151        0   \n",
       "152  TEST_152        1  TEST_152        0     TEST_152        0   \n",
       "153  TEST_153        1  TEST_153        0     TEST_153        0   \n",
       "154  TEST_154        1  TEST_154        0     TEST_154        0   \n",
       "155  TEST_155        1  TEST_155        0     TEST_155        0   \n",
       "156  TEST_156        1  TEST_156        0     TEST_156        0   \n",
       "157  TEST_157        1  TEST_157        0     TEST_157        0   \n",
       "158  TEST_158        1  TEST_158        0     TEST_158        0   \n",
       "159  TEST_159        1  TEST_159        0     TEST_159        0   \n",
       "160  TEST_160        1  TEST_160        0     TEST_160        0   \n",
       "161  TEST_161        1  TEST_161        0     TEST_161        0   \n",
       "162  TEST_162        1  TEST_162        0     TEST_162        0   \n",
       "163  TEST_163        1  TEST_163        0     TEST_163        0   \n",
       "164  TEST_164        1  TEST_164        0     TEST_164        0   \n",
       "165  TEST_165        1  TEST_165        0     TEST_165        0   \n",
       "166  TEST_166        1  TEST_166        0     TEST_166        0   \n",
       "167  TEST_167        1  TEST_167        0     TEST_167        0   \n",
       "168  TEST_168        1  TEST_168        0     TEST_168        0   \n",
       "169  TEST_169        1  TEST_169        0     TEST_169        0   \n",
       "170  TEST_170        1  TEST_170        0     TEST_170        0   \n",
       "\n",
       "    bayesian_macrof1  Y_Class  \n",
       "140         TEST_140        0  \n",
       "141         TEST_141        0  \n",
       "142         TEST_142        0  \n",
       "143         TEST_143        0  \n",
       "144         TEST_144        0  \n",
       "145         TEST_145        0  \n",
       "146         TEST_146        0  \n",
       "147         TEST_147        0  \n",
       "148         TEST_148        0  \n",
       "149         TEST_149        0  \n",
       "150         TEST_150        0  \n",
       "151         TEST_151        0  \n",
       "152         TEST_152        0  \n",
       "153         TEST_153        0  \n",
       "154         TEST_154        0  \n",
       "155         TEST_155        0  \n",
       "156         TEST_156        0  \n",
       "157         TEST_157        0  \n",
       "158         TEST_158        0  \n",
       "159         TEST_159        0  \n",
       "160         TEST_160        0  \n",
       "161         TEST_161        0  \n",
       "162         TEST_162        0  \n",
       "163         TEST_163        0  \n",
       "164         TEST_164        0  \n",
       "165         TEST_165        0  \n",
       "166         TEST_166        0  \n",
       "167         TEST_167        0  \n",
       "168         TEST_168        0  \n",
       "169         TEST_169        0  \n",
       "170         TEST_170        0  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_GBM_total.loc[140:170]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e9bbfc66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission7.Y_Class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "73bc530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission4 = pd.read_csv('/Users/kimminyoung/Desktop/Dacon_SmartFactory/t11_GBM_처음 제출한 것_0.30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bfcac06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#두 가지 분류기로 예측한 결과를 결정확률을 다 더하고 평균내서 확률이 더 높은 레이블 값을 최종 값으로 한다.\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "#개별모델 생성(Adaboost, GBM)\n",
    "Adab_clf = AdaBoostClassifier(n_estimators=1, \n",
    "                        random_state=37, \n",
    "                        learning_rate=0.005)\n",
    "GBM_clf = GradientBoostingClassifier(random_state=37, \n",
    "                                     n_estimators = 10, \n",
    "                                     learning_rate = 0.05, \n",
    "                                     min_samples_leaf = 17,\n",
    "                                    min_samples_split = 2)\n",
    "\n",
    "#개별 모델을 소프트 보팅 기반의 앙상블 모델로 구현\n",
    "vo_clf= VotingClassifier(estimators = [('Adab', Adab_clf),('GBM',GBM_clf)], voting='soft')\n",
    "\n",
    "#VotingClassifier 학습/예측/평가\n",
    "vo_clf.fit(train_x,train_y)\n",
    "preds = vo_clf.predict(test_x)\n",
    "submission3['Y_Class'] = preds\n",
    "submission3.to_csv('./t11_voting(Adab+GBM).csv', index=False)ㅇㅇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce78cc70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f7e73f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#모델 선언(모델 선택) + 모델 학습\n",
    "#random_state=37 로 시드 고정.\n",
    "RF = RandomForestClassifier(random_state=37, ).fit(train_x, train_y)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2150643c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#test 데이터로 예측\n",
    "preds = RF.predict(test_x)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5931f9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#제출 파일에 예측 column 넣기\n",
    "submission['Y_Class'] = preds\n",
    "submission.to_csv('./baseline_submission7.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "50592d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>Y_Class</th>\n",
       "      <th>Y_Quality</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>LINE</th>\n",
       "      <th>PRODUCT_CODE</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>...</th>\n",
       "      <th>X_2866</th>\n",
       "      <th>X_2867</th>\n",
       "      <th>X_2868</th>\n",
       "      <th>X_2869</th>\n",
       "      <th>X_2870</th>\n",
       "      <th>X_2871</th>\n",
       "      <th>X_2872</th>\n",
       "      <th>X_2873</th>\n",
       "      <th>X_2874</th>\n",
       "      <th>X_2875</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533433</td>\n",
       "      <td>2022-06-13 5:14</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.3400</td>\n",
       "      <td>40.8900</td>\n",
       "      <td>32.5600</td>\n",
       "      <td>34.0900</td>\n",
       "      <td>77.7700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.541819</td>\n",
       "      <td>2022-06-13 5:22</td>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.8900</td>\n",
       "      <td>42.8200</td>\n",
       "      <td>43.9200</td>\n",
       "      <td>35.3400</td>\n",
       "      <td>72.5500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531267</td>\n",
       "      <td>2022-06-13 5:30</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.1900</td>\n",
       "      <td>36.6500</td>\n",
       "      <td>42.4700</td>\n",
       "      <td>36.5300</td>\n",
       "      <td>78.3500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_003</td>\n",
       "      <td>2</td>\n",
       "      <td>0.537325</td>\n",
       "      <td>2022-06-13 5:39</td>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>37.7400</td>\n",
       "      <td>39.1700</td>\n",
       "      <td>52.1700</td>\n",
       "      <td>30.5800</td>\n",
       "      <td>71.7800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_004</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531590</td>\n",
       "      <td>2022-06-13 5:47</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.7000</td>\n",
       "      <td>41.8900</td>\n",
       "      <td>46.9300</td>\n",
       "      <td>33.0900</td>\n",
       "      <td>76.9700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRAIN_005</td>\n",
       "      <td>2</td>\n",
       "      <td>0.537833</td>\n",
       "      <td>2022-06-13 5:55</td>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.1600</td>\n",
       "      <td>51.2500</td>\n",
       "      <td>56.0100</td>\n",
       "      <td>37.4100</td>\n",
       "      <td>71.3700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TRAIN_006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533665</td>\n",
       "      <td>2022-06-13 6:03</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.5000</td>\n",
       "      <td>41.4200</td>\n",
       "      <td>38.3600</td>\n",
       "      <td>30.8300</td>\n",
       "      <td>76.9300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TRAIN_007</td>\n",
       "      <td>2</td>\n",
       "      <td>0.540003</td>\n",
       "      <td>2022-06-13 6:11</td>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0000</td>\n",
       "      <td>35.9500</td>\n",
       "      <td>59.5100</td>\n",
       "      <td>30.4900</td>\n",
       "      <td>72.7700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TRAIN_008</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531821</td>\n",
       "      <td>2022-06-13 6:19</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42.2500</td>\n",
       "      <td>43.1700</td>\n",
       "      <td>55.6000</td>\n",
       "      <td>33.2600</td>\n",
       "      <td>78.5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TRAIN_009</td>\n",
       "      <td>2</td>\n",
       "      <td>0.538049</td>\n",
       "      <td>2022-06-13 6:28</td>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34.4000</td>\n",
       "      <td>35.8800</td>\n",
       "      <td>50.3600</td>\n",
       "      <td>38.4500</td>\n",
       "      <td>71.4200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TRAIN_010</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531503</td>\n",
       "      <td>2022-06-13 6:36</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.1200</td>\n",
       "      <td>34.7400</td>\n",
       "      <td>54.9300</td>\n",
       "      <td>33.1600</td>\n",
       "      <td>76.3000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TRAIN_011</td>\n",
       "      <td>2</td>\n",
       "      <td>0.539149</td>\n",
       "      <td>2022-06-13 6:44</td>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.1600</td>\n",
       "      <td>35.4900</td>\n",
       "      <td>52.2700</td>\n",
       "      <td>31.4500</td>\n",
       "      <td>72.4600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TRAIN_012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533632</td>\n",
       "      <td>2022-06-13 6:52</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>36.5500</td>\n",
       "      <td>32.3200</td>\n",
       "      <td>54.2500</td>\n",
       "      <td>35.1500</td>\n",
       "      <td>78.8600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TRAIN_013</td>\n",
       "      <td>2</td>\n",
       "      <td>0.538508</td>\n",
       "      <td>2022-06-13 7:00</td>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.4200</td>\n",
       "      <td>34.3300</td>\n",
       "      <td>41.9800</td>\n",
       "      <td>40.3400</td>\n",
       "      <td>72.7700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TRAIN_014</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531254</td>\n",
       "      <td>2022-06-13 7:08</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.4200</td>\n",
       "      <td>38.3300</td>\n",
       "      <td>40.1400</td>\n",
       "      <td>30.7200</td>\n",
       "      <td>76.5200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TRAIN_015</td>\n",
       "      <td>2</td>\n",
       "      <td>0.539254</td>\n",
       "      <td>2022-06-13 7:17</td>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0300</td>\n",
       "      <td>44.5300</td>\n",
       "      <td>41.5400</td>\n",
       "      <td>37.2000</td>\n",
       "      <td>72.4600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TRAIN_016</td>\n",
       "      <td>1</td>\n",
       "      <td>0.534054</td>\n",
       "      <td>2022-06-13 7:25</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.5300</td>\n",
       "      <td>31.7000</td>\n",
       "      <td>49.4900</td>\n",
       "      <td>35.7300</td>\n",
       "      <td>79.7500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TRAIN_017</td>\n",
       "      <td>2</td>\n",
       "      <td>0.538854</td>\n",
       "      <td>2022-06-13 7:33</td>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.1600</td>\n",
       "      <td>33.2600</td>\n",
       "      <td>55.9700</td>\n",
       "      <td>35.1700</td>\n",
       "      <td>71.4000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TRAIN_018</td>\n",
       "      <td>1</td>\n",
       "      <td>0.532170</td>\n",
       "      <td>2022-06-13 7:41</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0700</td>\n",
       "      <td>48.3800</td>\n",
       "      <td>36.2400</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>75.8200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TRAIN_019</td>\n",
       "      <td>2</td>\n",
       "      <td>0.539235</td>\n",
       "      <td>2022-06-13 7:49</td>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.8073</td>\n",
       "      <td>53.6077</td>\n",
       "      <td>49.6062</td>\n",
       "      <td>51.6598</td>\n",
       "      <td>66.6497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>TRAIN_020</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531179</td>\n",
       "      <td>2022-06-13 7:58</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>2.409742</td>\n",
       "      <td>95.123209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.8073</td>\n",
       "      <td>53.6077</td>\n",
       "      <td>49.6062</td>\n",
       "      <td>51.6598</td>\n",
       "      <td>66.6497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows × 2881 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PRODUCT_ID  Y_Class  Y_Quality        TIMESTAMP     LINE PRODUCT_CODE  \\\n",
       "0   TRAIN_000        1   0.533433  2022-06-13 5:14  T050304         A_31   \n",
       "1   TRAIN_001        2   0.541819  2022-06-13 5:22  T050307         A_31   \n",
       "2   TRAIN_002        1   0.531267  2022-06-13 5:30  T050304         A_31   \n",
       "3   TRAIN_003        2   0.537325  2022-06-13 5:39  T050307         A_31   \n",
       "4   TRAIN_004        1   0.531590  2022-06-13 5:47  T050304         A_31   \n",
       "5   TRAIN_005        2   0.537833  2022-06-13 5:55  T050307         A_31   \n",
       "6   TRAIN_006        1   0.533665  2022-06-13 6:03  T050304         A_31   \n",
       "7   TRAIN_007        2   0.540003  2022-06-13 6:11  T050307         A_31   \n",
       "8   TRAIN_008        1   0.531821  2022-06-13 6:19  T050304         A_31   \n",
       "9   TRAIN_009        2   0.538049  2022-06-13 6:28  T050307         A_31   \n",
       "10  TRAIN_010        1   0.531503  2022-06-13 6:36  T050304         A_31   \n",
       "11  TRAIN_011        2   0.539149  2022-06-13 6:44  T050307         A_31   \n",
       "12  TRAIN_012        1   0.533632  2022-06-13 6:52  T050304         A_31   \n",
       "13  TRAIN_013        2   0.538508  2022-06-13 7:00  T050307         A_31   \n",
       "14  TRAIN_014        1   0.531254  2022-06-13 7:08  T050304         A_31   \n",
       "15  TRAIN_015        2   0.539254  2022-06-13 7:17  T050307         A_31   \n",
       "16  TRAIN_016        1   0.534054  2022-06-13 7:25  T050304         A_31   \n",
       "17  TRAIN_017        2   0.538854  2022-06-13 7:33  T050307         A_31   \n",
       "18  TRAIN_018        1   0.532170  2022-06-13 7:41  T050304         A_31   \n",
       "19  TRAIN_019        2   0.539235  2022-06-13 7:49  T050307         A_31   \n",
       "20  TRAIN_020        1   0.531179  2022-06-13 7:58  T050304         A_31   \n",
       "\n",
       "         X_1        X_2  X_3   X_4  ...   X_2866   X_2867   X_2868   X_2869  \\\n",
       "0   2.409742  95.123209  0.0  45.0  ...  39.3400  40.8900  32.5600  34.0900   \n",
       "1   2.409742  95.123209  0.0  45.0  ...  38.8900  42.8200  43.9200  35.3400   \n",
       "2   2.409742  95.123209  0.0  45.0  ...  39.1900  36.6500  42.4700  36.5300   \n",
       "3   2.409742  95.123209  0.0  45.0  ...  37.7400  39.1700  52.1700  30.5800   \n",
       "4   2.409742  95.123209  0.0  45.0  ...  38.7000  41.8900  46.9300  33.0900   \n",
       "5   2.409742  95.123209  0.0  45.0  ...  38.1600  51.2500  56.0100  37.4100   \n",
       "6   2.409742  95.123209  0.0  45.0  ...  32.5000  41.4200  38.3600  30.8300   \n",
       "7   2.409742  95.123209  0.0  45.0  ...  39.0000  35.9500  59.5100  30.4900   \n",
       "8   2.409742  95.123209  0.0  45.0  ...  42.2500  43.1700  55.6000  33.2600   \n",
       "9   2.409742  95.123209  0.0  45.0  ...  34.4000  35.8800  50.3600  38.4500   \n",
       "10  2.409742  95.123209  0.0  45.0  ...  32.1200  34.7400  54.9300  33.1600   \n",
       "11  2.409742  95.123209  0.0  45.0  ...  39.1600  35.4900  52.2700  31.4500   \n",
       "12  2.409742  95.123209  0.0  45.0  ...  36.5500  32.3200  54.2500  35.1500   \n",
       "13  2.409742  95.123209  0.0  45.0  ...  40.4200  34.3300  41.9800  40.3400   \n",
       "14  2.409742  95.123209  0.0  45.0  ...  40.4200  38.3300  40.1400  30.7200   \n",
       "15  2.409742  95.123209  0.0  45.0  ...  38.0300  44.5300  41.5400  37.2000   \n",
       "16  2.409742  95.123209  0.0  45.0  ...  40.5300  31.7000  49.4900  35.7300   \n",
       "17  2.409742  95.123209  0.0  45.0  ...  33.1600  33.2600  55.9700  35.1700   \n",
       "18  2.409742  95.123209  0.0  45.0  ...  35.0700  48.3800  36.2400  33.0000   \n",
       "19  2.409742  95.123209  0.0  45.0  ...  50.8073  53.6077  49.6062  51.6598   \n",
       "20  2.409742  95.123209  0.0  45.0  ...  50.8073  53.6077  49.6062  51.6598   \n",
       "\n",
       "     X_2870  X_2871  X_2872  X_2873  X_2874  X_2875  \n",
       "0   77.7700     1.0     0.0     0.0     0.0     0.0  \n",
       "1   72.5500     1.0     0.0     0.0     0.0     0.0  \n",
       "2   78.3500     1.0     0.0     0.0     0.0     0.0  \n",
       "3   71.7800     1.0     0.0     0.0     0.0     0.0  \n",
       "4   76.9700     1.0     0.0     0.0     0.0     0.0  \n",
       "5   71.3700     1.0     0.0     0.0     0.0     0.0  \n",
       "6   76.9300     1.0     0.0     0.0     0.0     0.0  \n",
       "7   72.7700     1.0     0.0     0.0     0.0     0.0  \n",
       "8   78.5000     1.0     0.0     0.0     0.0     0.0  \n",
       "9   71.4200     1.0     0.0     0.0     0.0     0.0  \n",
       "10  76.3000     1.0     0.0     0.0     0.0     0.0  \n",
       "11  72.4600     1.0     0.0     0.0     0.0     0.0  \n",
       "12  78.8600     1.0     0.0     0.0     0.0     0.0  \n",
       "13  72.7700     1.0     0.0     0.0     0.0     0.0  \n",
       "14  76.5200     1.0     0.0     0.0     0.0     0.0  \n",
       "15  72.4600     1.0     0.0     0.0     0.0     0.0  \n",
       "16  79.7500     1.0     0.0     0.0     0.0     0.0  \n",
       "17  71.4000     1.0     0.0     0.0     0.0     0.0  \n",
       "18  75.8200     1.0     0.0     0.0     0.0     0.0  \n",
       "19  66.6497     1.0     0.0     0.0     0.0     0.0  \n",
       "20  66.6497     1.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[21 rows x 2881 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0928cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d7d5f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a32d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e941d02d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52c3276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0efedc32",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>Y_Class</th>\n",
       "      <th>Y_Quality</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>LINE</th>\n",
       "      <th>PRODUCT_CODE</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>...</th>\n",
       "      <th>X_2866</th>\n",
       "      <th>X_2867</th>\n",
       "      <th>X_2868</th>\n",
       "      <th>X_2869</th>\n",
       "      <th>X_2870</th>\n",
       "      <th>X_2871</th>\n",
       "      <th>X_2872</th>\n",
       "      <th>X_2873</th>\n",
       "      <th>X_2874</th>\n",
       "      <th>X_2875</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_022</td>\n",
       "      <td>0</td>\n",
       "      <td>0.517719</td>\n",
       "      <td>2022-06-14 8:53</td>\n",
       "      <td>T100304</td>\n",
       "      <td>T_31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_023</td>\n",
       "      <td>0</td>\n",
       "      <td>0.519090</td>\n",
       "      <td>2022-06-14 9:01</td>\n",
       "      <td>T100304</td>\n",
       "      <td>T_31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_028</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521249</td>\n",
       "      <td>2022-06-19 20:26</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_034</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521524</td>\n",
       "      <td>2022-06-21 17:36</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>55.03</td>\n",
       "      <td>52.24</td>\n",
       "      <td>55.33</td>\n",
       "      <td>57.49</td>\n",
       "      <td>67.31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_066</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524408</td>\n",
       "      <td>2022-06-25 21:38</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>TRAIN_583</td>\n",
       "      <td>0</td>\n",
       "      <td>0.522340</td>\n",
       "      <td>2022-09-05 8:34</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>51.71</td>\n",
       "      <td>59.64</td>\n",
       "      <td>54.61</td>\n",
       "      <td>57.05</td>\n",
       "      <td>63.18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>TRAIN_584</td>\n",
       "      <td>0</td>\n",
       "      <td>0.519519</td>\n",
       "      <td>2022-09-05 11:09</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>TRAIN_585</td>\n",
       "      <td>0</td>\n",
       "      <td>0.515214</td>\n",
       "      <td>2022-09-05 11:17</td>\n",
       "      <td>T010306</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>TRAIN_594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524022</td>\n",
       "      <td>2022-09-08 22:38</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>49.47</td>\n",
       "      <td>53.07</td>\n",
       "      <td>50.89</td>\n",
       "      <td>55.10</td>\n",
       "      <td>66.49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>TRAIN_595</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521289</td>\n",
       "      <td>2022-09-08 22:47</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 2881 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PRODUCT_ID  Y_Class  Y_Quality         TIMESTAMP     LINE PRODUCT_CODE  \\\n",
       "0   TRAIN_022        0   0.517719   2022-06-14 8:53  T100304         T_31   \n",
       "1   TRAIN_023        0   0.519090   2022-06-14 9:01  T100304         T_31   \n",
       "2   TRAIN_028        0   0.521249  2022-06-19 20:26  T010305         A_31   \n",
       "3   TRAIN_034        0   0.521524  2022-06-21 17:36  T050304         A_31   \n",
       "4   TRAIN_066        0   0.524408  2022-06-25 21:38  T010305         A_31   \n",
       "..        ...      ...        ...               ...      ...          ...   \n",
       "83  TRAIN_583        0   0.522340   2022-09-05 8:34  T050304         A_31   \n",
       "84  TRAIN_584        0   0.519519  2022-09-05 11:09  T010305         A_31   \n",
       "85  TRAIN_585        0   0.515214  2022-09-05 11:17  T010306         A_31   \n",
       "86  TRAIN_594        0   0.524022  2022-09-08 22:38  T050304         A_31   \n",
       "87  TRAIN_595        0   0.521289  2022-09-08 22:47  T050304         A_31   \n",
       "\n",
       "    X_1    X_2  X_3   X_4  ...  X_2866  X_2867  X_2868  X_2869  X_2870  \\\n",
       "0   2.0  102.0  0.0  45.0  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "1   2.0  102.0  0.0  45.0  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "2   NaN    NaN  NaN   NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "3   NaN    NaN  NaN   NaN  ...   55.03   52.24   55.33   57.49   67.31   \n",
       "4   NaN    NaN  NaN   NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "..  ...    ...  ...   ...  ...     ...     ...     ...     ...     ...   \n",
       "83  NaN    NaN  NaN   NaN  ...   51.71   59.64   54.61   57.05   63.18   \n",
       "84  NaN    NaN  NaN   NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "85  NaN    NaN  NaN   NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "86  NaN    NaN  NaN   NaN  ...   49.47   53.07   50.89   55.10   66.49   \n",
       "87  NaN    NaN  NaN   NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "    X_2871  X_2872  X_2873  X_2874  X_2875  \n",
       "0      NaN     NaN     NaN     NaN     NaN  \n",
       "1      NaN     NaN     NaN     NaN     NaN  \n",
       "2      NaN     NaN     NaN     NaN     NaN  \n",
       "3      1.0     NaN     NaN     NaN     NaN  \n",
       "4      NaN     NaN     NaN     NaN     NaN  \n",
       "..     ...     ...     ...     ...     ...  \n",
       "83     1.0     NaN     NaN     NaN     NaN  \n",
       "84     NaN     NaN     NaN     NaN     NaN  \n",
       "85     NaN     NaN     NaN     NaN     NaN  \n",
       "86     1.0     NaN     NaN     NaN     NaN  \n",
       "87     1.0     NaN     NaN     NaN     NaN  \n",
       "\n",
       "[88 rows x 2881 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #train_df_0 index 재설정\n",
    "# train_df_0 = train_df_0.reset_index(inplace = False, drop = True)\n",
    "# train_df_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "872eda12",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='X_92'>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(y = 'X_92', data = train_df_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e72588cf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df_0.boxplot(column=['X_92'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a113917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[598,\n",
       " 3,\n",
       " 583,\n",
       " 598,\n",
       " 6,\n",
       " 3,\n",
       " 10,\n",
       " 16,\n",
       " 1,\n",
       " 2,\n",
       " 13,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 251,\n",
       " 178,\n",
       " 169,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 67,\n",
       " 72,\n",
       " 66,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 10,\n",
       " 12,\n",
       " 11,\n",
       " 12,\n",
       " 11,\n",
       " 9,\n",
       " 14,\n",
       " 12,\n",
       " 12,\n",
       " 13,\n",
       " 12,\n",
       " 14,\n",
       " 12,\n",
       " 13,\n",
       " 15,\n",
       " 11,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 13,\n",
       " 19,\n",
       " 11,\n",
       " 19,\n",
       " 8,\n",
       " 13,\n",
       " 13,\n",
       " 10,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 23,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 13,\n",
       " 15,\n",
       " 16,\n",
       " 1,\n",
       " 42,\n",
       " 52,\n",
       " 33,\n",
       " 1,\n",
       " 49,\n",
       " 54,\n",
       " 47,\n",
       " 1,\n",
       " 46,\n",
       " 81,\n",
       " 39,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 29,\n",
       " 31,\n",
       " 48,\n",
       " 24,\n",
       " 23,\n",
       " 1,\n",
       " 349,\n",
       " 175,\n",
       " 175,\n",
       " 174,\n",
       " 174,\n",
       " 78,\n",
       " 78,\n",
       " 42,\n",
       " 42,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 67,\n",
       " 67,\n",
       " 73,\n",
       " 99,\n",
       " 93,\n",
       " 107,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 108,\n",
       " 1,\n",
       " 31,\n",
       " 32,\n",
       " 35,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 27,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 13,\n",
       " 12,\n",
       " 12,\n",
       " 8,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 13,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 9,\n",
       " 1,\n",
       " 37,\n",
       " 1,\n",
       " 27,\n",
       " 27,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 10,\n",
       " 48,\n",
       " 1,\n",
       " 2,\n",
       " 45,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 108,\n",
       " 94,\n",
       " 88,\n",
       " 17,\n",
       " 15,\n",
       " 19,\n",
       " 1,\n",
       " 49,\n",
       " 47,\n",
       " 49,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 12,\n",
       " 10,\n",
       " 10,\n",
       " 11,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 11,\n",
       " 8,\n",
       " 14,\n",
       " 13,\n",
       " 15,\n",
       " 10,\n",
       " 14,\n",
       " 8,\n",
       " 9,\n",
       " 13,\n",
       " 11,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 25,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 26,\n",
       " 24,\n",
       " 25,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 39,\n",
       " 20,\n",
       " 42,\n",
       " 1,\n",
       " 23,\n",
       " 15,\n",
       " 28,\n",
       " 1,\n",
       " 14,\n",
       " 23,\n",
       " 28,\n",
       " 1,\n",
       " 21,\n",
       " 21,\n",
       " 24,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 28,\n",
       " 30,\n",
       " 34,\n",
       " 25,\n",
       " 25,\n",
       " 1,\n",
       " 129,\n",
       " 59,\n",
       " 59,\n",
       " 70,\n",
       " 70,\n",
       " 31,\n",
       " 21,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 13,\n",
       " 204,\n",
       " 13,\n",
       " 48,\n",
       " 308,\n",
       " 39,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 14,\n",
       " 6,\n",
       " 139,\n",
       " 93,\n",
       " 187,\n",
       " 27,\n",
       " 292,\n",
       " 25,\n",
       " 5,\n",
       " 155,\n",
       " 7,\n",
       " 7,\n",
       " 205,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 10,\n",
       " 244,\n",
       " 7,\n",
       " 30,\n",
       " 298,\n",
       " 25,\n",
       " 10,\n",
       " 235,\n",
       " 10,\n",
       " 29,\n",
       " 297,\n",
       " 30,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 208,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 50,\n",
       " 46,\n",
       " 107,\n",
       " 111,\n",
       " 46,\n",
       " 288,\n",
       " 57,\n",
       " 31,\n",
       " 9,\n",
       " 3,\n",
       " 27,\n",
       " 27,\n",
       " 16,\n",
       " 32,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 274,\n",
       " 178,\n",
       " 91,\n",
       " 292,\n",
       " 137,\n",
       " 125,\n",
       " 289,\n",
       " 155,\n",
       " 96,\n",
       " 165,\n",
       " 27,\n",
       " 9,\n",
       " 4,\n",
       " 25,\n",
       " 34,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 5,\n",
       " 18,\n",
       " 15,\n",
       " 15,\n",
       " 6,\n",
       " 14,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 144,\n",
       " 150,\n",
       " 130,\n",
       " 116,\n",
       " 15,\n",
       " 1,\n",
       " 7,\n",
       " 67,\n",
       " 281,\n",
       " 254,\n",
       " 93,\n",
       " 90,\n",
       " 252,\n",
       " 59,\n",
       " 32,\n",
       " 165,\n",
       " 342,\n",
       " 342,\n",
       " 338,\n",
       " 331,\n",
       " 272,\n",
       " 1,\n",
       " 7,\n",
       " 18,\n",
       " 13,\n",
       " 2,\n",
       " 12,\n",
       " 2,\n",
       " 1,\n",
       " 10,\n",
       " 137,\n",
       " 179,\n",
       " 140,\n",
       " 129,\n",
       " 16,\n",
       " 1,\n",
       " 275,\n",
       " 288,\n",
       " 4,\n",
       " 111,\n",
       " 178,\n",
       " 139,\n",
       " 57,\n",
       " 93,\n",
       " 187,\n",
       " 75,\n",
       " 80,\n",
       " 85,\n",
       " 82,\n",
       " 82,\n",
       " 205,\n",
       " 275,\n",
       " 29,\n",
       " 11,\n",
       " 4,\n",
       " 15,\n",
       " 27,\n",
       " 16,\n",
       " 3,\n",
       " 10,\n",
       " 33,\n",
       " 8,\n",
       " 12,\n",
       " 5,\n",
       " 7,\n",
       " 15,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 116,\n",
       " 182,\n",
       " 153,\n",
       " 131,\n",
       " 14,\n",
       " 9,\n",
       " 8,\n",
       " 28,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 19,\n",
       " 10,\n",
       " 4,\n",
       " 3,\n",
       " 10,\n",
       " 21,\n",
       " 11,\n",
       " 19,\n",
       " 2,\n",
       " 4,\n",
       " 10,\n",
       " 10,\n",
       " 3,\n",
       " 4,\n",
       " 18,\n",
       " 14,\n",
       " 13,\n",
       " 4,\n",
       " 5,\n",
       " 12,\n",
       " 7,\n",
       " 18,\n",
       " 15,\n",
       " 4,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 7,\n",
       " 31,\n",
       " 34,\n",
       " 27,\n",
       " 23,\n",
       " 31,\n",
       " 9,\n",
       " 11,\n",
       " 4,\n",
       " 15,\n",
       " 11,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 11,\n",
       " 19,\n",
       " 9,\n",
       " 22,\n",
       " 5,\n",
       " 40,\n",
       " 19,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 10,\n",
       " 10,\n",
       " 3,\n",
       " 4,\n",
       " 18,\n",
       " 9,\n",
       " 11,\n",
       " 32,\n",
       " 165,\n",
       " 342,\n",
       " 342,\n",
       " 338,\n",
       " 331,\n",
       " 272,\n",
       " 1,\n",
       " 343,\n",
       " 281,\n",
       " 90,\n",
       " 252,\n",
       " 281,\n",
       " 90,\n",
       " 252,\n",
       " 25,\n",
       " 121,\n",
       " 22,\n",
       " 123,\n",
       " 85,\n",
       " 65,\n",
       " 10,\n",
       " 300,\n",
       " 2,\n",
       " 75,\n",
       " 232,\n",
       " 310,\n",
       " 9,\n",
       " 13,\n",
       " 41,\n",
       " 33,\n",
       " 9,\n",
       " 4,\n",
       " 9,\n",
       " 5,\n",
       " 11,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 29,\n",
       " 17,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 274,\n",
       " 289,\n",
       " 328,\n",
       " 3,\n",
       " 316,\n",
       " 204,\n",
       " 211,\n",
       " 209,\n",
       " 210,\n",
       " 196,\n",
       " 192,\n",
       " 210,\n",
       " 195,\n",
       " 259,\n",
       " 204,\n",
       " 275,\n",
       " 279,\n",
       " 273,\n",
       " 206,\n",
       " 302,\n",
       " 101,\n",
       " 114,\n",
       " 31,\n",
       " 27,\n",
       " 9,\n",
       " 178,\n",
       " 9,\n",
       " 3,\n",
       " 91,\n",
       " 4,\n",
       " 27,\n",
       " 137,\n",
       " 16,\n",
       " 125,\n",
       " 32,\n",
       " 34,\n",
       " 9,\n",
       " 165,\n",
       " 8,\n",
       " 2,\n",
       " 96,\n",
       " 3,\n",
       " 5,\n",
       " 67,\n",
       " 15,\n",
       " 254,\n",
       " 13,\n",
       " 15,\n",
       " 93,\n",
       " 2,\n",
       " 59,\n",
       " 2,\n",
       " 9,\n",
       " 300,\n",
       " 2,\n",
       " 6,\n",
       " 260,\n",
       " 5,\n",
       " 28,\n",
       " 79,\n",
       " 2,\n",
       " 58,\n",
       " 3,\n",
       " 3,\n",
       " 64,\n",
       " 2,\n",
       " 4,\n",
       " 60,\n",
       " 2,\n",
       " 40,\n",
       " 40,\n",
       " 3,\n",
       " 208,\n",
       " 2,\n",
       " 3,\n",
       " 188,\n",
       " 2,\n",
       " 6,\n",
       " 253,\n",
       " 6,\n",
       " 16,\n",
       " 197,\n",
       " 15,\n",
       " 9,\n",
       " 121,\n",
       " 8,\n",
       " 14,\n",
       " 204,\n",
       " 12,\n",
       " 10,\n",
       " 7,\n",
       " 11,\n",
       " 9,\n",
       " 11,\n",
       " 7,\n",
       " 11,\n",
       " 8,\n",
       " 10,\n",
       " 8,\n",
       " 9,\n",
       " 7,\n",
       " 11,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 21,\n",
       " 15,\n",
       " 15,\n",
       " 13,\n",
       " 24,\n",
       " 23,\n",
       " 22,\n",
       " 22,\n",
       " 15,\n",
       " 13,\n",
       " 3,\n",
       " 45,\n",
       " 3,\n",
       " 4,\n",
       " 50,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 28,\n",
       " 279,\n",
       " 23,\n",
       " 15,\n",
       " 76,\n",
       " 3,\n",
       " 76,\n",
       " 2,\n",
       " 5,\n",
       " 154,\n",
       " 5,\n",
       " 15,\n",
       " 12,\n",
       " 2,\n",
       " 26,\n",
       " 4,\n",
       " 5,\n",
       " 41,\n",
       " 38,\n",
       " 28,\n",
       " 184,\n",
       " 33,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 111,\n",
       " 3,\n",
       " 9,\n",
       " 178,\n",
       " 10,\n",
       " 7,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 13,\n",
       " 13,\n",
       " 12,\n",
       " 11,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 199,\n",
       " 7,\n",
       " 7,\n",
       " 182,\n",
       " 184,\n",
       " 185,\n",
       " 180,\n",
       " 134,\n",
       " 141,\n",
       " 135,\n",
       " 142,\n",
       " 6,\n",
       " 120,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 12,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 96,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 32,\n",
       " 1,\n",
       " 7,\n",
       " 165,\n",
       " 10,\n",
       " 144,\n",
       " 342,\n",
       " 137,\n",
       " 150,\n",
       " 342,\n",
       " 179,\n",
       " 130,\n",
       " 338,\n",
       " 140,\n",
       " 116,\n",
       " 331,\n",
       " 129,\n",
       " 15,\n",
       " 272,\n",
       " 16,\n",
       " 4,\n",
       " 113,\n",
       " 3,\n",
       " 86,\n",
       " 178,\n",
       " 85,\n",
       " 31,\n",
       " 176,\n",
       " 31,\n",
       " 28,\n",
       " 197,\n",
       " 30,\n",
       " 97,\n",
       " 225,\n",
       " 42,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 68,\n",
       " 61,\n",
       " 70,\n",
       " 61,\n",
       " 135,\n",
       " 97,\n",
       " 228,\n",
       " 42,\n",
       " 223,\n",
       " 36,\n",
       " 38,\n",
       " 226,\n",
       " 40,\n",
       " 22,\n",
       " 231,\n",
       " 20,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 25,\n",
       " 219,\n",
       " 19,\n",
       " 96,\n",
       " 243,\n",
       " 77,\n",
       " 21,\n",
       " 143,\n",
       " 17,\n",
       " 16,\n",
       " 142,\n",
       " 15,\n",
       " 37,\n",
       " 222,\n",
       " 35,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 14,\n",
       " 220,\n",
       " 240,\n",
       " 224,\n",
       " 247,\n",
       " 247,\n",
       " 247,\n",
       " 208,\n",
       " 211,\n",
       " 224,\n",
       " 245,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 28,\n",
       " 2,\n",
       " 28,\n",
       " 39,\n",
       " 58,\n",
       " 42,\n",
       " 48,\n",
       " 34,\n",
       " 130,\n",
       " 108,\n",
       " 75,\n",
       " 10,\n",
       " 16,\n",
       " 77,\n",
       " 19,\n",
       " 14,\n",
       " 42,\n",
       " 248,\n",
       " 12,\n",
       " 13,\n",
       " 44,\n",
       " 56,\n",
       " 60,\n",
       " 38,\n",
       " 248,\n",
       " 7,\n",
       " 11,\n",
       " 222,\n",
       " 156,\n",
       " 183,\n",
       " 240,\n",
       " 170,\n",
       " 182,\n",
       " 223,\n",
       " 248,\n",
       " 138,\n",
       " 147,\n",
       " 231,\n",
       " 225,\n",
       " 236,\n",
       " 226,\n",
       " 248,\n",
       " 155,\n",
       " 156,\n",
       " 29,\n",
       " 32,\n",
       " 17,\n",
       " 83,\n",
       " 13,\n",
       " 14,\n",
       " 36,\n",
       " 248,\n",
       " 13,\n",
       " 13,\n",
       " 22,\n",
       " 65,\n",
       " 40,\n",
       " 248,\n",
       " 6,\n",
       " 7,\n",
       " 247,\n",
       " 60,\n",
       " 14,\n",
       " 22,\n",
       " 37,\n",
       " 27,\n",
       " 80,\n",
       " 14,\n",
       " 14,\n",
       " 22,\n",
       " 3,\n",
       " 245,\n",
       " 249,\n",
       " 19,\n",
       " 58,\n",
       " 7,\n",
       " ...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########아웃라이어를 어떻게 제거해줄지 고민하다 끊겼음\n",
    "value_type_num = train_df.nunique().tolist()\n",
    "value_type_num"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pas",
   "language": "python",
   "name": "pas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

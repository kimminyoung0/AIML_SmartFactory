{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c732c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings; warnings.filterwarnings(action='ignore')\n",
    "import pickle\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import sklearn.svm as svm\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "from xgboost import plot_importance\n",
    "from scipy.stats import randint\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c407cb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed) #파이썬 자체 모듈 random 모듈의 시드 고정\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) \n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(37) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33209ff9",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "864c76d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "149a45e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('./sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8c7839",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae41a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_df['Y_Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "606f458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_df.drop(columns = ['PRODUCT_ID', 'TIMESTAMP', 'Y_Class', 'Y_Quality'])\n",
    "test_x = test_df.drop(columns=['PRODUCT_ID', 'TIMESTAMP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd74ac6",
   "metadata": {},
   "source": [
    "범주형 데이터를 수치 데이터로 전환하기 위해 LabelEncoder 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53adcf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# qualitative to quantitative\n",
    "qual_col = ['LINE', 'PRODUCT_CODE']\n",
    "\n",
    "for i in qual_col:\n",
    "    le = LabelEncoder()\n",
    "    le = le.fit(train_x[i]) #원래 column 값을 기준으로 fit.\n",
    "    train_x[i] = le.transform(train_x[i]) #수치화, 수치로 변형\n",
    "\n",
    "    for label in np.unique(test_x[i]): \n",
    "        if label not in le.classes_: \n",
    "            le.classes_ = np.append(le.classes_, label)\n",
    "    test_x[i] = le.transform(test_x[i]) \n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55a73f6",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add2ad95",
   "metadata": {},
   "source": [
    "학습용과 테스트용 데이터 세트를 위해 별도의 Dmatrix를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c843a7ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:00:02] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"early_stopping\", \"eval_set\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-mlogloss:1.05928\teval-mlogloss:1.06846\n",
      "[1]\ttrain-mlogloss:1.02224\teval-mlogloss:1.03964\n",
      "[2]\ttrain-mlogloss:0.98753\teval-mlogloss:1.01551\n",
      "[3]\ttrain-mlogloss:0.95449\teval-mlogloss:0.99104\n",
      "[4]\ttrain-mlogloss:0.92392\teval-mlogloss:0.96798\n",
      "[5]\ttrain-mlogloss:0.89469\teval-mlogloss:0.94454\n",
      "[6]\ttrain-mlogloss:0.86730\teval-mlogloss:0.92149\n",
      "[7]\ttrain-mlogloss:0.84109\teval-mlogloss:0.90036\n",
      "[8]\ttrain-mlogloss:0.81629\teval-mlogloss:0.88033\n",
      "[9]\ttrain-mlogloss:0.79239\teval-mlogloss:0.85956\n",
      "[10]\ttrain-mlogloss:0.77003\teval-mlogloss:0.84263\n",
      "[11]\ttrain-mlogloss:0.74875\teval-mlogloss:0.82553\n",
      "[12]\ttrain-mlogloss:0.72855\teval-mlogloss:0.80987\n",
      "[13]\ttrain-mlogloss:0.70990\teval-mlogloss:0.79619\n",
      "[14]\ttrain-mlogloss:0.69126\teval-mlogloss:0.78199\n",
      "[15]\ttrain-mlogloss:0.67458\teval-mlogloss:0.76859\n",
      "[16]\ttrain-mlogloss:0.65735\teval-mlogloss:0.75758\n",
      "[17]\ttrain-mlogloss:0.64150\teval-mlogloss:0.74715\n",
      "[18]\ttrain-mlogloss:0.62598\teval-mlogloss:0.73522\n",
      "[19]\ttrain-mlogloss:0.61060\teval-mlogloss:0.72494\n",
      "[20]\ttrain-mlogloss:0.59582\teval-mlogloss:0.71527\n",
      "[21]\ttrain-mlogloss:0.58137\teval-mlogloss:0.70548\n",
      "[22]\ttrain-mlogloss:0.56725\teval-mlogloss:0.69478\n",
      "[23]\ttrain-mlogloss:0.55440\teval-mlogloss:0.68466\n",
      "[24]\ttrain-mlogloss:0.54090\teval-mlogloss:0.67543\n",
      "[25]\ttrain-mlogloss:0.52912\teval-mlogloss:0.66729\n",
      "[26]\ttrain-mlogloss:0.51600\teval-mlogloss:0.65835\n",
      "[27]\ttrain-mlogloss:0.50524\teval-mlogloss:0.65200\n",
      "[28]\ttrain-mlogloss:0.49457\teval-mlogloss:0.64593\n",
      "[29]\ttrain-mlogloss:0.48273\teval-mlogloss:0.63933\n",
      "[30]\ttrain-mlogloss:0.47217\teval-mlogloss:0.63346\n",
      "[31]\ttrain-mlogloss:0.46130\teval-mlogloss:0.62793\n",
      "[32]\ttrain-mlogloss:0.45030\teval-mlogloss:0.62293\n",
      "[33]\ttrain-mlogloss:0.43987\teval-mlogloss:0.61850\n",
      "[34]\ttrain-mlogloss:0.42890\teval-mlogloss:0.61413\n",
      "[35]\ttrain-mlogloss:0.41835\teval-mlogloss:0.60937\n",
      "[36]\ttrain-mlogloss:0.40830\teval-mlogloss:0.60688\n",
      "[37]\ttrain-mlogloss:0.39823\teval-mlogloss:0.60170\n",
      "[38]\ttrain-mlogloss:0.38906\teval-mlogloss:0.59852\n",
      "[39]\ttrain-mlogloss:0.38045\teval-mlogloss:0.59574\n",
      "[40]\ttrain-mlogloss:0.37164\teval-mlogloss:0.59419\n",
      "[41]\ttrain-mlogloss:0.36306\teval-mlogloss:0.59140\n",
      "[42]\ttrain-mlogloss:0.35477\teval-mlogloss:0.58949\n",
      "[43]\ttrain-mlogloss:0.34698\teval-mlogloss:0.58658\n",
      "[44]\ttrain-mlogloss:0.34016\teval-mlogloss:0.58363\n",
      "[45]\ttrain-mlogloss:0.33330\teval-mlogloss:0.58178\n",
      "[46]\ttrain-mlogloss:0.32563\teval-mlogloss:0.57920\n",
      "[47]\ttrain-mlogloss:0.31894\teval-mlogloss:0.57705\n",
      "[48]\ttrain-mlogloss:0.31215\teval-mlogloss:0.57408\n",
      "[49]\ttrain-mlogloss:0.30527\teval-mlogloss:0.57100\n",
      "[50]\ttrain-mlogloss:0.30014\teval-mlogloss:0.56919\n",
      "[51]\ttrain-mlogloss:0.29431\teval-mlogloss:0.56850\n",
      "[52]\ttrain-mlogloss:0.28849\teval-mlogloss:0.56619\n",
      "[53]\ttrain-mlogloss:0.28399\teval-mlogloss:0.56431\n",
      "[54]\ttrain-mlogloss:0.27779\teval-mlogloss:0.56259\n",
      "[55]\ttrain-mlogloss:0.27224\teval-mlogloss:0.56098\n",
      "[56]\ttrain-mlogloss:0.26672\teval-mlogloss:0.56163\n",
      "[57]\ttrain-mlogloss:0.26190\teval-mlogloss:0.56094\n",
      "[58]\ttrain-mlogloss:0.25621\teval-mlogloss:0.55932\n",
      "[59]\ttrain-mlogloss:0.25131\teval-mlogloss:0.55714\n",
      "[60]\ttrain-mlogloss:0.24689\teval-mlogloss:0.55631\n",
      "[61]\ttrain-mlogloss:0.24238\teval-mlogloss:0.55523\n",
      "[62]\ttrain-mlogloss:0.23859\teval-mlogloss:0.55338\n",
      "[63]\ttrain-mlogloss:0.23419\teval-mlogloss:0.55194\n",
      "[64]\ttrain-mlogloss:0.23027\teval-mlogloss:0.54986\n",
      "[65]\ttrain-mlogloss:0.22658\teval-mlogloss:0.54798\n",
      "[66]\ttrain-mlogloss:0.22315\teval-mlogloss:0.54563\n",
      "[67]\ttrain-mlogloss:0.21999\teval-mlogloss:0.54364\n",
      "[68]\ttrain-mlogloss:0.21621\teval-mlogloss:0.54326\n",
      "[69]\ttrain-mlogloss:0.21295\teval-mlogloss:0.54132\n",
      "[70]\ttrain-mlogloss:0.21007\teval-mlogloss:0.54043\n",
      "[71]\ttrain-mlogloss:0.20687\teval-mlogloss:0.53974\n",
      "[72]\ttrain-mlogloss:0.20336\teval-mlogloss:0.53917\n",
      "[73]\ttrain-mlogloss:0.20080\teval-mlogloss:0.53890\n",
      "[74]\ttrain-mlogloss:0.19741\teval-mlogloss:0.53913\n",
      "[75]\ttrain-mlogloss:0.19493\teval-mlogloss:0.53954\n",
      "[76]\ttrain-mlogloss:0.19175\teval-mlogloss:0.53850\n",
      "[77]\ttrain-mlogloss:0.18888\teval-mlogloss:0.53885\n",
      "[78]\ttrain-mlogloss:0.18646\teval-mlogloss:0.53886\n",
      "[79]\ttrain-mlogloss:0.18409\teval-mlogloss:0.53814\n",
      "[80]\ttrain-mlogloss:0.18138\teval-mlogloss:0.53819\n",
      "[81]\ttrain-mlogloss:0.17872\teval-mlogloss:0.53733\n",
      "[82]\ttrain-mlogloss:0.17613\teval-mlogloss:0.53829\n",
      "[83]\ttrain-mlogloss:0.17376\teval-mlogloss:0.53818\n",
      "[84]\ttrain-mlogloss:0.17182\teval-mlogloss:0.53737\n",
      "[85]\ttrain-mlogloss:0.16922\teval-mlogloss:0.53766\n",
      "[86]\ttrain-mlogloss:0.16713\teval-mlogloss:0.53750\n",
      "[87]\ttrain-mlogloss:0.16496\teval-mlogloss:0.53872\n",
      "[88]\ttrain-mlogloss:0.16273\teval-mlogloss:0.53865\n",
      "[89]\ttrain-mlogloss:0.16058\teval-mlogloss:0.53877\n",
      "[90]\ttrain-mlogloss:0.15842\teval-mlogloss:0.53895\n",
      "[91]\ttrain-mlogloss:0.15615\teval-mlogloss:0.53811\n",
      "[92]\ttrain-mlogloss:0.15412\teval-mlogloss:0.53762\n",
      "[93]\ttrain-mlogloss:0.15192\teval-mlogloss:0.53691\n",
      "[94]\ttrain-mlogloss:0.15005\teval-mlogloss:0.53661\n",
      "[95]\ttrain-mlogloss:0.14787\teval-mlogloss:0.53741\n",
      "[96]\ttrain-mlogloss:0.14641\teval-mlogloss:0.53748\n",
      "[97]\ttrain-mlogloss:0.14416\teval-mlogloss:0.53707\n",
      "[98]\ttrain-mlogloss:0.14249\teval-mlogloss:0.53681\n",
      "[99]\ttrain-mlogloss:0.14059\teval-mlogloss:0.53721\n",
      "[100]\ttrain-mlogloss:0.13883\teval-mlogloss:0.53753\n",
      "[101]\ttrain-mlogloss:0.13710\teval-mlogloss:0.53888\n",
      "[102]\ttrain-mlogloss:0.13556\teval-mlogloss:0.53824\n",
      "[103]\ttrain-mlogloss:0.13397\teval-mlogloss:0.53831\n",
      "[104]\ttrain-mlogloss:0.13247\teval-mlogloss:0.53770\n",
      "[105]\ttrain-mlogloss:0.13096\teval-mlogloss:0.53745\n",
      "[106]\ttrain-mlogloss:0.12960\teval-mlogloss:0.53874\n",
      "[107]\ttrain-mlogloss:0.12798\teval-mlogloss:0.53825\n",
      "[108]\ttrain-mlogloss:0.12622\teval-mlogloss:0.53789\n",
      "[109]\ttrain-mlogloss:0.12474\teval-mlogloss:0.53820\n",
      "[110]\ttrain-mlogloss:0.12308\teval-mlogloss:0.53824\n",
      "[111]\ttrain-mlogloss:0.12161\teval-mlogloss:0.53772\n",
      "[112]\ttrain-mlogloss:0.12006\teval-mlogloss:0.53750\n",
      "[113]\ttrain-mlogloss:0.11883\teval-mlogloss:0.53619\n",
      "[114]\ttrain-mlogloss:0.11763\teval-mlogloss:0.53684\n",
      "[115]\ttrain-mlogloss:0.11620\teval-mlogloss:0.53568\n",
      "[116]\ttrain-mlogloss:0.11468\teval-mlogloss:0.53574\n",
      "[117]\ttrain-mlogloss:0.11329\teval-mlogloss:0.53530\n",
      "[118]\ttrain-mlogloss:0.11210\teval-mlogloss:0.53585\n",
      "[119]\ttrain-mlogloss:0.11100\teval-mlogloss:0.53603\n",
      "[120]\ttrain-mlogloss:0.10989\teval-mlogloss:0.53705\n",
      "[121]\ttrain-mlogloss:0.10854\teval-mlogloss:0.53762\n",
      "[122]\ttrain-mlogloss:0.10695\teval-mlogloss:0.53719\n",
      "[123]\ttrain-mlogloss:0.10582\teval-mlogloss:0.53622\n",
      "[124]\ttrain-mlogloss:0.10479\teval-mlogloss:0.53612\n",
      "[125]\ttrain-mlogloss:0.10368\teval-mlogloss:0.53555\n",
      "[126]\ttrain-mlogloss:0.10253\teval-mlogloss:0.53670\n",
      "[127]\ttrain-mlogloss:0.10123\teval-mlogloss:0.53622\n",
      "[128]\ttrain-mlogloss:0.10003\teval-mlogloss:0.53606\n",
      "[129]\ttrain-mlogloss:0.09914\teval-mlogloss:0.53510\n",
      "[130]\ttrain-mlogloss:0.09827\teval-mlogloss:0.53513\n",
      "[131]\ttrain-mlogloss:0.09708\teval-mlogloss:0.53545\n",
      "[132]\ttrain-mlogloss:0.09586\teval-mlogloss:0.53489\n",
      "[133]\ttrain-mlogloss:0.09461\teval-mlogloss:0.53398\n",
      "[134]\ttrain-mlogloss:0.09363\teval-mlogloss:0.53322\n",
      "[135]\ttrain-mlogloss:0.09262\teval-mlogloss:0.53428\n",
      "[136]\ttrain-mlogloss:0.09153\teval-mlogloss:0.53334\n",
      "[137]\ttrain-mlogloss:0.09044\teval-mlogloss:0.53219\n",
      "[138]\ttrain-mlogloss:0.08942\teval-mlogloss:0.53283\n",
      "[139]\ttrain-mlogloss:0.08843\teval-mlogloss:0.53364\n",
      "[140]\ttrain-mlogloss:0.08749\teval-mlogloss:0.53346\n",
      "[141]\ttrain-mlogloss:0.08654\teval-mlogloss:0.53429\n",
      "[142]\ttrain-mlogloss:0.08581\teval-mlogloss:0.53550\n",
      "[143]\ttrain-mlogloss:0.08486\teval-mlogloss:0.53512\n",
      "[144]\ttrain-mlogloss:0.08403\teval-mlogloss:0.53627\n",
      "[145]\ttrain-mlogloss:0.08326\teval-mlogloss:0.53690\n",
      "[146]\ttrain-mlogloss:0.08241\teval-mlogloss:0.53738\n",
      "[147]\ttrain-mlogloss:0.08166\teval-mlogloss:0.53819\n",
      "[148]\ttrain-mlogloss:0.08073\teval-mlogloss:0.53810\n",
      "[149]\ttrain-mlogloss:0.08001\teval-mlogloss:0.53776\n",
      "[150]\ttrain-mlogloss:0.07917\teval-mlogloss:0.53811\n",
      "[151]\ttrain-mlogloss:0.07825\teval-mlogloss:0.53814\n",
      "[152]\ttrain-mlogloss:0.07758\teval-mlogloss:0.53829\n",
      "[153]\ttrain-mlogloss:0.07679\teval-mlogloss:0.53821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[154]\ttrain-mlogloss:0.07586\teval-mlogloss:0.53859\n",
      "[155]\ttrain-mlogloss:0.07515\teval-mlogloss:0.53809\n",
      "[156]\ttrain-mlogloss:0.07432\teval-mlogloss:0.53885\n",
      "[157]\ttrain-mlogloss:0.07356\teval-mlogloss:0.53911\n",
      "[158]\ttrain-mlogloss:0.07286\teval-mlogloss:0.53812\n",
      "[159]\ttrain-mlogloss:0.07214\teval-mlogloss:0.53908\n",
      "[160]\ttrain-mlogloss:0.07149\teval-mlogloss:0.53970\n",
      "[161]\ttrain-mlogloss:0.07085\teval-mlogloss:0.53975\n",
      "[162]\ttrain-mlogloss:0.07019\teval-mlogloss:0.53901\n",
      "[163]\ttrain-mlogloss:0.06951\teval-mlogloss:0.54001\n",
      "[164]\ttrain-mlogloss:0.06887\teval-mlogloss:0.53961\n",
      "[165]\ttrain-mlogloss:0.06811\teval-mlogloss:0.53860\n",
      "[166]\ttrain-mlogloss:0.06752\teval-mlogloss:0.53814\n",
      "[167]\ttrain-mlogloss:0.06689\teval-mlogloss:0.53932\n",
      "[168]\ttrain-mlogloss:0.06617\teval-mlogloss:0.53933\n",
      "[169]\ttrain-mlogloss:0.06552\teval-mlogloss:0.53895\n",
      "[170]\ttrain-mlogloss:0.06484\teval-mlogloss:0.54014\n",
      "[171]\ttrain-mlogloss:0.06418\teval-mlogloss:0.54057\n",
      "[172]\ttrain-mlogloss:0.06358\teval-mlogloss:0.54042\n",
      "[173]\ttrain-mlogloss:0.06300\teval-mlogloss:0.54039\n",
      "[174]\ttrain-mlogloss:0.06247\teval-mlogloss:0.54069\n",
      "[175]\ttrain-mlogloss:0.06187\teval-mlogloss:0.54067\n",
      "[176]\ttrain-mlogloss:0.06126\teval-mlogloss:0.53972\n",
      "[177]\ttrain-mlogloss:0.06071\teval-mlogloss:0.54002\n",
      "[178]\ttrain-mlogloss:0.06011\teval-mlogloss:0.54000\n",
      "[179]\ttrain-mlogloss:0.05962\teval-mlogloss:0.53936\n",
      "[180]\ttrain-mlogloss:0.05904\teval-mlogloss:0.53939\n",
      "[181]\ttrain-mlogloss:0.05853\teval-mlogloss:0.53913\n",
      "[182]\ttrain-mlogloss:0.05807\teval-mlogloss:0.53930\n",
      "[183]\ttrain-mlogloss:0.05753\teval-mlogloss:0.54032\n",
      "[184]\ttrain-mlogloss:0.05693\teval-mlogloss:0.53927\n",
      "[185]\ttrain-mlogloss:0.05628\teval-mlogloss:0.53925\n",
      "[186]\ttrain-mlogloss:0.05571\teval-mlogloss:0.53935\n",
      "[187]\ttrain-mlogloss:0.05519\teval-mlogloss:0.53913\n",
      "[188]\ttrain-mlogloss:0.05466\teval-mlogloss:0.53950\n",
      "[189]\ttrain-mlogloss:0.05398\teval-mlogloss:0.53739\n",
      "[190]\ttrain-mlogloss:0.05360\teval-mlogloss:0.53663\n",
      "[191]\ttrain-mlogloss:0.05313\teval-mlogloss:0.53622\n",
      "[192]\ttrain-mlogloss:0.05264\teval-mlogloss:0.53616\n",
      "[193]\ttrain-mlogloss:0.05207\teval-mlogloss:0.53603\n",
      "[194]\ttrain-mlogloss:0.05157\teval-mlogloss:0.53627\n",
      "[195]\ttrain-mlogloss:0.05099\teval-mlogloss:0.53588\n",
      "[196]\ttrain-mlogloss:0.05048\teval-mlogloss:0.53628\n",
      "[197]\ttrain-mlogloss:0.05002\teval-mlogloss:0.53676\n",
      "[198]\ttrain-mlogloss:0.04955\teval-mlogloss:0.53674\n",
      "[199]\ttrain-mlogloss:0.04906\teval-mlogloss:0.53693\n",
      "[200]\ttrain-mlogloss:0.04868\teval-mlogloss:0.53665\n",
      "[201]\ttrain-mlogloss:0.04827\teval-mlogloss:0.53641\n",
      "[202]\ttrain-mlogloss:0.04790\teval-mlogloss:0.53637\n",
      "[203]\ttrain-mlogloss:0.04746\teval-mlogloss:0.53661\n",
      "[204]\ttrain-mlogloss:0.04707\teval-mlogloss:0.53634\n",
      "[205]\ttrain-mlogloss:0.04672\teval-mlogloss:0.53589\n",
      "[206]\ttrain-mlogloss:0.04627\teval-mlogloss:0.53587\n",
      "[207]\ttrain-mlogloss:0.04586\teval-mlogloss:0.53622\n",
      "[208]\ttrain-mlogloss:0.04544\teval-mlogloss:0.53585\n",
      "[209]\ttrain-mlogloss:0.04502\teval-mlogloss:0.53578\n",
      "[210]\ttrain-mlogloss:0.04458\teval-mlogloss:0.53582\n",
      "[211]\ttrain-mlogloss:0.04416\teval-mlogloss:0.53546\n",
      "[212]\ttrain-mlogloss:0.04381\teval-mlogloss:0.53530\n",
      "[213]\ttrain-mlogloss:0.04330\teval-mlogloss:0.53520\n",
      "[214]\ttrain-mlogloss:0.04295\teval-mlogloss:0.53562\n",
      "[215]\ttrain-mlogloss:0.04255\teval-mlogloss:0.53461\n",
      "[216]\ttrain-mlogloss:0.04215\teval-mlogloss:0.53408\n",
      "[217]\ttrain-mlogloss:0.04179\teval-mlogloss:0.53406\n",
      "[218]\ttrain-mlogloss:0.04139\teval-mlogloss:0.53421\n",
      "[219]\ttrain-mlogloss:0.04101\teval-mlogloss:0.53455\n",
      "[220]\ttrain-mlogloss:0.04068\teval-mlogloss:0.53420\n",
      "[221]\ttrain-mlogloss:0.04031\teval-mlogloss:0.53422\n",
      "[222]\ttrain-mlogloss:0.04002\teval-mlogloss:0.53425\n",
      "[223]\ttrain-mlogloss:0.03969\teval-mlogloss:0.53362\n",
      "[224]\ttrain-mlogloss:0.03938\teval-mlogloss:0.53287\n",
      "[225]\ttrain-mlogloss:0.03906\teval-mlogloss:0.53327\n",
      "[226]\ttrain-mlogloss:0.03878\teval-mlogloss:0.53322\n",
      "[227]\ttrain-mlogloss:0.03839\teval-mlogloss:0.53280\n",
      "[228]\ttrain-mlogloss:0.03811\teval-mlogloss:0.53291\n",
      "[229]\ttrain-mlogloss:0.03780\teval-mlogloss:0.53266\n",
      "[230]\ttrain-mlogloss:0.03755\teval-mlogloss:0.53338\n",
      "[231]\ttrain-mlogloss:0.03724\teval-mlogloss:0.53351\n",
      "[232]\ttrain-mlogloss:0.03692\teval-mlogloss:0.53418\n",
      "[233]\ttrain-mlogloss:0.03659\teval-mlogloss:0.53380\n",
      "[234]\ttrain-mlogloss:0.03628\teval-mlogloss:0.53399\n",
      "[235]\ttrain-mlogloss:0.03595\teval-mlogloss:0.53381\n",
      "[236]\ttrain-mlogloss:0.03569\teval-mlogloss:0.53388\n"
     ]
    }
   ],
   "source": [
    "#t7_0.53219 ########성능 0.683\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, \n",
    "                                                    test_size=0.1, \n",
    "                                                    stratify=train_y, \n",
    "                                                    random_state=37)\n",
    "\n",
    "dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(data=X_test, label=y_test)\n",
    "dtest_x = xgb.DMatrix(data=test_x)\n",
    "\n",
    "params = {'max_depth' : 6,\n",
    "          'eta': 0.04,\n",
    "          'objective':'multi:softmax',\n",
    "          'num_class':3,\n",
    "          'eval_metric':'mlogloss',\n",
    "          'eval_set': [(X_test, y_test)], #적용이 안 되고 있다고 뜸\n",
    "          'early_stopping':100 #적용이 안 되고 있다고 뜸\n",
    "          }\n",
    "num_rounds = 400\n",
    "\n",
    "wlist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "xgb_model = xgb.train(params=params, \n",
    "                      dtrain=dtrain, \n",
    "                      num_boost_round=num_rounds, \n",
    "                      early_stopping_rounds=100, \n",
    "                      evals=wlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "127aa3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137\n",
      "138\n",
      "0.5321924893185497\n"
     ]
    }
   ],
   "source": [
    "print(xgb_model.best_iteration)\n",
    "print(xgb_model.best_ntree_limit)\n",
    "print(xgb_model.best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7aef602",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = xgb_model.predict(dtest_x, ntree_limit=xgb_model.best_ntree_limit)\n",
    "preds = np.round(pred_probs).astype(int)\n",
    "sub['Y_Class'] = preds\n",
    "sub.to_csv('./t30_XGB_Dmatrix_Earlystopping_eta004_testsize01.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f817d5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 저장\n",
    "with open('model_XGB_0683.pickle','wb') as fw:\n",
    "    pickle.dump(xgb_model, fw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pas",
   "language": "python",
   "name": "pas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "0c732c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings; warnings.filterwarnings(action='ignore')\n",
    "import pickle\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import sklearn.svm as svm\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "from xgboost import plot_importance\n",
    "from scipy.stats import randint\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c407cb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed) #파이썬 자체 모듈 random 모듈의 시드 고정\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) \n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(37) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33209ff9",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "864c76d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "149a45e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('./sample_submission.csv')\n",
    "sub2 = pd.read_csv('./sample_submission.csv')\n",
    "sub3 = pd.read_csv('./sample_submission.csv')\n",
    "sub4 = pd.read_csv('./sample_submission.csv')\n",
    "sub5 = pd.read_csv('./sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8c7839",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "7913ec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_010 = train_df[(train_df['LINE']=='T010306') | (train_df['LINE']=='T010305')]\n",
    "train_050 = train_df[(train_df['LINE']=='T050304') | (train_df['LINE']=='T050307')]\n",
    "train_100 = train_df[(train_df['LINE']=='T100306') | (train_df['LINE']=='T100304')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "3c5ac86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_010 = test_df[(test_df['LINE']=='T010306') | (test_df['LINE']=='T010305')]\n",
    "test_050 = test_df[(test_df['LINE']=='T050304') | (test_df['LINE']=='T050307')]\n",
    "test_100 = test_df[(test_df['LINE']=='T100304') | (test_df['LINE']=='T100306')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "024814e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n",
      "120\n",
      "349\n"
     ]
    }
   ],
   "source": [
    "print(len(train_010)) #196 245\n",
    "print(len(train_050))\n",
    "print(len(train_100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "879f3881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "39\n",
      "243\n"
     ]
    }
   ],
   "source": [
    "print(len(test_010)) #196 245\n",
    "print(len(test_050))\n",
    "print(len(test_100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61893824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "ae41a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_100['Y_Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "606f458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_100.drop(columns = ['PRODUCT_ID', 'TIMESTAMP', 'Y_Class', 'Y_Quality'])\n",
    "test_x = test_100.drop(columns=['PRODUCT_ID', 'TIMESTAMP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "0c158f97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 230,\n",
       " 231,\n",
       " 232,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 236,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 240,\n",
       " 241,\n",
       " 242,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 246,\n",
       " 247,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 259,\n",
       " 261,\n",
       " 262,\n",
       " 264,\n",
       " 265,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 270,\n",
       " 271,\n",
       " 272,\n",
       " 273,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 279,\n",
       " 287,\n",
       " 288,\n",
       " 289,\n",
       " 290,\n",
       " 291,\n",
       " 294,\n",
       " 295,\n",
       " 296,\n",
       " 297,\n",
       " 298,\n",
       " 299,\n",
       " 300,\n",
       " 301,\n",
       " 302,\n",
       " 303,\n",
       " 304,\n",
       " 305,\n",
       " 306,\n",
       " 307,\n",
       " 308,\n",
       " 309]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1 = test_x.index.tolist() #28 #39 # \n",
    "p1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd74ac6",
   "metadata": {},
   "source": [
    "범주형 데이터를 수치 데이터로 전환하기 위해 LabelEncoder 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "53adcf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# qualitative to quantitative\n",
    "qual_col = ['LINE', 'PRODUCT_CODE']\n",
    "\n",
    "for i in qual_col:\n",
    "    le = LabelEncoder()\n",
    "    le = le.fit(train_x[i]) #원래 column 값을 기준으로 fit.\n",
    "    train_x[i] = le.transform(train_x[i]) #수치화, 수치로 변형\n",
    "\n",
    "    for label in np.unique(test_x[i]): \n",
    "        if label not in le.classes_: \n",
    "            le.classes_ = np.append(le.classes_, label)\n",
    "    test_x[i] = le.transform(test_x[i]) \n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55a73f6",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add2ad95",
   "metadata": {},
   "source": [
    "학습용과 테스트용 데이터 세트를 위해 별도의 Dmatrix를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "c843a7ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.05831\teval-mlogloss:1.06865\n",
      "[1]\ttrain-mlogloss:1.02135\teval-mlogloss:1.03825\n",
      "[2]\ttrain-mlogloss:0.98582\teval-mlogloss:1.01160\n",
      "[3]\ttrain-mlogloss:0.95312\teval-mlogloss:0.98509\n",
      "[4]\ttrain-mlogloss:0.92077\teval-mlogloss:0.96043\n",
      "[5]\ttrain-mlogloss:0.89129\teval-mlogloss:0.93739\n",
      "[6]\ttrain-mlogloss:0.86193\teval-mlogloss:0.91788\n",
      "[7]\ttrain-mlogloss:0.83444\teval-mlogloss:0.89757\n",
      "[8]\ttrain-mlogloss:0.80886\teval-mlogloss:0.87742\n",
      "[9]\ttrain-mlogloss:0.78349\teval-mlogloss:0.86147\n",
      "[10]\ttrain-mlogloss:0.75970\teval-mlogloss:0.84404\n",
      "[11]\ttrain-mlogloss:0.73745\teval-mlogloss:0.82866\n",
      "[12]\ttrain-mlogloss:0.71576\teval-mlogloss:0.81398\n",
      "[13]\ttrain-mlogloss:0.69549\teval-mlogloss:0.80028\n",
      "[14]\ttrain-mlogloss:0.67507\teval-mlogloss:0.78717\n",
      "[15]\ttrain-mlogloss:0.65485\teval-mlogloss:0.77542\n",
      "[16]\ttrain-mlogloss:0.63566\teval-mlogloss:0.76296\n",
      "[17]\ttrain-mlogloss:0.61755\teval-mlogloss:0.75108\n",
      "[18]\ttrain-mlogloss:0.59985\teval-mlogloss:0.74139\n",
      "[19]\ttrain-mlogloss:0.58289\teval-mlogloss:0.73190\n",
      "[20]\ttrain-mlogloss:0.56698\teval-mlogloss:0.72180\n",
      "[21]\ttrain-mlogloss:0.55139\teval-mlogloss:0.71343\n",
      "[22]\ttrain-mlogloss:0.53562\teval-mlogloss:0.70375\n",
      "[23]\ttrain-mlogloss:0.52101\teval-mlogloss:0.69604\n",
      "[24]\ttrain-mlogloss:0.50684\teval-mlogloss:0.68852\n",
      "[25]\ttrain-mlogloss:0.49289\teval-mlogloss:0.68126\n",
      "[26]\ttrain-mlogloss:0.47978\teval-mlogloss:0.67487\n",
      "[27]\ttrain-mlogloss:0.46731\teval-mlogloss:0.66947\n",
      "[28]\ttrain-mlogloss:0.45522\teval-mlogloss:0.66289\n",
      "[29]\ttrain-mlogloss:0.44308\teval-mlogloss:0.65747\n",
      "[30]\ttrain-mlogloss:0.43098\teval-mlogloss:0.65247\n",
      "[31]\ttrain-mlogloss:0.41780\teval-mlogloss:0.65100\n",
      "[32]\ttrain-mlogloss:0.40511\teval-mlogloss:0.64927\n",
      "[33]\ttrain-mlogloss:0.39289\teval-mlogloss:0.64789\n",
      "[34]\ttrain-mlogloss:0.38136\teval-mlogloss:0.64388\n",
      "[35]\ttrain-mlogloss:0.37020\teval-mlogloss:0.64216\n",
      "[36]\ttrain-mlogloss:0.35950\teval-mlogloss:0.63787\n",
      "[37]\ttrain-mlogloss:0.34919\teval-mlogloss:0.63476\n",
      "[38]\ttrain-mlogloss:0.33906\teval-mlogloss:0.63405\n",
      "[39]\ttrain-mlogloss:0.32924\teval-mlogloss:0.63335\n",
      "[40]\ttrain-mlogloss:0.31984\teval-mlogloss:0.63073\n",
      "[41]\ttrain-mlogloss:0.31072\teval-mlogloss:0.63026\n",
      "[42]\ttrain-mlogloss:0.30212\teval-mlogloss:0.63045\n",
      "[43]\ttrain-mlogloss:0.29352\teval-mlogloss:0.63030\n",
      "[44]\ttrain-mlogloss:0.28522\teval-mlogloss:0.62902\n",
      "[45]\ttrain-mlogloss:0.27781\teval-mlogloss:0.62730\n",
      "[46]\ttrain-mlogloss:0.27004\teval-mlogloss:0.62791\n",
      "[47]\ttrain-mlogloss:0.26240\teval-mlogloss:0.62872\n",
      "[48]\ttrain-mlogloss:0.25535\teval-mlogloss:0.62752\n",
      "[49]\ttrain-mlogloss:0.24832\teval-mlogloss:0.62693\n",
      "[50]\ttrain-mlogloss:0.24214\teval-mlogloss:0.62599\n",
      "[51]\ttrain-mlogloss:0.23559\teval-mlogloss:0.62694\n",
      "[52]\ttrain-mlogloss:0.22923\teval-mlogloss:0.62709\n",
      "[53]\ttrain-mlogloss:0.22312\teval-mlogloss:0.62777\n",
      "[54]\ttrain-mlogloss:0.21701\teval-mlogloss:0.62913\n",
      "[55]\ttrain-mlogloss:0.21135\teval-mlogloss:0.63060\n",
      "[56]\ttrain-mlogloss:0.20575\teval-mlogloss:0.63005\n",
      "[57]\ttrain-mlogloss:0.20081\teval-mlogloss:0.63021\n",
      "[58]\ttrain-mlogloss:0.19561\teval-mlogloss:0.63165\n",
      "[59]\ttrain-mlogloss:0.19049\teval-mlogloss:0.63241\n",
      "[60]\ttrain-mlogloss:0.18587\teval-mlogloss:0.63196\n",
      "[61]\ttrain-mlogloss:0.18086\teval-mlogloss:0.63511\n",
      "[62]\ttrain-mlogloss:0.17650\teval-mlogloss:0.63626\n",
      "[63]\ttrain-mlogloss:0.17191\teval-mlogloss:0.63903\n",
      "[64]\ttrain-mlogloss:0.16748\teval-mlogloss:0.64040\n",
      "[65]\ttrain-mlogloss:0.16357\teval-mlogloss:0.64177\n",
      "[66]\ttrain-mlogloss:0.15964\teval-mlogloss:0.64398\n",
      "[67]\ttrain-mlogloss:0.15570\teval-mlogloss:0.64549\n",
      "[68]\ttrain-mlogloss:0.15183\teval-mlogloss:0.64752\n",
      "[69]\ttrain-mlogloss:0.14804\teval-mlogloss:0.64963\n",
      "[70]\ttrain-mlogloss:0.14483\teval-mlogloss:0.65115\n",
      "[71]\ttrain-mlogloss:0.14146\teval-mlogloss:0.65277\n",
      "[72]\ttrain-mlogloss:0.13821\teval-mlogloss:0.65446\n",
      "[73]\ttrain-mlogloss:0.13495\teval-mlogloss:0.65609\n",
      "[74]\ttrain-mlogloss:0.13209\teval-mlogloss:0.65733\n",
      "[75]\ttrain-mlogloss:0.12897\teval-mlogloss:0.65723\n",
      "[76]\ttrain-mlogloss:0.12600\teval-mlogloss:0.65991\n",
      "[77]\ttrain-mlogloss:0.12321\teval-mlogloss:0.66089\n",
      "[78]\ttrain-mlogloss:0.12053\teval-mlogloss:0.66245\n",
      "[79]\ttrain-mlogloss:0.11775\teval-mlogloss:0.66189\n",
      "[80]\ttrain-mlogloss:0.11517\teval-mlogloss:0.66423\n",
      "[81]\ttrain-mlogloss:0.11256\teval-mlogloss:0.66574\n",
      "[82]\ttrain-mlogloss:0.11026\teval-mlogloss:0.66718\n",
      "[83]\ttrain-mlogloss:0.10790\teval-mlogloss:0.66751\n",
      "[84]\ttrain-mlogloss:0.10552\teval-mlogloss:0.66931\n",
      "[85]\ttrain-mlogloss:0.10334\teval-mlogloss:0.66960\n",
      "[86]\ttrain-mlogloss:0.10121\teval-mlogloss:0.67185\n",
      "[87]\ttrain-mlogloss:0.09899\teval-mlogloss:0.67253\n",
      "[88]\ttrain-mlogloss:0.09699\teval-mlogloss:0.67307\n",
      "[89]\ttrain-mlogloss:0.09497\teval-mlogloss:0.67659\n",
      "[90]\ttrain-mlogloss:0.09303\teval-mlogloss:0.67873\n",
      "[91]\ttrain-mlogloss:0.09113\teval-mlogloss:0.67931\n",
      "[92]\ttrain-mlogloss:0.08930\teval-mlogloss:0.67984\n",
      "[93]\ttrain-mlogloss:0.08754\teval-mlogloss:0.67985\n",
      "[94]\ttrain-mlogloss:0.08576\teval-mlogloss:0.68221\n",
      "[95]\ttrain-mlogloss:0.08402\teval-mlogloss:0.68434\n",
      "[96]\ttrain-mlogloss:0.08234\teval-mlogloss:0.68513\n",
      "[97]\ttrain-mlogloss:0.08079\teval-mlogloss:0.68806\n",
      "[98]\ttrain-mlogloss:0.07918\teval-mlogloss:0.69065\n",
      "[99]\ttrain-mlogloss:0.07773\teval-mlogloss:0.69356\n",
      "[100]\ttrain-mlogloss:0.07623\teval-mlogloss:0.69346\n",
      "[101]\ttrain-mlogloss:0.07481\teval-mlogloss:0.69439\n",
      "[102]\ttrain-mlogloss:0.07336\teval-mlogloss:0.69759\n",
      "[103]\ttrain-mlogloss:0.07199\teval-mlogloss:0.69818\n",
      "[104]\ttrain-mlogloss:0.07070\teval-mlogloss:0.69952\n",
      "[105]\ttrain-mlogloss:0.06939\teval-mlogloss:0.70013\n",
      "[106]\ttrain-mlogloss:0.06816\teval-mlogloss:0.70132\n",
      "[107]\ttrain-mlogloss:0.06690\teval-mlogloss:0.70357\n",
      "[108]\ttrain-mlogloss:0.06575\teval-mlogloss:0.70638\n",
      "[109]\ttrain-mlogloss:0.06456\teval-mlogloss:0.70843\n",
      "[110]\ttrain-mlogloss:0.06345\teval-mlogloss:0.70787\n",
      "[111]\ttrain-mlogloss:0.06238\teval-mlogloss:0.71034\n",
      "[112]\ttrain-mlogloss:0.06133\teval-mlogloss:0.71069\n",
      "[113]\ttrain-mlogloss:0.06026\teval-mlogloss:0.71262\n",
      "[114]\ttrain-mlogloss:0.05927\teval-mlogloss:0.71444\n",
      "[115]\ttrain-mlogloss:0.05834\teval-mlogloss:0.71550\n",
      "[116]\ttrain-mlogloss:0.05744\teval-mlogloss:0.71710\n",
      "[117]\ttrain-mlogloss:0.05647\teval-mlogloss:0.71957\n",
      "[118]\ttrain-mlogloss:0.05560\teval-mlogloss:0.72150\n",
      "[119]\ttrain-mlogloss:0.05473\teval-mlogloss:0.72252\n",
      "[120]\ttrain-mlogloss:0.05391\teval-mlogloss:0.72435\n",
      "[121]\ttrain-mlogloss:0.05304\teval-mlogloss:0.72738\n",
      "[122]\ttrain-mlogloss:0.05226\teval-mlogloss:0.72826\n",
      "[123]\ttrain-mlogloss:0.05147\teval-mlogloss:0.72893\n",
      "[124]\ttrain-mlogloss:0.05071\teval-mlogloss:0.73060\n",
      "[125]\ttrain-mlogloss:0.04990\teval-mlogloss:0.73294\n",
      "[126]\ttrain-mlogloss:0.04918\teval-mlogloss:0.73354\n",
      "[127]\ttrain-mlogloss:0.04847\teval-mlogloss:0.73540\n",
      "[128]\ttrain-mlogloss:0.04779\teval-mlogloss:0.73668\n",
      "[129]\ttrain-mlogloss:0.04712\teval-mlogloss:0.73726\n",
      "[130]\ttrain-mlogloss:0.04645\teval-mlogloss:0.73785\n",
      "[131]\ttrain-mlogloss:0.04583\teval-mlogloss:0.73859\n",
      "[132]\ttrain-mlogloss:0.04521\teval-mlogloss:0.74029\n",
      "[133]\ttrain-mlogloss:0.04456\teval-mlogloss:0.74114\n",
      "[134]\ttrain-mlogloss:0.04397\teval-mlogloss:0.74201\n",
      "[135]\ttrain-mlogloss:0.04340\teval-mlogloss:0.74256\n",
      "[136]\ttrain-mlogloss:0.04284\teval-mlogloss:0.74336\n",
      "[137]\ttrain-mlogloss:0.04229\teval-mlogloss:0.74552\n",
      "[138]\ttrain-mlogloss:0.04174\teval-mlogloss:0.74713\n",
      "[139]\ttrain-mlogloss:0.04121\teval-mlogloss:0.74999\n",
      "[140]\ttrain-mlogloss:0.04065\teval-mlogloss:0.75140\n",
      "[141]\ttrain-mlogloss:0.04015\teval-mlogloss:0.75343\n",
      "[142]\ttrain-mlogloss:0.03964\teval-mlogloss:0.75466\n",
      "[143]\ttrain-mlogloss:0.03916\teval-mlogloss:0.75592\n",
      "[144]\ttrain-mlogloss:0.03867\teval-mlogloss:0.75693\n",
      "[145]\ttrain-mlogloss:0.03820\teval-mlogloss:0.75824\n",
      "[146]\ttrain-mlogloss:0.03778\teval-mlogloss:0.75949\n",
      "[147]\ttrain-mlogloss:0.03733\teval-mlogloss:0.76051\n",
      "[148]\ttrain-mlogloss:0.03686\teval-mlogloss:0.76223\n",
      "[149]\ttrain-mlogloss:0.03641\teval-mlogloss:0.76344\n",
      "[150]\ttrain-mlogloss:0.03603\teval-mlogloss:0.76468\n"
     ]
    }
   ],
   "source": [
    "#t7_0.53219 ########성능 0.683 testsize만 0.2로 바꿨더니 0.653\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    stratify=train_y, \n",
    "                                                    random_state=37)\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(data=X_test, label=y_test)\n",
    "dtest_x = xgb.DMatrix(data=test_x)\n",
    "\n",
    "params = {'max_depth' : 6,\n",
    "          'eta': 0.035,\n",
    "          'objective':'multi:softmax',\n",
    "          'num_class':3,\n",
    "          'eval_metric':'mlogloss'\n",
    "          }\n",
    "num_rounds = 400\n",
    "\n",
    "wlist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "xgb_model = xgb.train(params=params, \n",
    "                      dtrain=dtrain, \n",
    "                      num_boost_round=num_rounds, \n",
    "                      early_stopping_rounds=100, \n",
    "                      evals=wlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "e7aef602",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_class\n",
       "p1          \n",
       "3          1\n",
       "4          1\n",
       "5          1\n",
       "6          1\n",
       "9          1\n",
       "10         1\n",
       "11         1\n",
       "12         1\n",
       "37         0\n",
       "38         0\n",
       "39         0\n",
       "40         0\n",
       "71         0\n",
       "72         1\n",
       "79         1\n",
       "86         0\n",
       "87         1\n",
       "88         0\n",
       "89         1\n",
       "109        1\n",
       "114        1\n",
       "115        1\n",
       "116        1\n",
       "117        1\n",
       "128        0\n",
       "129        2\n",
       "141        1\n",
       "142        1"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pred_probs = xgb_model.predict(dtest_x, ntree_limit=xgb_model.best_ntree_limit)\n",
    "y_preds = xgb_model.predict(dtest_x, ntree_limit=xgb_model.best_ntree_limit)\n",
    "preds_1 = np.round(y_preds).astype(int)\n",
    "preds1 = pd.DataFrame(preds_1)\n",
    "p1 = pd.Series(data = p1)\n",
    "preds10 = pd.concat([preds1, p1], axis = 1)\n",
    "preds10.columns = ['y_class', 'p1']\n",
    "preds10.index = preds10['p1']\n",
    "del preds10['p1']\n",
    "preds10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "b0650494",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_class\n",
       "p1          \n",
       "7          0\n",
       "8          1\n",
       "13         2\n",
       "14         0\n",
       "35         0\n",
       "36         2\n",
       "41         0\n",
       "42         0\n",
       "52         0\n",
       "53         0\n",
       "54         0\n",
       "61         1\n",
       "62         2\n",
       "63         0\n",
       "64         0\n",
       "65         0\n",
       "66         1\n",
       "130        0\n",
       "131        0\n",
       "132        0\n",
       "248        2\n",
       "249        2\n",
       "250        2\n",
       "251        2\n",
       "252        2\n",
       "253        2\n",
       "254        2\n",
       "255        2\n",
       "260        2\n",
       "263        2\n",
       "280        2\n",
       "281        2\n",
       "282        2\n",
       "283        2\n",
       "284        2\n",
       "285        2\n",
       "286        2\n",
       "292        2\n",
       "293        2"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = xgb_model.predict(dtest_x, ntree_limit=xgb_model.best_ntree_limit)\n",
    "preds_2 = np.round(y_preds).astype(int)\n",
    "preds2 = pd.DataFrame(preds_2)\n",
    "p1 = pd.Series(data = p1)\n",
    "preds20 = pd.concat([preds2, p1], axis = 1)\n",
    "preds20.columns = ['y_class', 'p1']\n",
    "preds20.index = preds20['p1']\n",
    "del preds20['p1']\n",
    "preds20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "89fdabe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_class\n",
       "p1          \n",
       "0          1\n",
       "1          2\n",
       "2          1\n",
       "15         1\n",
       "16         1\n",
       "..       ...\n",
       "305        2\n",
       "306        1\n",
       "307        1\n",
       "308        2\n",
       "309        2\n",
       "\n",
       "[243 rows x 1 columns]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = xgb_model.predict(dtest_x, ntree_limit=xgb_model.best_ntree_limit)\n",
    "preds_3 = np.round(y_preds).astype(int)\n",
    "preds3 = pd.DataFrame(preds_3)\n",
    "p1 = pd.Series(data = p1)\n",
    "preds30 = pd.concat([preds3, p1], axis = 1)\n",
    "preds30.columns = ['y_class', 'p1']\n",
    "preds30.index = preds30['p1']\n",
    "del preds30['p1']\n",
    "preds30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "65e54749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_class\n",
       "p1          \n",
       "69         1\n",
       "70         1\n",
       "73         1\n",
       "74         1\n",
       "75         1\n",
       "76         1\n",
       "77         1\n",
       "78         2\n",
       "80         1\n",
       "81         1\n",
       "82         0\n",
       "83         1\n",
       "84         2\n",
       "85         1\n",
       "90         1\n",
       "91         1\n",
       "92         2\n",
       "93         1\n",
       "94         1\n",
       "95         1\n",
       "96         1\n",
       "97         2\n",
       "98         1\n",
       "99         2\n",
       "100        1\n",
       "101        2\n",
       "102        1\n",
       "103        1\n",
       "104        1\n",
       "105        1\n",
       "106        2\n",
       "107        1\n",
       "108        1\n",
       "110        1\n",
       "111        1\n",
       "112        1\n",
       "113        1\n",
       "118        1\n",
       "119        2\n",
       "120        1"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds30[40:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "d5e2d8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.concat([preds10, preds20, preds30], axis = 0)\n",
    "preds = preds.sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "8ada9d2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_class\n",
       "p1          \n",
       "0          1\n",
       "1          2\n",
       "2          1\n",
       "3          1\n",
       "4          1\n",
       "..       ...\n",
       "305        2\n",
       "306        1\n",
       "307        1\n",
       "308        2\n",
       "309        2\n",
       "\n",
       "[310 rows x 1 columns]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "08cccd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2['Y_Class'] = preds['y_class']\n",
    "sub2.to_csv('./t30_XGB_sep_LINEdata_com.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "fc7879d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_class\n",
       "p1          \n",
       "0          1\n",
       "1          2\n",
       "2          1\n",
       "3          1\n",
       "4          1\n",
       "..       ...\n",
       "305        2\n",
       "306        1\n",
       "307        1\n",
       "308        2\n",
       "309        2\n",
       "\n",
       "[310 rows x 1 columns]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "62e72ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>310.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.980645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.425269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Y_Class\n",
       "count  310.000000\n",
       "mean     0.980645\n",
       "std      0.425269\n",
       "min      0.000000\n",
       "25%      1.000000\n",
       "50%      1.000000\n",
       "75%      1.000000\n",
       "max      2.000000"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm = pd.read_csv('/Users/kimminyoung/Desktop/Dacon_SmartFactory/t30_XGB_sep_LINEdata_com.csv')\n",
    "subm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9f8f217b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6530173736877647\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_model.predict(dtest, ntree_limit=xgb_model.best_ntree_limit)\n",
    "preds = np.round(y_pred).astype(int)\n",
    "print(f1_score(y_test, preds, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "22e1c7bb",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.05928\teval-mlogloss:1.06846\n",
      "[1]\ttrain-mlogloss:1.02224\teval-mlogloss:1.03964\n",
      "[2]\ttrain-mlogloss:0.98753\teval-mlogloss:1.01551\n",
      "[3]\ttrain-mlogloss:0.95449\teval-mlogloss:0.99104\n",
      "[4]\ttrain-mlogloss:0.92392\teval-mlogloss:0.96798\n",
      "[5]\ttrain-mlogloss:0.89469\teval-mlogloss:0.94454\n",
      "[6]\ttrain-mlogloss:0.86730\teval-mlogloss:0.92149\n",
      "[7]\ttrain-mlogloss:0.84109\teval-mlogloss:0.90036\n",
      "[8]\ttrain-mlogloss:0.81629\teval-mlogloss:0.88033\n",
      "[9]\ttrain-mlogloss:0.79239\teval-mlogloss:0.85956\n",
      "[10]\ttrain-mlogloss:0.77003\teval-mlogloss:0.84263\n",
      "[11]\ttrain-mlogloss:0.74875\teval-mlogloss:0.82553\n",
      "[12]\ttrain-mlogloss:0.72855\teval-mlogloss:0.80987\n",
      "[13]\ttrain-mlogloss:0.70990\teval-mlogloss:0.79619\n",
      "[14]\ttrain-mlogloss:0.69126\teval-mlogloss:0.78199\n",
      "[15]\ttrain-mlogloss:0.67458\teval-mlogloss:0.76859\n",
      "[16]\ttrain-mlogloss:0.65735\teval-mlogloss:0.75758\n",
      "[17]\ttrain-mlogloss:0.64150\teval-mlogloss:0.74715\n",
      "[18]\ttrain-mlogloss:0.62598\teval-mlogloss:0.73522\n",
      "[19]\ttrain-mlogloss:0.61060\teval-mlogloss:0.72494\n",
      "[20]\ttrain-mlogloss:0.59582\teval-mlogloss:0.71527\n",
      "[21]\ttrain-mlogloss:0.58137\teval-mlogloss:0.70548\n",
      "[22]\ttrain-mlogloss:0.56725\teval-mlogloss:0.69478\n",
      "[23]\ttrain-mlogloss:0.55440\teval-mlogloss:0.68466\n",
      "[24]\ttrain-mlogloss:0.54090\teval-mlogloss:0.67543\n",
      "[25]\ttrain-mlogloss:0.52912\teval-mlogloss:0.66729\n",
      "[26]\ttrain-mlogloss:0.51600\teval-mlogloss:0.65835\n",
      "[27]\ttrain-mlogloss:0.50524\teval-mlogloss:0.65200\n",
      "[28]\ttrain-mlogloss:0.49457\teval-mlogloss:0.64593\n",
      "[29]\ttrain-mlogloss:0.48273\teval-mlogloss:0.63933\n",
      "[30]\ttrain-mlogloss:0.47217\teval-mlogloss:0.63346\n",
      "[31]\ttrain-mlogloss:0.46130\teval-mlogloss:0.62793\n",
      "[32]\ttrain-mlogloss:0.45030\teval-mlogloss:0.62293\n",
      "[33]\ttrain-mlogloss:0.43987\teval-mlogloss:0.61850\n",
      "[34]\ttrain-mlogloss:0.42890\teval-mlogloss:0.61413\n",
      "[35]\ttrain-mlogloss:0.41835\teval-mlogloss:0.60937\n",
      "[36]\ttrain-mlogloss:0.40830\teval-mlogloss:0.60688\n",
      "[37]\ttrain-mlogloss:0.39823\teval-mlogloss:0.60170\n",
      "[38]\ttrain-mlogloss:0.38906\teval-mlogloss:0.59852\n",
      "[39]\ttrain-mlogloss:0.38045\teval-mlogloss:0.59574\n",
      "[40]\ttrain-mlogloss:0.37164\teval-mlogloss:0.59419\n",
      "[41]\ttrain-mlogloss:0.36306\teval-mlogloss:0.59140\n",
      "[42]\ttrain-mlogloss:0.35477\teval-mlogloss:0.58949\n",
      "[43]\ttrain-mlogloss:0.34698\teval-mlogloss:0.58658\n",
      "[44]\ttrain-mlogloss:0.34016\teval-mlogloss:0.58363\n",
      "[45]\ttrain-mlogloss:0.33330\teval-mlogloss:0.58178\n",
      "[46]\ttrain-mlogloss:0.32563\teval-mlogloss:0.57920\n",
      "[47]\ttrain-mlogloss:0.31894\teval-mlogloss:0.57705\n",
      "[48]\ttrain-mlogloss:0.31215\teval-mlogloss:0.57408\n",
      "[49]\ttrain-mlogloss:0.30527\teval-mlogloss:0.57100\n",
      "[50]\ttrain-mlogloss:0.30014\teval-mlogloss:0.56919\n",
      "[51]\ttrain-mlogloss:0.29431\teval-mlogloss:0.56850\n",
      "[52]\ttrain-mlogloss:0.28849\teval-mlogloss:0.56619\n",
      "[53]\ttrain-mlogloss:0.28399\teval-mlogloss:0.56431\n",
      "[54]\ttrain-mlogloss:0.27779\teval-mlogloss:0.56259\n",
      "[55]\ttrain-mlogloss:0.27224\teval-mlogloss:0.56098\n",
      "[56]\ttrain-mlogloss:0.26672\teval-mlogloss:0.56163\n",
      "[57]\ttrain-mlogloss:0.26190\teval-mlogloss:0.56094\n",
      "[58]\ttrain-mlogloss:0.25621\teval-mlogloss:0.55932\n",
      "[59]\ttrain-mlogloss:0.25131\teval-mlogloss:0.55714\n",
      "[60]\ttrain-mlogloss:0.24689\teval-mlogloss:0.55631\n",
      "[61]\ttrain-mlogloss:0.24238\teval-mlogloss:0.55523\n",
      "[62]\ttrain-mlogloss:0.23859\teval-mlogloss:0.55338\n",
      "[63]\ttrain-mlogloss:0.23419\teval-mlogloss:0.55194\n",
      "[64]\ttrain-mlogloss:0.23027\teval-mlogloss:0.54986\n",
      "[65]\ttrain-mlogloss:0.22658\teval-mlogloss:0.54798\n",
      "[66]\ttrain-mlogloss:0.22315\teval-mlogloss:0.54563\n",
      "[67]\ttrain-mlogloss:0.21999\teval-mlogloss:0.54364\n",
      "[68]\ttrain-mlogloss:0.21621\teval-mlogloss:0.54326\n",
      "[69]\ttrain-mlogloss:0.21295\teval-mlogloss:0.54132\n",
      "[70]\ttrain-mlogloss:0.21007\teval-mlogloss:0.54043\n",
      "[71]\ttrain-mlogloss:0.20687\teval-mlogloss:0.53974\n",
      "[72]\ttrain-mlogloss:0.20336\teval-mlogloss:0.53917\n",
      "[73]\ttrain-mlogloss:0.20080\teval-mlogloss:0.53890\n",
      "[74]\ttrain-mlogloss:0.19741\teval-mlogloss:0.53913\n",
      "[75]\ttrain-mlogloss:0.19493\teval-mlogloss:0.53954\n",
      "[76]\ttrain-mlogloss:0.19175\teval-mlogloss:0.53850\n",
      "[77]\ttrain-mlogloss:0.18888\teval-mlogloss:0.53885\n",
      "[78]\ttrain-mlogloss:0.18646\teval-mlogloss:0.53886\n",
      "[79]\ttrain-mlogloss:0.18409\teval-mlogloss:0.53814\n",
      "[80]\ttrain-mlogloss:0.18138\teval-mlogloss:0.53819\n",
      "[81]\ttrain-mlogloss:0.17872\teval-mlogloss:0.53733\n",
      "[82]\ttrain-mlogloss:0.17613\teval-mlogloss:0.53829\n",
      "[83]\ttrain-mlogloss:0.17376\teval-mlogloss:0.53818\n",
      "[84]\ttrain-mlogloss:0.17182\teval-mlogloss:0.53737\n",
      "[85]\ttrain-mlogloss:0.16922\teval-mlogloss:0.53766\n",
      "[86]\ttrain-mlogloss:0.16713\teval-mlogloss:0.53750\n",
      "[87]\ttrain-mlogloss:0.16496\teval-mlogloss:0.53872\n",
      "[88]\ttrain-mlogloss:0.16273\teval-mlogloss:0.53865\n",
      "[89]\ttrain-mlogloss:0.16058\teval-mlogloss:0.53877\n",
      "[90]\ttrain-mlogloss:0.15842\teval-mlogloss:0.53895\n",
      "[91]\ttrain-mlogloss:0.15615\teval-mlogloss:0.53811\n",
      "[92]\ttrain-mlogloss:0.15412\teval-mlogloss:0.53762\n",
      "[93]\ttrain-mlogloss:0.15192\teval-mlogloss:0.53691\n",
      "[94]\ttrain-mlogloss:0.15005\teval-mlogloss:0.53661\n",
      "[95]\ttrain-mlogloss:0.14787\teval-mlogloss:0.53741\n",
      "[96]\ttrain-mlogloss:0.14641\teval-mlogloss:0.53748\n",
      "[97]\ttrain-mlogloss:0.14416\teval-mlogloss:0.53707\n",
      "[98]\ttrain-mlogloss:0.14249\teval-mlogloss:0.53681\n",
      "[99]\ttrain-mlogloss:0.14059\teval-mlogloss:0.53721\n",
      "[100]\ttrain-mlogloss:0.13883\teval-mlogloss:0.53753\n",
      "[101]\ttrain-mlogloss:0.13710\teval-mlogloss:0.53888\n",
      "[102]\ttrain-mlogloss:0.13556\teval-mlogloss:0.53824\n",
      "[103]\ttrain-mlogloss:0.13397\teval-mlogloss:0.53831\n",
      "[104]\ttrain-mlogloss:0.13247\teval-mlogloss:0.53770\n",
      "[105]\ttrain-mlogloss:0.13096\teval-mlogloss:0.53745\n",
      "[106]\ttrain-mlogloss:0.12960\teval-mlogloss:0.53874\n",
      "[107]\ttrain-mlogloss:0.12798\teval-mlogloss:0.53825\n",
      "[108]\ttrain-mlogloss:0.12622\teval-mlogloss:0.53789\n",
      "[109]\ttrain-mlogloss:0.12474\teval-mlogloss:0.53820\n",
      "[110]\ttrain-mlogloss:0.12308\teval-mlogloss:0.53824\n",
      "[111]\ttrain-mlogloss:0.12161\teval-mlogloss:0.53772\n",
      "[112]\ttrain-mlogloss:0.12006\teval-mlogloss:0.53750\n",
      "[113]\ttrain-mlogloss:0.11883\teval-mlogloss:0.53619\n",
      "[114]\ttrain-mlogloss:0.11763\teval-mlogloss:0.53684\n",
      "[115]\ttrain-mlogloss:0.11620\teval-mlogloss:0.53568\n",
      "[116]\ttrain-mlogloss:0.11468\teval-mlogloss:0.53574\n",
      "[117]\ttrain-mlogloss:0.11329\teval-mlogloss:0.53530\n",
      "[118]\ttrain-mlogloss:0.11210\teval-mlogloss:0.53585\n",
      "[119]\ttrain-mlogloss:0.11100\teval-mlogloss:0.53603\n",
      "[120]\ttrain-mlogloss:0.10989\teval-mlogloss:0.53705\n",
      "[121]\ttrain-mlogloss:0.10854\teval-mlogloss:0.53762\n",
      "[122]\ttrain-mlogloss:0.10695\teval-mlogloss:0.53719\n",
      "[123]\ttrain-mlogloss:0.10582\teval-mlogloss:0.53622\n",
      "[124]\ttrain-mlogloss:0.10479\teval-mlogloss:0.53612\n",
      "[125]\ttrain-mlogloss:0.10368\teval-mlogloss:0.53555\n",
      "[126]\ttrain-mlogloss:0.10253\teval-mlogloss:0.53670\n",
      "[127]\ttrain-mlogloss:0.10123\teval-mlogloss:0.53622\n",
      "[128]\ttrain-mlogloss:0.10003\teval-mlogloss:0.53606\n",
      "[129]\ttrain-mlogloss:0.09914\teval-mlogloss:0.53510\n",
      "[130]\ttrain-mlogloss:0.09827\teval-mlogloss:0.53513\n",
      "[131]\ttrain-mlogloss:0.09708\teval-mlogloss:0.53545\n",
      "[132]\ttrain-mlogloss:0.09586\teval-mlogloss:0.53489\n",
      "[133]\ttrain-mlogloss:0.09461\teval-mlogloss:0.53398\n",
      "[134]\ttrain-mlogloss:0.09363\teval-mlogloss:0.53322\n",
      "[135]\ttrain-mlogloss:0.09262\teval-mlogloss:0.53428\n",
      "[136]\ttrain-mlogloss:0.09153\teval-mlogloss:0.53334\n",
      "[137]\ttrain-mlogloss:0.09044\teval-mlogloss:0.53219\n",
      "[138]\ttrain-mlogloss:0.08942\teval-mlogloss:0.53283\n",
      "[139]\ttrain-mlogloss:0.08843\teval-mlogloss:0.53364\n",
      "[140]\ttrain-mlogloss:0.08749\teval-mlogloss:0.53346\n",
      "[141]\ttrain-mlogloss:0.08654\teval-mlogloss:0.53429\n",
      "[142]\ttrain-mlogloss:0.08581\teval-mlogloss:0.53550\n",
      "[143]\ttrain-mlogloss:0.08486\teval-mlogloss:0.53512\n",
      "[144]\ttrain-mlogloss:0.08403\teval-mlogloss:0.53627\n",
      "[145]\ttrain-mlogloss:0.08326\teval-mlogloss:0.53690\n",
      "[146]\ttrain-mlogloss:0.08241\teval-mlogloss:0.53738\n",
      "[147]\ttrain-mlogloss:0.08166\teval-mlogloss:0.53819\n",
      "[148]\ttrain-mlogloss:0.08073\teval-mlogloss:0.53810\n",
      "[149]\ttrain-mlogloss:0.08001\teval-mlogloss:0.53776\n",
      "[150]\ttrain-mlogloss:0.07917\teval-mlogloss:0.53811\n",
      "[151]\ttrain-mlogloss:0.07825\teval-mlogloss:0.53814\n",
      "[152]\ttrain-mlogloss:0.07758\teval-mlogloss:0.53829\n",
      "[153]\ttrain-mlogloss:0.07679\teval-mlogloss:0.53821\n",
      "[154]\ttrain-mlogloss:0.07586\teval-mlogloss:0.53859\n",
      "[155]\ttrain-mlogloss:0.07515\teval-mlogloss:0.53809\n",
      "[156]\ttrain-mlogloss:0.07432\teval-mlogloss:0.53885\n",
      "[157]\ttrain-mlogloss:0.07356\teval-mlogloss:0.53911\n",
      "[158]\ttrain-mlogloss:0.07286\teval-mlogloss:0.53812\n",
      "[159]\ttrain-mlogloss:0.07214\teval-mlogloss:0.53908\n",
      "[160]\ttrain-mlogloss:0.07149\teval-mlogloss:0.53970\n",
      "[161]\ttrain-mlogloss:0.07085\teval-mlogloss:0.53975\n",
      "[162]\ttrain-mlogloss:0.07019\teval-mlogloss:0.53901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[163]\ttrain-mlogloss:0.06951\teval-mlogloss:0.54001\n",
      "[164]\ttrain-mlogloss:0.06887\teval-mlogloss:0.53961\n",
      "[165]\ttrain-mlogloss:0.06811\teval-mlogloss:0.53860\n",
      "[166]\ttrain-mlogloss:0.06752\teval-mlogloss:0.53814\n",
      "[167]\ttrain-mlogloss:0.06689\teval-mlogloss:0.53932\n",
      "[168]\ttrain-mlogloss:0.06617\teval-mlogloss:0.53933\n",
      "[169]\ttrain-mlogloss:0.06552\teval-mlogloss:0.53895\n",
      "[170]\ttrain-mlogloss:0.06484\teval-mlogloss:0.54014\n",
      "[171]\ttrain-mlogloss:0.06418\teval-mlogloss:0.54057\n",
      "[172]\ttrain-mlogloss:0.06358\teval-mlogloss:0.54042\n",
      "[173]\ttrain-mlogloss:0.06300\teval-mlogloss:0.54039\n",
      "[174]\ttrain-mlogloss:0.06247\teval-mlogloss:0.54069\n",
      "[175]\ttrain-mlogloss:0.06187\teval-mlogloss:0.54067\n",
      "[176]\ttrain-mlogloss:0.06126\teval-mlogloss:0.53972\n",
      "[177]\ttrain-mlogloss:0.06071\teval-mlogloss:0.54002\n",
      "[178]\ttrain-mlogloss:0.06011\teval-mlogloss:0.54000\n",
      "[179]\ttrain-mlogloss:0.05962\teval-mlogloss:0.53936\n",
      "[180]\ttrain-mlogloss:0.05904\teval-mlogloss:0.53939\n",
      "[181]\ttrain-mlogloss:0.05853\teval-mlogloss:0.53913\n",
      "[182]\ttrain-mlogloss:0.05807\teval-mlogloss:0.53930\n",
      "[183]\ttrain-mlogloss:0.05753\teval-mlogloss:0.54032\n",
      "[184]\ttrain-mlogloss:0.05693\teval-mlogloss:0.53927\n",
      "[185]\ttrain-mlogloss:0.05628\teval-mlogloss:0.53925\n",
      "[186]\ttrain-mlogloss:0.05571\teval-mlogloss:0.53935\n",
      "[187]\ttrain-mlogloss:0.05519\teval-mlogloss:0.53913\n",
      "[188]\ttrain-mlogloss:0.05466\teval-mlogloss:0.53950\n",
      "[189]\ttrain-mlogloss:0.05398\teval-mlogloss:0.53739\n",
      "[190]\ttrain-mlogloss:0.05360\teval-mlogloss:0.53663\n",
      "[191]\ttrain-mlogloss:0.05313\teval-mlogloss:0.53622\n",
      "[192]\ttrain-mlogloss:0.05264\teval-mlogloss:0.53616\n",
      "[193]\ttrain-mlogloss:0.05207\teval-mlogloss:0.53603\n",
      "[194]\ttrain-mlogloss:0.05157\teval-mlogloss:0.53627\n",
      "[195]\ttrain-mlogloss:0.05099\teval-mlogloss:0.53588\n",
      "[196]\ttrain-mlogloss:0.05048\teval-mlogloss:0.53628\n",
      "[197]\ttrain-mlogloss:0.05002\teval-mlogloss:0.53676\n",
      "[198]\ttrain-mlogloss:0.04955\teval-mlogloss:0.53674\n",
      "[199]\ttrain-mlogloss:0.04906\teval-mlogloss:0.53693\n",
      "[200]\ttrain-mlogloss:0.04868\teval-mlogloss:0.53665\n",
      "[201]\ttrain-mlogloss:0.04827\teval-mlogloss:0.53641\n",
      "[202]\ttrain-mlogloss:0.04790\teval-mlogloss:0.53637\n",
      "[203]\ttrain-mlogloss:0.04746\teval-mlogloss:0.53661\n",
      "[204]\ttrain-mlogloss:0.04707\teval-mlogloss:0.53634\n",
      "[205]\ttrain-mlogloss:0.04672\teval-mlogloss:0.53589\n",
      "[206]\ttrain-mlogloss:0.04627\teval-mlogloss:0.53587\n",
      "[207]\ttrain-mlogloss:0.04586\teval-mlogloss:0.53622\n",
      "[208]\ttrain-mlogloss:0.04544\teval-mlogloss:0.53585\n",
      "[209]\ttrain-mlogloss:0.04502\teval-mlogloss:0.53578\n",
      "[210]\ttrain-mlogloss:0.04458\teval-mlogloss:0.53582\n",
      "[211]\ttrain-mlogloss:0.04416\teval-mlogloss:0.53546\n",
      "[212]\ttrain-mlogloss:0.04381\teval-mlogloss:0.53530\n",
      "[213]\ttrain-mlogloss:0.04330\teval-mlogloss:0.53520\n",
      "[214]\ttrain-mlogloss:0.04295\teval-mlogloss:0.53562\n",
      "[215]\ttrain-mlogloss:0.04255\teval-mlogloss:0.53461\n",
      "[216]\ttrain-mlogloss:0.04215\teval-mlogloss:0.53408\n",
      "[217]\ttrain-mlogloss:0.04179\teval-mlogloss:0.53406\n",
      "[218]\ttrain-mlogloss:0.04139\teval-mlogloss:0.53421\n",
      "[219]\ttrain-mlogloss:0.04101\teval-mlogloss:0.53455\n",
      "[220]\ttrain-mlogloss:0.04068\teval-mlogloss:0.53420\n",
      "[221]\ttrain-mlogloss:0.04031\teval-mlogloss:0.53422\n",
      "[222]\ttrain-mlogloss:0.04002\teval-mlogloss:0.53425\n",
      "[223]\ttrain-mlogloss:0.03969\teval-mlogloss:0.53362\n",
      "[224]\ttrain-mlogloss:0.03938\teval-mlogloss:0.53287\n",
      "[225]\ttrain-mlogloss:0.03906\teval-mlogloss:0.53327\n",
      "[226]\ttrain-mlogloss:0.03878\teval-mlogloss:0.53322\n",
      "[227]\ttrain-mlogloss:0.03839\teval-mlogloss:0.53280\n",
      "[228]\ttrain-mlogloss:0.03811\teval-mlogloss:0.53291\n",
      "[229]\ttrain-mlogloss:0.03780\teval-mlogloss:0.53266\n",
      "[230]\ttrain-mlogloss:0.03755\teval-mlogloss:0.53338\n",
      "[231]\ttrain-mlogloss:0.03724\teval-mlogloss:0.53351\n",
      "[232]\ttrain-mlogloss:0.03692\teval-mlogloss:0.53418\n",
      "[233]\ttrain-mlogloss:0.03659\teval-mlogloss:0.53380\n",
      "[234]\ttrain-mlogloss:0.03628\teval-mlogloss:0.53399\n",
      "[235]\ttrain-mlogloss:0.03595\teval-mlogloss:0.53381\n",
      "[236]\ttrain-mlogloss:0.03569\teval-mlogloss:0.53388\n",
      "[237]\ttrain-mlogloss:0.03537\teval-mlogloss:0.53388\n"
     ]
    }
   ],
   "source": [
    "#t7_0.53219 ########성능 0.683 원래대로 진행 0.782\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, \n",
    "                                                    test_size=0.1, \n",
    "                                                    stratify=train_y, \n",
    "                                                    random_state=37)\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(data=X_test, label=y_test)\n",
    "#dtest_x = xgb.DMatrix(data=test_x)\n",
    "\n",
    "params = {'max_depth' : 6,\n",
    "          'eta': 0.04,\n",
    "          'objective':'multi:softmax',\n",
    "          'num_class':3,\n",
    "          'eval_metric':'mlogloss',\n",
    "#           'eval_set': [(X_test, y_test)], #적용이 안 되고 있다고 뜸\n",
    "#           'early_stopping':100 #적용이 안 되고 있다고 뜸\n",
    "          }\n",
    "num_rounds = 400\n",
    "\n",
    "wlist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "xgb_model = xgb.train(params=params, \n",
    "                      dtrain=dtrain, \n",
    "                      num_boost_round=num_rounds, \n",
    "                      early_stopping_rounds=100, \n",
    "                      evals=wlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a992aabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.782559847895601\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_model.predict(dtest, ntree_limit=xgb_model.best_ntree_limit)\n",
    "preds = np.round(y_pred).astype(int)\n",
    "print(f1_score(y_test, preds, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c10ac621",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.05734\teval-mlogloss:1.06639\n",
      "[1]\ttrain-mlogloss:1.01836\teval-mlogloss:1.03465\n",
      "[2]\ttrain-mlogloss:0.98192\teval-mlogloss:1.00666\n",
      "[3]\ttrain-mlogloss:0.94688\teval-mlogloss:0.98095\n",
      "[4]\ttrain-mlogloss:0.91448\teval-mlogloss:0.95759\n",
      "[5]\ttrain-mlogloss:0.88443\teval-mlogloss:0.93223\n",
      "[6]\ttrain-mlogloss:0.85517\teval-mlogloss:0.90750\n",
      "[7]\ttrain-mlogloss:0.82821\teval-mlogloss:0.88531\n",
      "[8]\ttrain-mlogloss:0.80172\teval-mlogloss:0.86370\n",
      "[9]\ttrain-mlogloss:0.77609\teval-mlogloss:0.84379\n",
      "[10]\ttrain-mlogloss:0.75217\teval-mlogloss:0.82476\n",
      "[11]\ttrain-mlogloss:0.72932\teval-mlogloss:0.80693\n",
      "[12]\ttrain-mlogloss:0.70798\teval-mlogloss:0.79104\n",
      "[13]\ttrain-mlogloss:0.68855\teval-mlogloss:0.77681\n",
      "[14]\ttrain-mlogloss:0.66958\teval-mlogloss:0.76155\n",
      "[15]\ttrain-mlogloss:0.65132\teval-mlogloss:0.74939\n",
      "[16]\ttrain-mlogloss:0.63192\teval-mlogloss:0.73638\n",
      "[17]\ttrain-mlogloss:0.61405\teval-mlogloss:0.72359\n",
      "[18]\ttrain-mlogloss:0.59767\teval-mlogloss:0.71347\n",
      "[19]\ttrain-mlogloss:0.58050\teval-mlogloss:0.70147\n",
      "[20]\ttrain-mlogloss:0.56465\teval-mlogloss:0.69078\n",
      "[21]\ttrain-mlogloss:0.54961\teval-mlogloss:0.68007\n",
      "[22]\ttrain-mlogloss:0.53604\teval-mlogloss:0.66967\n",
      "[23]\ttrain-mlogloss:0.52350\teval-mlogloss:0.66000\n",
      "[24]\ttrain-mlogloss:0.51100\teval-mlogloss:0.65100\n",
      "[25]\ttrain-mlogloss:0.49805\teval-mlogloss:0.64346\n",
      "[26]\ttrain-mlogloss:0.48538\teval-mlogloss:0.63373\n",
      "[27]\ttrain-mlogloss:0.47380\teval-mlogloss:0.62604\n",
      "[28]\ttrain-mlogloss:0.46214\teval-mlogloss:0.61960\n",
      "[29]\ttrain-mlogloss:0.45015\teval-mlogloss:0.61217\n",
      "[30]\ttrain-mlogloss:0.43876\teval-mlogloss:0.60527\n",
      "[31]\ttrain-mlogloss:0.42826\teval-mlogloss:0.59854\n",
      "[32]\ttrain-mlogloss:0.41697\teval-mlogloss:0.59268\n",
      "[33]\ttrain-mlogloss:0.40703\teval-mlogloss:0.58822\n",
      "[34]\ttrain-mlogloss:0.39701\teval-mlogloss:0.58424\n",
      "[35]\ttrain-mlogloss:0.38799\teval-mlogloss:0.58141\n",
      "[36]\ttrain-mlogloss:0.37807\teval-mlogloss:0.57805\n",
      "[37]\ttrain-mlogloss:0.36877\teval-mlogloss:0.57396\n",
      "[38]\ttrain-mlogloss:0.36030\teval-mlogloss:0.57051\n",
      "[39]\ttrain-mlogloss:0.35091\teval-mlogloss:0.56579\n",
      "[40]\ttrain-mlogloss:0.34230\teval-mlogloss:0.56173\n",
      "[41]\ttrain-mlogloss:0.33459\teval-mlogloss:0.56004\n",
      "[42]\ttrain-mlogloss:0.32598\teval-mlogloss:0.55684\n",
      "[43]\ttrain-mlogloss:0.31793\teval-mlogloss:0.55352\n",
      "[44]\ttrain-mlogloss:0.31008\teval-mlogloss:0.55049\n",
      "[45]\ttrain-mlogloss:0.30243\teval-mlogloss:0.54886\n",
      "[46]\ttrain-mlogloss:0.29583\teval-mlogloss:0.54608\n",
      "[47]\ttrain-mlogloss:0.28927\teval-mlogloss:0.54459\n",
      "[48]\ttrain-mlogloss:0.28174\teval-mlogloss:0.54209\n",
      "[49]\ttrain-mlogloss:0.27485\teval-mlogloss:0.54104\n",
      "[50]\ttrain-mlogloss:0.26857\teval-mlogloss:0.53901\n",
      "[51]\ttrain-mlogloss:0.26196\teval-mlogloss:0.53635\n",
      "[52]\ttrain-mlogloss:0.25637\teval-mlogloss:0.53364\n",
      "[53]\ttrain-mlogloss:0.25151\teval-mlogloss:0.53176\n",
      "[54]\ttrain-mlogloss:0.24552\teval-mlogloss:0.53018\n",
      "[55]\ttrain-mlogloss:0.24108\teval-mlogloss:0.52898\n",
      "[56]\ttrain-mlogloss:0.23615\teval-mlogloss:0.52805\n",
      "[57]\ttrain-mlogloss:0.23072\teval-mlogloss:0.52616\n",
      "[58]\ttrain-mlogloss:0.22608\teval-mlogloss:0.52517\n",
      "[59]\ttrain-mlogloss:0.22119\teval-mlogloss:0.52378\n",
      "[60]\ttrain-mlogloss:0.21650\teval-mlogloss:0.52306\n",
      "[61]\ttrain-mlogloss:0.21237\teval-mlogloss:0.52181\n",
      "[62]\ttrain-mlogloss:0.20851\teval-mlogloss:0.52090\n",
      "[63]\ttrain-mlogloss:0.20452\teval-mlogloss:0.52012\n",
      "[64]\ttrain-mlogloss:0.20054\teval-mlogloss:0.52004\n",
      "[65]\ttrain-mlogloss:0.19651\teval-mlogloss:0.51890\n",
      "[66]\ttrain-mlogloss:0.19263\teval-mlogloss:0.51781\n",
      "[67]\ttrain-mlogloss:0.18947\teval-mlogloss:0.51813\n",
      "[68]\ttrain-mlogloss:0.18557\teval-mlogloss:0.51732\n",
      "[69]\ttrain-mlogloss:0.18219\teval-mlogloss:0.51726\n",
      "[70]\ttrain-mlogloss:0.17865\teval-mlogloss:0.51615\n",
      "[71]\ttrain-mlogloss:0.17535\teval-mlogloss:0.51708\n",
      "[72]\ttrain-mlogloss:0.17249\teval-mlogloss:0.51624\n",
      "[73]\ttrain-mlogloss:0.16930\teval-mlogloss:0.51463\n",
      "[74]\ttrain-mlogloss:0.16658\teval-mlogloss:0.51333\n",
      "[75]\ttrain-mlogloss:0.16386\teval-mlogloss:0.51326\n",
      "[76]\ttrain-mlogloss:0.16104\teval-mlogloss:0.51320\n",
      "[77]\ttrain-mlogloss:0.15843\teval-mlogloss:0.51274\n",
      "[78]\ttrain-mlogloss:0.15581\teval-mlogloss:0.51324\n",
      "[79]\ttrain-mlogloss:0.15314\teval-mlogloss:0.51215\n",
      "[80]\ttrain-mlogloss:0.15070\teval-mlogloss:0.51090\n",
      "[81]\ttrain-mlogloss:0.14859\teval-mlogloss:0.51183\n",
      "[82]\ttrain-mlogloss:0.14597\teval-mlogloss:0.51296\n",
      "[83]\ttrain-mlogloss:0.14396\teval-mlogloss:0.51304\n",
      "[84]\ttrain-mlogloss:0.14152\teval-mlogloss:0.51423\n",
      "[85]\ttrain-mlogloss:0.13938\teval-mlogloss:0.51374\n",
      "[86]\ttrain-mlogloss:0.13721\teval-mlogloss:0.51345\n",
      "[87]\ttrain-mlogloss:0.13487\teval-mlogloss:0.51270\n",
      "[88]\ttrain-mlogloss:0.13287\teval-mlogloss:0.51292\n",
      "[89]\ttrain-mlogloss:0.13125\teval-mlogloss:0.51345\n",
      "[90]\ttrain-mlogloss:0.12904\teval-mlogloss:0.51247\n",
      "[91]\ttrain-mlogloss:0.12739\teval-mlogloss:0.51246\n",
      "[92]\ttrain-mlogloss:0.12547\teval-mlogloss:0.51273\n",
      "[93]\ttrain-mlogloss:0.12381\teval-mlogloss:0.51306\n",
      "[94]\ttrain-mlogloss:0.12202\teval-mlogloss:0.51365\n",
      "[95]\ttrain-mlogloss:0.12021\teval-mlogloss:0.51415\n",
      "[96]\ttrain-mlogloss:0.11836\teval-mlogloss:0.51408\n",
      "[97]\ttrain-mlogloss:0.11660\teval-mlogloss:0.51506\n",
      "[98]\ttrain-mlogloss:0.11491\teval-mlogloss:0.51549\n",
      "[99]\ttrain-mlogloss:0.11353\teval-mlogloss:0.51649\n",
      "[100]\ttrain-mlogloss:0.11195\teval-mlogloss:0.51698\n",
      "[101]\ttrain-mlogloss:0.11042\teval-mlogloss:0.51706\n",
      "[102]\ttrain-mlogloss:0.10879\teval-mlogloss:0.51756\n",
      "[103]\ttrain-mlogloss:0.10713\teval-mlogloss:0.51870\n",
      "[104]\ttrain-mlogloss:0.10566\teval-mlogloss:0.51857\n",
      "[105]\ttrain-mlogloss:0.10397\teval-mlogloss:0.51784\n",
      "[106]\ttrain-mlogloss:0.10238\teval-mlogloss:0.51809\n",
      "[107]\ttrain-mlogloss:0.10100\teval-mlogloss:0.51862\n",
      "[108]\ttrain-mlogloss:0.09927\teval-mlogloss:0.51817\n",
      "[109]\ttrain-mlogloss:0.09789\teval-mlogloss:0.51807\n",
      "[110]\ttrain-mlogloss:0.09641\teval-mlogloss:0.51801\n",
      "[111]\ttrain-mlogloss:0.09514\teval-mlogloss:0.51954\n",
      "[112]\ttrain-mlogloss:0.09380\teval-mlogloss:0.52018\n",
      "[113]\ttrain-mlogloss:0.09233\teval-mlogloss:0.52120\n",
      "[114]\ttrain-mlogloss:0.09109\teval-mlogloss:0.52060\n",
      "[115]\ttrain-mlogloss:0.08991\teval-mlogloss:0.51976\n",
      "[116]\ttrain-mlogloss:0.08867\teval-mlogloss:0.52048\n",
      "[117]\ttrain-mlogloss:0.08763\teval-mlogloss:0.52092\n",
      "[118]\ttrain-mlogloss:0.08642\teval-mlogloss:0.52132\n",
      "[119]\ttrain-mlogloss:0.08525\teval-mlogloss:0.52193\n",
      "[120]\ttrain-mlogloss:0.08398\teval-mlogloss:0.52268\n",
      "[121]\ttrain-mlogloss:0.08295\teval-mlogloss:0.52210\n",
      "[122]\ttrain-mlogloss:0.08208\teval-mlogloss:0.52126\n",
      "[123]\ttrain-mlogloss:0.08096\teval-mlogloss:0.52217\n",
      "[124]\ttrain-mlogloss:0.07980\teval-mlogloss:0.52254\n",
      "[125]\ttrain-mlogloss:0.07881\teval-mlogloss:0.52231\n",
      "[126]\ttrain-mlogloss:0.07782\teval-mlogloss:0.52400\n",
      "[127]\ttrain-mlogloss:0.07672\teval-mlogloss:0.52400\n",
      "[128]\ttrain-mlogloss:0.07564\teval-mlogloss:0.52380\n",
      "[129]\ttrain-mlogloss:0.07450\teval-mlogloss:0.52475\n",
      "[130]\ttrain-mlogloss:0.07327\teval-mlogloss:0.52489\n",
      "[131]\ttrain-mlogloss:0.07211\teval-mlogloss:0.52501\n",
      "[132]\ttrain-mlogloss:0.07114\teval-mlogloss:0.52419\n",
      "[133]\ttrain-mlogloss:0.07016\teval-mlogloss:0.52406\n",
      "[134]\ttrain-mlogloss:0.06930\teval-mlogloss:0.52417\n",
      "[135]\ttrain-mlogloss:0.06833\teval-mlogloss:0.52441\n",
      "[136]\ttrain-mlogloss:0.06748\teval-mlogloss:0.52489\n",
      "[137]\ttrain-mlogloss:0.06655\teval-mlogloss:0.52445\n",
      "[138]\ttrain-mlogloss:0.06578\teval-mlogloss:0.52455\n",
      "[139]\ttrain-mlogloss:0.06498\teval-mlogloss:0.52582\n",
      "[140]\ttrain-mlogloss:0.06428\teval-mlogloss:0.52490\n",
      "[141]\ttrain-mlogloss:0.06339\teval-mlogloss:0.52504\n",
      "[142]\ttrain-mlogloss:0.06274\teval-mlogloss:0.52519\n",
      "[143]\ttrain-mlogloss:0.06193\teval-mlogloss:0.52583\n",
      "[144]\ttrain-mlogloss:0.06129\teval-mlogloss:0.52550\n",
      "[145]\ttrain-mlogloss:0.06060\teval-mlogloss:0.52523\n",
      "[146]\ttrain-mlogloss:0.05989\teval-mlogloss:0.52528\n",
      "[147]\ttrain-mlogloss:0.05915\teval-mlogloss:0.52596\n",
      "[148]\ttrain-mlogloss:0.05839\teval-mlogloss:0.52668\n",
      "[149]\ttrain-mlogloss:0.05775\teval-mlogloss:0.52667\n",
      "[150]\ttrain-mlogloss:0.05712\teval-mlogloss:0.52710\n",
      "[151]\ttrain-mlogloss:0.05640\teval-mlogloss:0.52698\n",
      "[152]\ttrain-mlogloss:0.05566\teval-mlogloss:0.52684\n",
      "[153]\ttrain-mlogloss:0.05504\teval-mlogloss:0.52661\n",
      "[154]\ttrain-mlogloss:0.05441\teval-mlogloss:0.52583\n",
      "[155]\ttrain-mlogloss:0.05378\teval-mlogloss:0.52659\n",
      "[156]\ttrain-mlogloss:0.05318\teval-mlogloss:0.52672\n",
      "[157]\ttrain-mlogloss:0.05252\teval-mlogloss:0.52651\n",
      "[158]\ttrain-mlogloss:0.05183\teval-mlogloss:0.52677\n",
      "[159]\ttrain-mlogloss:0.05116\teval-mlogloss:0.52777\n",
      "[160]\ttrain-mlogloss:0.05064\teval-mlogloss:0.52802\n",
      "[161]\ttrain-mlogloss:0.05006\teval-mlogloss:0.52790\n",
      "[162]\ttrain-mlogloss:0.04939\teval-mlogloss:0.52833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[163]\ttrain-mlogloss:0.04885\teval-mlogloss:0.52874\n",
      "[164]\ttrain-mlogloss:0.04832\teval-mlogloss:0.52860\n",
      "[165]\ttrain-mlogloss:0.04781\teval-mlogloss:0.52807\n",
      "[166]\ttrain-mlogloss:0.04726\teval-mlogloss:0.52934\n",
      "[167]\ttrain-mlogloss:0.04663\teval-mlogloss:0.53003\n",
      "[168]\ttrain-mlogloss:0.04610\teval-mlogloss:0.53017\n",
      "[169]\ttrain-mlogloss:0.04570\teval-mlogloss:0.53035\n",
      "[170]\ttrain-mlogloss:0.04516\teval-mlogloss:0.53122\n",
      "[171]\ttrain-mlogloss:0.04463\teval-mlogloss:0.53193\n",
      "[172]\ttrain-mlogloss:0.04414\teval-mlogloss:0.53294\n",
      "[173]\ttrain-mlogloss:0.04362\teval-mlogloss:0.53284\n",
      "[174]\ttrain-mlogloss:0.04310\teval-mlogloss:0.53328\n",
      "[175]\ttrain-mlogloss:0.04268\teval-mlogloss:0.53409\n",
      "[176]\ttrain-mlogloss:0.04219\teval-mlogloss:0.53437\n",
      "[177]\ttrain-mlogloss:0.04169\teval-mlogloss:0.53506\n",
      "[178]\ttrain-mlogloss:0.04123\teval-mlogloss:0.53469\n",
      "[179]\ttrain-mlogloss:0.04078\teval-mlogloss:0.53437\n"
     ]
    }
   ],
   "source": [
    "#t7_0.53219 ########성능 0.683 원래에서 max_depth 7로 0.787 과적합 가능성 있음\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, \n",
    "                                                    test_size=0.1, \n",
    "                                                    stratify=train_y, \n",
    "                                                    random_state=37)\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(data=X_test, label=y_test)\n",
    "#dtest_x = xgb.DMatrix(data=test_x)\n",
    "\n",
    "params = {'max_depth' : 7,\n",
    "          'eta': 0.04,\n",
    "          'objective':'multi:softmax',\n",
    "          'num_class':3,\n",
    "          'eval_metric':'mlogloss',\n",
    "#           'eval_set': [(X_test, y_test)], #적용이 안 되고 있다고 뜸\n",
    "#           'early_stopping':100 #적용이 안 되고 있다고 뜸\n",
    "          }\n",
    "num_rounds = 400\n",
    "\n",
    "wlist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "xgb_model = xgb.train(params=params, \n",
    "                      dtrain=dtrain, \n",
    "                      num_boost_round=num_rounds, \n",
    "                      early_stopping_rounds=100, \n",
    "                      evals=wlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ce29fcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7877394636015325\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_model.predict(dtest, ntree_limit=xgb_model.best_ntree_limit)\n",
    "preds = np.round(y_pred).astype(int)\n",
    "print(f1_score(y_test, preds, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a703b045",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.06473\teval-mlogloss:1.07224\n",
      "[1]\ttrain-mlogloss:1.03262\teval-mlogloss:1.05003\n",
      "[2]\ttrain-mlogloss:1.00198\teval-mlogloss:1.02696\n",
      "[3]\ttrain-mlogloss:0.97269\teval-mlogloss:1.00597\n",
      "[4]\ttrain-mlogloss:0.94468\teval-mlogloss:0.98503\n",
      "[5]\ttrain-mlogloss:0.91779\teval-mlogloss:0.96462\n",
      "[6]\ttrain-mlogloss:0.89202\teval-mlogloss:0.94676\n",
      "[7]\ttrain-mlogloss:0.86716\teval-mlogloss:0.92772\n",
      "[8]\ttrain-mlogloss:0.84327\teval-mlogloss:0.90891\n",
      "[9]\ttrain-mlogloss:0.82052\teval-mlogloss:0.89083\n",
      "[10]\ttrain-mlogloss:0.79841\teval-mlogloss:0.87388\n",
      "[11]\ttrain-mlogloss:0.77796\teval-mlogloss:0.85915\n",
      "[12]\ttrain-mlogloss:0.75698\teval-mlogloss:0.84447\n",
      "[13]\ttrain-mlogloss:0.73748\teval-mlogloss:0.83089\n",
      "[14]\ttrain-mlogloss:0.71823\teval-mlogloss:0.81684\n",
      "[15]\ttrain-mlogloss:0.69980\teval-mlogloss:0.80418\n",
      "[16]\ttrain-mlogloss:0.68107\teval-mlogloss:0.79105\n",
      "[17]\ttrain-mlogloss:0.66354\teval-mlogloss:0.77746\n",
      "[18]\ttrain-mlogloss:0.64592\teval-mlogloss:0.76592\n",
      "[19]\ttrain-mlogloss:0.62957\teval-mlogloss:0.75423\n",
      "[20]\ttrain-mlogloss:0.61339\teval-mlogloss:0.74239\n",
      "[21]\ttrain-mlogloss:0.59786\teval-mlogloss:0.73184\n",
      "[22]\ttrain-mlogloss:0.58268\teval-mlogloss:0.72056\n",
      "[23]\ttrain-mlogloss:0.56897\teval-mlogloss:0.71001\n",
      "[24]\ttrain-mlogloss:0.55476\teval-mlogloss:0.69995\n",
      "[25]\ttrain-mlogloss:0.54163\teval-mlogloss:0.69183\n",
      "[26]\ttrain-mlogloss:0.52934\teval-mlogloss:0.68299\n",
      "[27]\ttrain-mlogloss:0.51626\teval-mlogloss:0.67521\n",
      "[28]\ttrain-mlogloss:0.50438\teval-mlogloss:0.66722\n",
      "[29]\ttrain-mlogloss:0.49193\teval-mlogloss:0.65967\n",
      "[30]\ttrain-mlogloss:0.48062\teval-mlogloss:0.65158\n",
      "[31]\ttrain-mlogloss:0.46912\teval-mlogloss:0.64603\n",
      "[32]\ttrain-mlogloss:0.45799\teval-mlogloss:0.63964\n",
      "[33]\ttrain-mlogloss:0.44746\teval-mlogloss:0.63233\n",
      "[34]\ttrain-mlogloss:0.43666\teval-mlogloss:0.62727\n",
      "[35]\ttrain-mlogloss:0.42603\teval-mlogloss:0.62319\n",
      "[36]\ttrain-mlogloss:0.41599\teval-mlogloss:0.61816\n",
      "[37]\ttrain-mlogloss:0.40590\teval-mlogloss:0.61246\n",
      "[38]\ttrain-mlogloss:0.39646\teval-mlogloss:0.60817\n",
      "[39]\ttrain-mlogloss:0.38758\teval-mlogloss:0.60273\n",
      "[40]\ttrain-mlogloss:0.37874\teval-mlogloss:0.59721\n",
      "[41]\ttrain-mlogloss:0.37017\teval-mlogloss:0.59197\n",
      "[42]\ttrain-mlogloss:0.36184\teval-mlogloss:0.58607\n",
      "[43]\ttrain-mlogloss:0.35343\teval-mlogloss:0.58104\n",
      "[44]\ttrain-mlogloss:0.34517\teval-mlogloss:0.57632\n",
      "[45]\ttrain-mlogloss:0.33703\teval-mlogloss:0.57123\n",
      "[46]\ttrain-mlogloss:0.32937\teval-mlogloss:0.56731\n",
      "[47]\ttrain-mlogloss:0.32157\teval-mlogloss:0.56309\n",
      "[48]\ttrain-mlogloss:0.31435\teval-mlogloss:0.55903\n",
      "[49]\ttrain-mlogloss:0.30737\teval-mlogloss:0.55514\n",
      "[50]\ttrain-mlogloss:0.30014\teval-mlogloss:0.55075\n",
      "[51]\ttrain-mlogloss:0.29314\teval-mlogloss:0.54722\n",
      "[52]\ttrain-mlogloss:0.28688\teval-mlogloss:0.54352\n",
      "[53]\ttrain-mlogloss:0.28043\teval-mlogloss:0.54156\n",
      "[54]\ttrain-mlogloss:0.27462\teval-mlogloss:0.53807\n",
      "[55]\ttrain-mlogloss:0.26880\teval-mlogloss:0.53581\n",
      "[56]\ttrain-mlogloss:0.26292\teval-mlogloss:0.53406\n",
      "[57]\ttrain-mlogloss:0.25745\teval-mlogloss:0.53197\n",
      "[58]\ttrain-mlogloss:0.25167\teval-mlogloss:0.53035\n",
      "[59]\ttrain-mlogloss:0.24595\teval-mlogloss:0.52773\n",
      "[60]\ttrain-mlogloss:0.24090\teval-mlogloss:0.52620\n",
      "[61]\ttrain-mlogloss:0.23571\teval-mlogloss:0.52425\n",
      "[62]\ttrain-mlogloss:0.23051\teval-mlogloss:0.52231\n",
      "[63]\ttrain-mlogloss:0.22552\teval-mlogloss:0.52010\n",
      "[64]\ttrain-mlogloss:0.22072\teval-mlogloss:0.51841\n",
      "[65]\ttrain-mlogloss:0.21601\teval-mlogloss:0.51765\n",
      "[66]\ttrain-mlogloss:0.21138\teval-mlogloss:0.51515\n",
      "[67]\ttrain-mlogloss:0.20679\teval-mlogloss:0.51410\n",
      "[68]\ttrain-mlogloss:0.20256\teval-mlogloss:0.51227\n",
      "[69]\ttrain-mlogloss:0.19838\teval-mlogloss:0.51064\n",
      "[70]\ttrain-mlogloss:0.19460\teval-mlogloss:0.50970\n",
      "[71]\ttrain-mlogloss:0.19072\teval-mlogloss:0.50843\n",
      "[72]\ttrain-mlogloss:0.18684\teval-mlogloss:0.50810\n",
      "[73]\ttrain-mlogloss:0.18321\teval-mlogloss:0.50683\n",
      "[74]\ttrain-mlogloss:0.17975\teval-mlogloss:0.50622\n",
      "[75]\ttrain-mlogloss:0.17618\teval-mlogloss:0.50607\n",
      "[76]\ttrain-mlogloss:0.17258\teval-mlogloss:0.50485\n",
      "[77]\ttrain-mlogloss:0.16926\teval-mlogloss:0.50454\n",
      "[78]\ttrain-mlogloss:0.16606\teval-mlogloss:0.50401\n",
      "[79]\ttrain-mlogloss:0.16289\teval-mlogloss:0.50379\n",
      "[80]\ttrain-mlogloss:0.15985\teval-mlogloss:0.50264\n",
      "[81]\ttrain-mlogloss:0.15694\teval-mlogloss:0.50131\n",
      "[82]\ttrain-mlogloss:0.15411\teval-mlogloss:0.50127\n",
      "[83]\ttrain-mlogloss:0.15133\teval-mlogloss:0.50217\n",
      "[84]\ttrain-mlogloss:0.14859\teval-mlogloss:0.50175\n",
      "[85]\ttrain-mlogloss:0.14594\teval-mlogloss:0.50178\n",
      "[86]\ttrain-mlogloss:0.14351\teval-mlogloss:0.50149\n",
      "[87]\ttrain-mlogloss:0.14101\teval-mlogloss:0.50136\n",
      "[88]\ttrain-mlogloss:0.13860\teval-mlogloss:0.50095\n",
      "[89]\ttrain-mlogloss:0.13629\teval-mlogloss:0.50054\n",
      "[90]\ttrain-mlogloss:0.13391\teval-mlogloss:0.50089\n",
      "[91]\ttrain-mlogloss:0.13167\teval-mlogloss:0.50106\n",
      "[92]\ttrain-mlogloss:0.12935\teval-mlogloss:0.50171\n",
      "[93]\ttrain-mlogloss:0.12721\teval-mlogloss:0.50171\n",
      "[94]\ttrain-mlogloss:0.12502\teval-mlogloss:0.50140\n",
      "[95]\ttrain-mlogloss:0.12285\teval-mlogloss:0.50164\n",
      "[96]\ttrain-mlogloss:0.12084\teval-mlogloss:0.50175\n",
      "[97]\ttrain-mlogloss:0.11881\teval-mlogloss:0.50160\n",
      "[98]\ttrain-mlogloss:0.11684\teval-mlogloss:0.50180\n",
      "[99]\ttrain-mlogloss:0.11494\teval-mlogloss:0.50124\n",
      "[100]\ttrain-mlogloss:0.11302\teval-mlogloss:0.50143\n",
      "[101]\ttrain-mlogloss:0.11110\teval-mlogloss:0.50142\n",
      "[102]\ttrain-mlogloss:0.10944\teval-mlogloss:0.50097\n",
      "[103]\ttrain-mlogloss:0.10762\teval-mlogloss:0.50099\n",
      "[104]\ttrain-mlogloss:0.10593\teval-mlogloss:0.50048\n",
      "[105]\ttrain-mlogloss:0.10433\teval-mlogloss:0.50031\n",
      "[106]\ttrain-mlogloss:0.10268\teval-mlogloss:0.50052\n",
      "[107]\ttrain-mlogloss:0.10109\teval-mlogloss:0.50033\n",
      "[108]\ttrain-mlogloss:0.09952\teval-mlogloss:0.49992\n",
      "[109]\ttrain-mlogloss:0.09799\teval-mlogloss:0.50022\n",
      "[110]\ttrain-mlogloss:0.09655\teval-mlogloss:0.50027\n",
      "[111]\ttrain-mlogloss:0.09509\teval-mlogloss:0.50064\n",
      "[112]\ttrain-mlogloss:0.09377\teval-mlogloss:0.50057\n",
      "[113]\ttrain-mlogloss:0.09237\teval-mlogloss:0.50000\n",
      "[114]\ttrain-mlogloss:0.09090\teval-mlogloss:0.50046\n",
      "[115]\ttrain-mlogloss:0.08957\teval-mlogloss:0.50133\n",
      "[116]\ttrain-mlogloss:0.08826\teval-mlogloss:0.50180\n",
      "[117]\ttrain-mlogloss:0.08695\teval-mlogloss:0.50255\n",
      "[118]\ttrain-mlogloss:0.08566\teval-mlogloss:0.50381\n",
      "[119]\ttrain-mlogloss:0.08443\teval-mlogloss:0.50367\n",
      "[120]\ttrain-mlogloss:0.08320\teval-mlogloss:0.50396\n",
      "[121]\ttrain-mlogloss:0.08198\teval-mlogloss:0.50502\n",
      "[122]\ttrain-mlogloss:0.08074\teval-mlogloss:0.50500\n",
      "[123]\ttrain-mlogloss:0.07959\teval-mlogloss:0.50445\n",
      "[124]\ttrain-mlogloss:0.07851\teval-mlogloss:0.50518\n",
      "[125]\ttrain-mlogloss:0.07737\teval-mlogloss:0.50518\n",
      "[126]\ttrain-mlogloss:0.07634\teval-mlogloss:0.50576\n",
      "[127]\ttrain-mlogloss:0.07529\teval-mlogloss:0.50575\n",
      "[128]\ttrain-mlogloss:0.07428\teval-mlogloss:0.50690\n",
      "[129]\ttrain-mlogloss:0.07327\teval-mlogloss:0.50773\n",
      "[130]\ttrain-mlogloss:0.07223\teval-mlogloss:0.50837\n",
      "[131]\ttrain-mlogloss:0.07122\teval-mlogloss:0.50906\n",
      "[132]\ttrain-mlogloss:0.07025\teval-mlogloss:0.50948\n",
      "[133]\ttrain-mlogloss:0.06935\teval-mlogloss:0.51084\n",
      "[134]\ttrain-mlogloss:0.06840\teval-mlogloss:0.51098\n",
      "[135]\ttrain-mlogloss:0.06751\teval-mlogloss:0.51201\n",
      "[136]\ttrain-mlogloss:0.06665\teval-mlogloss:0.51274\n",
      "[137]\ttrain-mlogloss:0.06575\teval-mlogloss:0.51298\n",
      "[138]\ttrain-mlogloss:0.06491\teval-mlogloss:0.51300\n",
      "[139]\ttrain-mlogloss:0.06408\teval-mlogloss:0.51298\n",
      "[140]\ttrain-mlogloss:0.06326\teval-mlogloss:0.51262\n",
      "[141]\ttrain-mlogloss:0.06253\teval-mlogloss:0.51268\n",
      "[142]\ttrain-mlogloss:0.06180\teval-mlogloss:0.51243\n",
      "[143]\ttrain-mlogloss:0.06099\teval-mlogloss:0.51238\n",
      "[144]\ttrain-mlogloss:0.06028\teval-mlogloss:0.51272\n",
      "[145]\ttrain-mlogloss:0.05953\teval-mlogloss:0.51297\n",
      "[146]\ttrain-mlogloss:0.05882\teval-mlogloss:0.51257\n",
      "[147]\ttrain-mlogloss:0.05811\teval-mlogloss:0.51268\n",
      "[148]\ttrain-mlogloss:0.05744\teval-mlogloss:0.51302\n",
      "[149]\ttrain-mlogloss:0.05672\teval-mlogloss:0.51273\n",
      "[150]\ttrain-mlogloss:0.05603\teval-mlogloss:0.51234\n",
      "[151]\ttrain-mlogloss:0.05541\teval-mlogloss:0.51302\n",
      "[152]\ttrain-mlogloss:0.05476\teval-mlogloss:0.51265\n",
      "[153]\ttrain-mlogloss:0.05413\teval-mlogloss:0.51288\n",
      "[154]\ttrain-mlogloss:0.05351\teval-mlogloss:0.51306\n",
      "[155]\ttrain-mlogloss:0.05289\teval-mlogloss:0.51272\n",
      "[156]\ttrain-mlogloss:0.05228\teval-mlogloss:0.51293\n",
      "[157]\ttrain-mlogloss:0.05169\teval-mlogloss:0.51309\n",
      "[158]\ttrain-mlogloss:0.05111\teval-mlogloss:0.51375\n",
      "[159]\ttrain-mlogloss:0.05052\teval-mlogloss:0.51386\n",
      "[160]\ttrain-mlogloss:0.04995\teval-mlogloss:0.51425\n",
      "[161]\ttrain-mlogloss:0.04943\teval-mlogloss:0.51393\n",
      "[162]\ttrain-mlogloss:0.04889\teval-mlogloss:0.51446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[163]\ttrain-mlogloss:0.04835\teval-mlogloss:0.51480\n",
      "[164]\ttrain-mlogloss:0.04785\teval-mlogloss:0.51524\n",
      "[165]\ttrain-mlogloss:0.04734\teval-mlogloss:0.51564\n",
      "[166]\ttrain-mlogloss:0.04686\teval-mlogloss:0.51650\n",
      "[167]\ttrain-mlogloss:0.04635\teval-mlogloss:0.51691\n",
      "[168]\ttrain-mlogloss:0.04586\teval-mlogloss:0.51747\n",
      "[169]\ttrain-mlogloss:0.04536\teval-mlogloss:0.51727\n",
      "[170]\ttrain-mlogloss:0.04490\teval-mlogloss:0.51772\n",
      "[171]\ttrain-mlogloss:0.04442\teval-mlogloss:0.51807\n",
      "[172]\ttrain-mlogloss:0.04397\teval-mlogloss:0.51866\n",
      "[173]\ttrain-mlogloss:0.04353\teval-mlogloss:0.51901\n",
      "[174]\ttrain-mlogloss:0.04311\teval-mlogloss:0.51940\n",
      "[175]\ttrain-mlogloss:0.04267\teval-mlogloss:0.52013\n",
      "[176]\ttrain-mlogloss:0.04224\teval-mlogloss:0.51985\n",
      "[177]\ttrain-mlogloss:0.04184\teval-mlogloss:0.52027\n",
      "[178]\ttrain-mlogloss:0.04142\teval-mlogloss:0.51979\n",
      "[179]\ttrain-mlogloss:0.04101\teval-mlogloss:0.51993\n",
      "[180]\ttrain-mlogloss:0.04061\teval-mlogloss:0.52042\n",
      "[181]\ttrain-mlogloss:0.04022\teval-mlogloss:0.52069\n",
      "[182]\ttrain-mlogloss:0.03984\teval-mlogloss:0.52047\n",
      "[183]\ttrain-mlogloss:0.03945\teval-mlogloss:0.52069\n",
      "[184]\ttrain-mlogloss:0.03910\teval-mlogloss:0.52051\n",
      "[185]\ttrain-mlogloss:0.03873\teval-mlogloss:0.52131\n",
      "[186]\ttrain-mlogloss:0.03838\teval-mlogloss:0.52185\n",
      "[187]\ttrain-mlogloss:0.03804\teval-mlogloss:0.52190\n",
      "[188]\ttrain-mlogloss:0.03771\teval-mlogloss:0.52205\n",
      "[189]\ttrain-mlogloss:0.03737\teval-mlogloss:0.52274\n",
      "[190]\ttrain-mlogloss:0.03704\teval-mlogloss:0.52230\n",
      "[191]\ttrain-mlogloss:0.03672\teval-mlogloss:0.52266\n",
      "[192]\ttrain-mlogloss:0.03642\teval-mlogloss:0.52326\n",
      "[193]\ttrain-mlogloss:0.03611\teval-mlogloss:0.52290\n",
      "[194]\ttrain-mlogloss:0.03580\teval-mlogloss:0.52325\n",
      "[195]\ttrain-mlogloss:0.03551\teval-mlogloss:0.52374\n",
      "[196]\ttrain-mlogloss:0.03522\teval-mlogloss:0.52401\n",
      "[197]\ttrain-mlogloss:0.03490\teval-mlogloss:0.52350\n",
      "[198]\ttrain-mlogloss:0.03463\teval-mlogloss:0.52368\n",
      "[199]\ttrain-mlogloss:0.03436\teval-mlogloss:0.52428\n",
      "[200]\ttrain-mlogloss:0.03408\teval-mlogloss:0.52425\n",
      "[201]\ttrain-mlogloss:0.03381\teval-mlogloss:0.52450\n",
      "[202]\ttrain-mlogloss:0.03354\teval-mlogloss:0.52502\n",
      "[203]\ttrain-mlogloss:0.03329\teval-mlogloss:0.52497\n",
      "[204]\ttrain-mlogloss:0.03302\teval-mlogloss:0.52568\n",
      "[205]\ttrain-mlogloss:0.03276\teval-mlogloss:0.52610\n",
      "[206]\ttrain-mlogloss:0.03251\teval-mlogloss:0.52639\n",
      "[207]\ttrain-mlogloss:0.03228\teval-mlogloss:0.52596\n"
     ]
    }
   ],
   "source": [
    "#t7_0.53219 ########성능 0.683 원래에서 max_depth 10로 0.791\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, \n",
    "                                                    test_size=0.1, \n",
    "                                                    stratify=train_y, \n",
    "                                                    random_state=37)\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(data=X_test, label=y_test)\n",
    "#dtest_x = xgb.DMatrix(data=test_x)\n",
    "\n",
    "params = {'max_depth' : 10,\n",
    "          'eta': 0.03,\n",
    "          'objective':'multi:softmax',\n",
    "          'num_class':3,\n",
    "          'eval_metric':'mlogloss',\n",
    "#           'eval_set': [(X_test, y_test)], #적용이 안 되고 있다고 뜸\n",
    "#           'early_stopping':100 #적용이 안 되고 있다고 뜸\n",
    "          }\n",
    "num_rounds = 400\n",
    "\n",
    "wlist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "xgb_model = xgb.train(params=params, \n",
    "                      dtrain=dtrain, \n",
    "                      num_boost_round=num_rounds, \n",
    "                      early_stopping_rounds=100, \n",
    "                      evals=wlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e7348323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7918075276087446\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_model.predict(dtest, ntree_limit=xgb_model.best_ntree_limit)\n",
    "preds = np.round(y_pred).astype(int)\n",
    "print(f1_score(y_test, preds, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "38e8f8e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.06414\teval-mlogloss:1.07218\n",
      "[1]\ttrain-mlogloss:1.03142\teval-mlogloss:1.04668\n",
      "[2]\ttrain-mlogloss:1.00052\teval-mlogloss:1.02519\n",
      "[3]\ttrain-mlogloss:0.97054\teval-mlogloss:1.00240\n",
      "[4]\ttrain-mlogloss:0.94299\teval-mlogloss:0.98364\n",
      "[5]\ttrain-mlogloss:0.91671\teval-mlogloss:0.96251\n",
      "[6]\ttrain-mlogloss:0.89149\teval-mlogloss:0.94173\n",
      "[7]\ttrain-mlogloss:0.86732\teval-mlogloss:0.92338\n",
      "[8]\ttrain-mlogloss:0.84442\teval-mlogloss:0.90463\n",
      "[9]\ttrain-mlogloss:0.82251\teval-mlogloss:0.88676\n",
      "[10]\ttrain-mlogloss:0.80135\teval-mlogloss:0.86907\n",
      "[11]\ttrain-mlogloss:0.78150\teval-mlogloss:0.85287\n",
      "[12]\ttrain-mlogloss:0.76243\teval-mlogloss:0.83708\n",
      "[13]\ttrain-mlogloss:0.74417\teval-mlogloss:0.82313\n",
      "[14]\ttrain-mlogloss:0.72705\teval-mlogloss:0.80971\n",
      "[15]\ttrain-mlogloss:0.71031\teval-mlogloss:0.79851\n",
      "[16]\ttrain-mlogloss:0.69456\teval-mlogloss:0.78730\n",
      "[17]\ttrain-mlogloss:0.67880\teval-mlogloss:0.77663\n",
      "[18]\ttrain-mlogloss:0.66375\teval-mlogloss:0.76521\n",
      "[19]\ttrain-mlogloss:0.64977\teval-mlogloss:0.75537\n",
      "[20]\ttrain-mlogloss:0.63588\teval-mlogloss:0.74564\n",
      "[21]\ttrain-mlogloss:0.62236\teval-mlogloss:0.73577\n",
      "[22]\ttrain-mlogloss:0.60948\teval-mlogloss:0.72589\n",
      "[23]\ttrain-mlogloss:0.59518\teval-mlogloss:0.71716\n",
      "[24]\ttrain-mlogloss:0.58191\teval-mlogloss:0.70945\n",
      "[25]\ttrain-mlogloss:0.57015\teval-mlogloss:0.70001\n",
      "[26]\ttrain-mlogloss:0.55847\teval-mlogloss:0.69186\n",
      "[27]\ttrain-mlogloss:0.54715\teval-mlogloss:0.68354\n",
      "[28]\ttrain-mlogloss:0.53619\teval-mlogloss:0.67578\n",
      "[29]\ttrain-mlogloss:0.52488\teval-mlogloss:0.66918\n",
      "[30]\ttrain-mlogloss:0.51532\teval-mlogloss:0.66290\n",
      "[31]\ttrain-mlogloss:0.50449\teval-mlogloss:0.65592\n",
      "[32]\ttrain-mlogloss:0.49456\teval-mlogloss:0.64896\n",
      "[33]\ttrain-mlogloss:0.48564\teval-mlogloss:0.64430\n",
      "[34]\ttrain-mlogloss:0.47614\teval-mlogloss:0.63934\n",
      "[35]\ttrain-mlogloss:0.46646\teval-mlogloss:0.63419\n",
      "[36]\ttrain-mlogloss:0.45753\teval-mlogloss:0.62963\n",
      "[37]\ttrain-mlogloss:0.44868\teval-mlogloss:0.62617\n",
      "[38]\ttrain-mlogloss:0.43925\teval-mlogloss:0.62108\n",
      "[39]\ttrain-mlogloss:0.43023\teval-mlogloss:0.61795\n",
      "[40]\ttrain-mlogloss:0.42089\teval-mlogloss:0.61403\n",
      "[41]\ttrain-mlogloss:0.41202\teval-mlogloss:0.61061\n",
      "[42]\ttrain-mlogloss:0.40332\teval-mlogloss:0.60662\n",
      "[43]\ttrain-mlogloss:0.39443\teval-mlogloss:0.60288\n",
      "[44]\ttrain-mlogloss:0.38616\teval-mlogloss:0.59997\n",
      "[45]\ttrain-mlogloss:0.37835\teval-mlogloss:0.59831\n",
      "[46]\ttrain-mlogloss:0.37031\teval-mlogloss:0.59672\n",
      "[47]\ttrain-mlogloss:0.36245\teval-mlogloss:0.59488\n",
      "[48]\ttrain-mlogloss:0.35549\teval-mlogloss:0.59275\n",
      "[49]\ttrain-mlogloss:0.34896\teval-mlogloss:0.58940\n",
      "[50]\ttrain-mlogloss:0.34296\teval-mlogloss:0.58721\n",
      "[51]\ttrain-mlogloss:0.33667\teval-mlogloss:0.58506\n",
      "[52]\ttrain-mlogloss:0.33093\teval-mlogloss:0.58329\n",
      "[53]\ttrain-mlogloss:0.32488\teval-mlogloss:0.58165\n",
      "[54]\ttrain-mlogloss:0.31830\teval-mlogloss:0.57991\n",
      "[55]\ttrain-mlogloss:0.31328\teval-mlogloss:0.57911\n",
      "[56]\ttrain-mlogloss:0.30809\teval-mlogloss:0.57742\n",
      "[57]\ttrain-mlogloss:0.30241\teval-mlogloss:0.57597\n",
      "[58]\ttrain-mlogloss:0.29682\teval-mlogloss:0.57464\n",
      "[59]\ttrain-mlogloss:0.29216\teval-mlogloss:0.57295\n",
      "[60]\ttrain-mlogloss:0.28706\teval-mlogloss:0.56987\n",
      "[61]\ttrain-mlogloss:0.28314\teval-mlogloss:0.56859\n",
      "[62]\ttrain-mlogloss:0.27775\teval-mlogloss:0.56600\n",
      "[63]\ttrain-mlogloss:0.27217\teval-mlogloss:0.56506\n",
      "[64]\ttrain-mlogloss:0.26720\teval-mlogloss:0.56314\n",
      "[65]\ttrain-mlogloss:0.26304\teval-mlogloss:0.56289\n",
      "[66]\ttrain-mlogloss:0.25822\teval-mlogloss:0.56125\n",
      "[67]\ttrain-mlogloss:0.25369\teval-mlogloss:0.55987\n",
      "[68]\ttrain-mlogloss:0.24965\teval-mlogloss:0.55935\n",
      "[69]\ttrain-mlogloss:0.24499\teval-mlogloss:0.55739\n",
      "[70]\ttrain-mlogloss:0.24136\teval-mlogloss:0.55638\n",
      "[71]\ttrain-mlogloss:0.23731\teval-mlogloss:0.55562\n",
      "[72]\ttrain-mlogloss:0.23421\teval-mlogloss:0.55405\n",
      "[73]\ttrain-mlogloss:0.23075\teval-mlogloss:0.55346\n",
      "[74]\ttrain-mlogloss:0.22707\teval-mlogloss:0.55148\n",
      "[75]\ttrain-mlogloss:0.22406\teval-mlogloss:0.54910\n",
      "[76]\ttrain-mlogloss:0.22123\teval-mlogloss:0.54795\n",
      "[77]\ttrain-mlogloss:0.21833\teval-mlogloss:0.54605\n",
      "[78]\ttrain-mlogloss:0.21491\teval-mlogloss:0.54524\n",
      "[79]\ttrain-mlogloss:0.21204\teval-mlogloss:0.54451\n",
      "[80]\ttrain-mlogloss:0.20940\teval-mlogloss:0.54354\n",
      "[81]\ttrain-mlogloss:0.20663\teval-mlogloss:0.54220\n",
      "[82]\ttrain-mlogloss:0.20435\teval-mlogloss:0.54192\n",
      "[83]\ttrain-mlogloss:0.20178\teval-mlogloss:0.54163\n",
      "[84]\ttrain-mlogloss:0.19948\teval-mlogloss:0.54074\n",
      "[85]\ttrain-mlogloss:0.19640\teval-mlogloss:0.54069\n",
      "[86]\ttrain-mlogloss:0.19353\teval-mlogloss:0.54111\n",
      "[87]\ttrain-mlogloss:0.19143\teval-mlogloss:0.54173\n",
      "[88]\ttrain-mlogloss:0.18891\teval-mlogloss:0.54209\n",
      "[89]\ttrain-mlogloss:0.18685\teval-mlogloss:0.54134\n",
      "[90]\ttrain-mlogloss:0.18463\teval-mlogloss:0.54129\n",
      "[91]\ttrain-mlogloss:0.18263\teval-mlogloss:0.54138\n",
      "[92]\ttrain-mlogloss:0.18038\teval-mlogloss:0.54161\n",
      "[93]\ttrain-mlogloss:0.17818\teval-mlogloss:0.54084\n",
      "[94]\ttrain-mlogloss:0.17606\teval-mlogloss:0.54177\n",
      "[95]\ttrain-mlogloss:0.17395\teval-mlogloss:0.54163\n",
      "[96]\ttrain-mlogloss:0.17165\teval-mlogloss:0.54176\n",
      "[97]\ttrain-mlogloss:0.16977\teval-mlogloss:0.54156\n",
      "[98]\ttrain-mlogloss:0.16794\teval-mlogloss:0.54145\n",
      "[99]\ttrain-mlogloss:0.16580\teval-mlogloss:0.54167\n",
      "[100]\ttrain-mlogloss:0.16411\teval-mlogloss:0.54219\n",
      "[101]\ttrain-mlogloss:0.16248\teval-mlogloss:0.54280\n",
      "[102]\ttrain-mlogloss:0.16078\teval-mlogloss:0.54266\n",
      "[103]\ttrain-mlogloss:0.15889\teval-mlogloss:0.54219\n",
      "[104]\ttrain-mlogloss:0.15706\teval-mlogloss:0.54330\n",
      "[105]\ttrain-mlogloss:0.15501\teval-mlogloss:0.54313\n",
      "[106]\ttrain-mlogloss:0.15270\teval-mlogloss:0.54297\n",
      "[107]\ttrain-mlogloss:0.15127\teval-mlogloss:0.54297\n",
      "[108]\ttrain-mlogloss:0.14920\teval-mlogloss:0.54362\n",
      "[109]\ttrain-mlogloss:0.14759\teval-mlogloss:0.54250\n",
      "[110]\ttrain-mlogloss:0.14617\teval-mlogloss:0.54280\n",
      "[111]\ttrain-mlogloss:0.14444\teval-mlogloss:0.54295\n",
      "[112]\ttrain-mlogloss:0.14313\teval-mlogloss:0.54226\n",
      "[113]\ttrain-mlogloss:0.14158\teval-mlogloss:0.54265\n",
      "[114]\ttrain-mlogloss:0.14001\teval-mlogloss:0.54274\n",
      "[115]\ttrain-mlogloss:0.13836\teval-mlogloss:0.54287\n",
      "[116]\ttrain-mlogloss:0.13701\teval-mlogloss:0.54301\n",
      "[117]\ttrain-mlogloss:0.13545\teval-mlogloss:0.54227\n",
      "[118]\ttrain-mlogloss:0.13390\teval-mlogloss:0.54247\n",
      "[119]\ttrain-mlogloss:0.13265\teval-mlogloss:0.54267\n",
      "[120]\ttrain-mlogloss:0.13135\teval-mlogloss:0.54312\n",
      "[121]\ttrain-mlogloss:0.12991\teval-mlogloss:0.54288\n",
      "[122]\ttrain-mlogloss:0.12861\teval-mlogloss:0.54269\n",
      "[123]\ttrain-mlogloss:0.12729\teval-mlogloss:0.54201\n",
      "[124]\ttrain-mlogloss:0.12605\teval-mlogloss:0.54175\n",
      "[125]\ttrain-mlogloss:0.12490\teval-mlogloss:0.54199\n",
      "[126]\ttrain-mlogloss:0.12363\teval-mlogloss:0.54277\n",
      "[127]\ttrain-mlogloss:0.12239\teval-mlogloss:0.54329\n",
      "[128]\ttrain-mlogloss:0.12133\teval-mlogloss:0.54309\n",
      "[129]\ttrain-mlogloss:0.12019\teval-mlogloss:0.54328\n",
      "[130]\ttrain-mlogloss:0.11907\teval-mlogloss:0.54285\n",
      "[131]\ttrain-mlogloss:0.11801\teval-mlogloss:0.54283\n",
      "[132]\ttrain-mlogloss:0.11682\teval-mlogloss:0.54188\n",
      "[133]\ttrain-mlogloss:0.11552\teval-mlogloss:0.54126\n",
      "[134]\ttrain-mlogloss:0.11423\teval-mlogloss:0.54035\n",
      "[135]\ttrain-mlogloss:0.11325\teval-mlogloss:0.54046\n",
      "[136]\ttrain-mlogloss:0.11198\teval-mlogloss:0.54117\n",
      "[137]\ttrain-mlogloss:0.11095\teval-mlogloss:0.54164\n",
      "[138]\ttrain-mlogloss:0.10969\teval-mlogloss:0.54059\n",
      "[139]\ttrain-mlogloss:0.10885\teval-mlogloss:0.54124\n",
      "[140]\ttrain-mlogloss:0.10785\teval-mlogloss:0.54126\n",
      "[141]\ttrain-mlogloss:0.10701\teval-mlogloss:0.54198\n",
      "[142]\ttrain-mlogloss:0.10599\teval-mlogloss:0.54252\n",
      "[143]\ttrain-mlogloss:0.10492\teval-mlogloss:0.54313\n",
      "[144]\ttrain-mlogloss:0.10360\teval-mlogloss:0.54243\n",
      "[145]\ttrain-mlogloss:0.10270\teval-mlogloss:0.54218\n",
      "[146]\ttrain-mlogloss:0.10161\teval-mlogloss:0.54194\n",
      "[147]\ttrain-mlogloss:0.10068\teval-mlogloss:0.54142\n",
      "[148]\ttrain-mlogloss:0.09981\teval-mlogloss:0.54149\n",
      "[149]\ttrain-mlogloss:0.09870\teval-mlogloss:0.54181\n",
      "[150]\ttrain-mlogloss:0.09784\teval-mlogloss:0.54251\n",
      "[151]\ttrain-mlogloss:0.09693\teval-mlogloss:0.54290\n",
      "[152]\ttrain-mlogloss:0.09603\teval-mlogloss:0.54243\n",
      "[153]\ttrain-mlogloss:0.09497\teval-mlogloss:0.54277\n",
      "[154]\ttrain-mlogloss:0.09420\teval-mlogloss:0.54323\n",
      "[155]\ttrain-mlogloss:0.09306\teval-mlogloss:0.54261\n",
      "[156]\ttrain-mlogloss:0.09231\teval-mlogloss:0.54318\n",
      "[157]\ttrain-mlogloss:0.09152\teval-mlogloss:0.54321\n",
      "[158]\ttrain-mlogloss:0.09081\teval-mlogloss:0.54453\n",
      "[159]\ttrain-mlogloss:0.09005\teval-mlogloss:0.54473\n",
      "[160]\ttrain-mlogloss:0.08918\teval-mlogloss:0.54447\n",
      "[161]\ttrain-mlogloss:0.08818\teval-mlogloss:0.54339\n",
      "[162]\ttrain-mlogloss:0.08741\teval-mlogloss:0.54361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[163]\ttrain-mlogloss:0.08658\teval-mlogloss:0.54319\n",
      "[164]\ttrain-mlogloss:0.08580\teval-mlogloss:0.54360\n",
      "[165]\ttrain-mlogloss:0.08513\teval-mlogloss:0.54335\n",
      "[166]\ttrain-mlogloss:0.08432\teval-mlogloss:0.54375\n",
      "[167]\ttrain-mlogloss:0.08355\teval-mlogloss:0.54421\n",
      "[168]\ttrain-mlogloss:0.08263\teval-mlogloss:0.54343\n",
      "[169]\ttrain-mlogloss:0.08186\teval-mlogloss:0.54386\n",
      "[170]\ttrain-mlogloss:0.08103\teval-mlogloss:0.54450\n",
      "[171]\ttrain-mlogloss:0.08021\teval-mlogloss:0.54430\n",
      "[172]\ttrain-mlogloss:0.07954\teval-mlogloss:0.54411\n",
      "[173]\ttrain-mlogloss:0.07879\teval-mlogloss:0.54337\n",
      "[174]\ttrain-mlogloss:0.07806\teval-mlogloss:0.54366\n",
      "[175]\ttrain-mlogloss:0.07740\teval-mlogloss:0.54397\n",
      "[176]\ttrain-mlogloss:0.07670\teval-mlogloss:0.54462\n",
      "[177]\ttrain-mlogloss:0.07605\teval-mlogloss:0.54556\n",
      "[178]\ttrain-mlogloss:0.07541\teval-mlogloss:0.54595\n",
      "[179]\ttrain-mlogloss:0.07477\teval-mlogloss:0.54635\n",
      "[180]\ttrain-mlogloss:0.07410\teval-mlogloss:0.54706\n",
      "[181]\ttrain-mlogloss:0.07353\teval-mlogloss:0.54824\n",
      "[182]\ttrain-mlogloss:0.07288\teval-mlogloss:0.54907\n",
      "[183]\ttrain-mlogloss:0.07226\teval-mlogloss:0.54872\n",
      "[184]\ttrain-mlogloss:0.07150\teval-mlogloss:0.54857\n",
      "[185]\ttrain-mlogloss:0.07082\teval-mlogloss:0.54930\n",
      "[186]\ttrain-mlogloss:0.07018\teval-mlogloss:0.54911\n",
      "[187]\ttrain-mlogloss:0.06966\teval-mlogloss:0.54935\n",
      "[188]\ttrain-mlogloss:0.06906\teval-mlogloss:0.54924\n",
      "[189]\ttrain-mlogloss:0.06844\teval-mlogloss:0.54955\n",
      "[190]\ttrain-mlogloss:0.06768\teval-mlogloss:0.54933\n",
      "[191]\ttrain-mlogloss:0.06715\teval-mlogloss:0.54882\n",
      "[192]\ttrain-mlogloss:0.06646\teval-mlogloss:0.54887\n",
      "[193]\ttrain-mlogloss:0.06595\teval-mlogloss:0.54930\n",
      "[194]\ttrain-mlogloss:0.06549\teval-mlogloss:0.54923\n",
      "[195]\ttrain-mlogloss:0.06490\teval-mlogloss:0.54964\n",
      "[196]\ttrain-mlogloss:0.06435\teval-mlogloss:0.54934\n",
      "[197]\ttrain-mlogloss:0.06387\teval-mlogloss:0.54911\n",
      "[198]\ttrain-mlogloss:0.06342\teval-mlogloss:0.54937\n",
      "[199]\ttrain-mlogloss:0.06302\teval-mlogloss:0.54985\n",
      "[200]\ttrain-mlogloss:0.06244\teval-mlogloss:0.54983\n",
      "[201]\ttrain-mlogloss:0.06192\teval-mlogloss:0.54967\n",
      "[202]\ttrain-mlogloss:0.06140\teval-mlogloss:0.54969\n",
      "[203]\ttrain-mlogloss:0.06096\teval-mlogloss:0.54956\n",
      "[204]\ttrain-mlogloss:0.06038\teval-mlogloss:0.54957\n",
      "[205]\ttrain-mlogloss:0.05990\teval-mlogloss:0.54985\n",
      "[206]\ttrain-mlogloss:0.05945\teval-mlogloss:0.55018\n",
      "[207]\ttrain-mlogloss:0.05903\teval-mlogloss:0.55133\n",
      "[208]\ttrain-mlogloss:0.05854\teval-mlogloss:0.55019\n",
      "[209]\ttrain-mlogloss:0.05809\teval-mlogloss:0.54949\n",
      "[210]\ttrain-mlogloss:0.05767\teval-mlogloss:0.55024\n",
      "[211]\ttrain-mlogloss:0.05714\teval-mlogloss:0.54992\n",
      "[212]\ttrain-mlogloss:0.05655\teval-mlogloss:0.55004\n",
      "[213]\ttrain-mlogloss:0.05610\teval-mlogloss:0.55005\n",
      "[214]\ttrain-mlogloss:0.05563\teval-mlogloss:0.55012\n",
      "[215]\ttrain-mlogloss:0.05516\teval-mlogloss:0.54979\n",
      "[216]\ttrain-mlogloss:0.05472\teval-mlogloss:0.55009\n",
      "[217]\ttrain-mlogloss:0.05429\teval-mlogloss:0.54965\n",
      "[218]\ttrain-mlogloss:0.05384\teval-mlogloss:0.54925\n",
      "[219]\ttrain-mlogloss:0.05342\teval-mlogloss:0.54830\n",
      "[220]\ttrain-mlogloss:0.05301\teval-mlogloss:0.54862\n",
      "[221]\ttrain-mlogloss:0.05263\teval-mlogloss:0.54877\n",
      "[222]\ttrain-mlogloss:0.05217\teval-mlogloss:0.54810\n",
      "[223]\ttrain-mlogloss:0.05165\teval-mlogloss:0.54797\n",
      "[224]\ttrain-mlogloss:0.05123\teval-mlogloss:0.54801\n",
      "[225]\ttrain-mlogloss:0.05081\teval-mlogloss:0.54849\n",
      "[226]\ttrain-mlogloss:0.05042\teval-mlogloss:0.54793\n",
      "[227]\ttrain-mlogloss:0.05009\teval-mlogloss:0.54885\n",
      "[228]\ttrain-mlogloss:0.04973\teval-mlogloss:0.54918\n",
      "[229]\ttrain-mlogloss:0.04929\teval-mlogloss:0.54865\n",
      "[230]\ttrain-mlogloss:0.04882\teval-mlogloss:0.54862\n",
      "[231]\ttrain-mlogloss:0.04847\teval-mlogloss:0.54844\n",
      "[232]\ttrain-mlogloss:0.04808\teval-mlogloss:0.54721\n",
      "[233]\ttrain-mlogloss:0.04766\teval-mlogloss:0.54780\n",
      "[234]\ttrain-mlogloss:0.04725\teval-mlogloss:0.54702\n"
     ]
    }
   ],
   "source": [
    "#t7_0.53219 ########성능 0.683 원래에서 eta 0.035로 0.807\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, \n",
    "                                                    test_size=0.1, \n",
    "                                                    stratify=train_y, \n",
    "                                                    random_state=37)\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(data=X_test, label=y_test)\n",
    "dtest_x = xgb.DMatrix(data=test_x)\n",
    "\n",
    "params = {'max_depth' : 6,\n",
    "          'eta': 0.035,\n",
    "          'objective':'multi:softmax',\n",
    "          'num_class':3,\n",
    "          'eval_metric':'mlogloss'\n",
    "          }\n",
    "num_rounds = 400\n",
    "\n",
    "wlist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "xgb_model = xgb.train(params=params, \n",
    "                      dtrain=dtrain, \n",
    "                      num_boost_round=num_rounds, \n",
    "                      early_stopping_rounds=100, \n",
    "                      evals=wlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "220058ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8070874861572537\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_model.predict(dtest, ntree_limit=xgb_model.best_ntree_limit)\n",
    "preds = np.round(y_pred).astype(int)\n",
    "print(f1_score(y_test, preds, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "37e2adb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = xgb_model.predict(dtest_x, ntree_limit=xgb_model.best_ntree_limit)\n",
    "preds = np.round(pred_probs).astype(int)\n",
    "sub3['Y_Class'] = preds\n",
    "sub3.to_csv('./t30_XGB_Dmatrix_Earlystopping_eta0035_testsize01.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4336e024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22adabae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdfa603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "73690cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7557720057720058\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_model.predict(dtest, ntree_limit=xgb_model.best_ntree_limit)\n",
    "preds = np.round(y_pred).astype(int)\n",
    "print(f1_score(y_test, preds, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edfd1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4a9c36fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:0.95927\n",
      "[1]\tvalidation_0-mlogloss:0.85181\n",
      "[2]\tvalidation_0-mlogloss:0.75319\n",
      "[3]\tvalidation_0-mlogloss:0.72759\n",
      "[4]\tvalidation_0-mlogloss:0.72671\n",
      "[5]\tvalidation_0-mlogloss:0.69939\n",
      "[6]\tvalidation_0-mlogloss:0.66953\n",
      "[7]\tvalidation_0-mlogloss:0.65160\n",
      "[8]\tvalidation_0-mlogloss:0.65946\n",
      "[9]\tvalidation_0-mlogloss:0.61611\n",
      "[10]\tvalidation_0-mlogloss:0.61855\n",
      "[11]\tvalidation_0-mlogloss:0.60403\n",
      "[12]\tvalidation_0-mlogloss:0.59930\n",
      "[13]\tvalidation_0-mlogloss:0.59560\n",
      "[14]\tvalidation_0-mlogloss:0.57280\n",
      "[15]\tvalidation_0-mlogloss:0.56851\n",
      "[16]\tvalidation_0-mlogloss:0.55139\n",
      "[17]\tvalidation_0-mlogloss:0.54871\n",
      "[18]\tvalidation_0-mlogloss:0.55955\n",
      "[19]\tvalidation_0-mlogloss:0.57247\n",
      "[20]\tvalidation_0-mlogloss:0.57112\n",
      "[21]\tvalidation_0-mlogloss:0.57502\n",
      "[22]\tvalidation_0-mlogloss:0.57584\n",
      "[23]\tvalidation_0-mlogloss:0.57856\n",
      "[24]\tvalidation_0-mlogloss:0.57598\n",
      "[25]\tvalidation_0-mlogloss:0.57346\n",
      "[26]\tvalidation_0-mlogloss:0.57668\n",
      "[27]\tvalidation_0-mlogloss:0.57791\n",
      "[28]\tvalidation_0-mlogloss:0.58307\n",
      "[29]\tvalidation_0-mlogloss:0.58649\n",
      "[30]\tvalidation_0-mlogloss:0.58338\n",
      "[31]\tvalidation_0-mlogloss:0.58027\n",
      "[32]\tvalidation_0-mlogloss:0.58372\n",
      "[33]\tvalidation_0-mlogloss:0.58238\n",
      "[34]\tvalidation_0-mlogloss:0.58658\n",
      "[35]\tvalidation_0-mlogloss:0.58921\n",
      "[36]\tvalidation_0-mlogloss:0.58628\n",
      "[0]\tvalidation_0-mlogloss:0.80077\n",
      "[1]\tvalidation_0-mlogloss:0.64405\n",
      "[2]\tvalidation_0-mlogloss:0.53885\n",
      "[3]\tvalidation_0-mlogloss:0.46897\n",
      "[4]\tvalidation_0-mlogloss:0.42834\n",
      "[5]\tvalidation_0-mlogloss:0.39751\n",
      "[6]\tvalidation_0-mlogloss:0.38084\n",
      "[7]\tvalidation_0-mlogloss:0.37567\n",
      "[8]\tvalidation_0-mlogloss:0.37680\n",
      "[9]\tvalidation_0-mlogloss:0.38121\n",
      "[10]\tvalidation_0-mlogloss:0.39108\n",
      "[11]\tvalidation_0-mlogloss:0.38997\n",
      "[12]\tvalidation_0-mlogloss:0.39679\n",
      "[13]\tvalidation_0-mlogloss:0.40343\n",
      "[14]\tvalidation_0-mlogloss:0.40537\n",
      "[15]\tvalidation_0-mlogloss:0.41289\n",
      "[16]\tvalidation_0-mlogloss:0.41499\n",
      "[17]\tvalidation_0-mlogloss:0.42038\n",
      "[18]\tvalidation_0-mlogloss:0.42786\n",
      "[19]\tvalidation_0-mlogloss:0.43539\n",
      "[20]\tvalidation_0-mlogloss:0.43745\n",
      "[21]\tvalidation_0-mlogloss:0.44649\n",
      "[22]\tvalidation_0-mlogloss:0.45099\n",
      "[23]\tvalidation_0-mlogloss:0.45356\n",
      "[24]\tvalidation_0-mlogloss:0.45304\n",
      "[25]\tvalidation_0-mlogloss:0.45793\n",
      "[26]\tvalidation_0-mlogloss:0.45981\n",
      "[27]\tvalidation_0-mlogloss:0.46228\n",
      "[0]\tvalidation_0-mlogloss:0.85781\n",
      "[1]\tvalidation_0-mlogloss:0.69241\n",
      "[2]\tvalidation_0-mlogloss:0.57941\n",
      "[3]\tvalidation_0-mlogloss:0.49452\n",
      "[4]\tvalidation_0-mlogloss:0.44071\n",
      "[5]\tvalidation_0-mlogloss:0.40510\n",
      "[6]\tvalidation_0-mlogloss:0.38454\n",
      "[7]\tvalidation_0-mlogloss:0.36933\n",
      "[8]\tvalidation_0-mlogloss:0.35339\n",
      "[9]\tvalidation_0-mlogloss:0.35511\n",
      "[10]\tvalidation_0-mlogloss:0.36026\n",
      "[11]\tvalidation_0-mlogloss:0.36346\n",
      "[12]\tvalidation_0-mlogloss:0.36700\n",
      "[13]\tvalidation_0-mlogloss:0.37104\n",
      "[14]\tvalidation_0-mlogloss:0.37837\n",
      "[15]\tvalidation_0-mlogloss:0.37900\n",
      "[16]\tvalidation_0-mlogloss:0.38932\n",
      "[17]\tvalidation_0-mlogloss:0.39601\n",
      "[18]\tvalidation_0-mlogloss:0.40030\n",
      "[19]\tvalidation_0-mlogloss:0.40969\n",
      "[20]\tvalidation_0-mlogloss:0.41730\n",
      "[21]\tvalidation_0-mlogloss:0.42141\n",
      "[22]\tvalidation_0-mlogloss:0.43011\n",
      "[23]\tvalidation_0-mlogloss:0.43034\n",
      "[24]\tvalidation_0-mlogloss:0.42826\n",
      "[25]\tvalidation_0-mlogloss:0.42957\n",
      "[26]\tvalidation_0-mlogloss:0.43630\n",
      "[27]\tvalidation_0-mlogloss:0.43821\n",
      "[28]\tvalidation_0-mlogloss:0.44527\n",
      "[0]\tvalidation_0-mlogloss:0.97287\n",
      "[1]\tvalidation_0-mlogloss:0.86217\n",
      "[2]\tvalidation_0-mlogloss:0.80863\n",
      "[3]\tvalidation_0-mlogloss:0.79694\n",
      "[4]\tvalidation_0-mlogloss:0.72718\n",
      "[5]\tvalidation_0-mlogloss:0.69723\n",
      "[6]\tvalidation_0-mlogloss:0.66414\n",
      "[7]\tvalidation_0-mlogloss:0.63438\n",
      "[8]\tvalidation_0-mlogloss:0.62025\n",
      "[9]\tvalidation_0-mlogloss:0.60368\n",
      "[10]\tvalidation_0-mlogloss:0.59932\n",
      "[11]\tvalidation_0-mlogloss:0.59433\n",
      "[12]\tvalidation_0-mlogloss:0.58358\n",
      "[13]\tvalidation_0-mlogloss:0.56704\n",
      "[14]\tvalidation_0-mlogloss:0.56352\n",
      "[15]\tvalidation_0-mlogloss:0.55889\n",
      "[16]\tvalidation_0-mlogloss:0.54485\n",
      "[17]\tvalidation_0-mlogloss:0.52856\n",
      "[18]\tvalidation_0-mlogloss:0.51967\n",
      "[19]\tvalidation_0-mlogloss:0.52441\n",
      "[20]\tvalidation_0-mlogloss:0.51983\n",
      "[21]\tvalidation_0-mlogloss:0.52301\n",
      "[22]\tvalidation_0-mlogloss:0.51672\n",
      "[23]\tvalidation_0-mlogloss:0.50830\n",
      "[24]\tvalidation_0-mlogloss:0.51493\n",
      "[25]\tvalidation_0-mlogloss:0.51795\n",
      "[26]\tvalidation_0-mlogloss:0.52205\n",
      "[27]\tvalidation_0-mlogloss:0.52201\n",
      "[28]\tvalidation_0-mlogloss:0.51906\n",
      "[29]\tvalidation_0-mlogloss:0.52069\n",
      "[30]\tvalidation_0-mlogloss:0.51950\n",
      "[31]\tvalidation_0-mlogloss:0.51122\n",
      "[32]\tvalidation_0-mlogloss:0.50159\n",
      "[33]\tvalidation_0-mlogloss:0.51077\n",
      "[34]\tvalidation_0-mlogloss:0.52358\n",
      "[35]\tvalidation_0-mlogloss:0.52591\n",
      "[36]\tvalidation_0-mlogloss:0.52439\n",
      "[37]\tvalidation_0-mlogloss:0.52757\n",
      "[38]\tvalidation_0-mlogloss:0.52842\n",
      "[39]\tvalidation_0-mlogloss:0.52995\n",
      "[40]\tvalidation_0-mlogloss:0.52733\n",
      "[41]\tvalidation_0-mlogloss:0.52594\n",
      "[42]\tvalidation_0-mlogloss:0.53817\n",
      "[43]\tvalidation_0-mlogloss:0.53860\n",
      "[44]\tvalidation_0-mlogloss:0.53735\n",
      "[45]\tvalidation_0-mlogloss:0.53803\n",
      "[46]\tvalidation_0-mlogloss:0.53835\n",
      "[47]\tvalidation_0-mlogloss:0.54038\n",
      "[48]\tvalidation_0-mlogloss:0.53788\n",
      "[49]\tvalidation_0-mlogloss:0.53702\n",
      "[50]\tvalidation_0-mlogloss:0.53833\n",
      "[51]\tvalidation_0-mlogloss:0.53716\n",
      "[0]\tvalidation_0-mlogloss:0.83460\n",
      "[1]\tvalidation_0-mlogloss:0.69052\n",
      "[2]\tvalidation_0-mlogloss:0.60905\n",
      "[3]\tvalidation_0-mlogloss:0.52935\n",
      "[4]\tvalidation_0-mlogloss:0.48661\n",
      "[5]\tvalidation_0-mlogloss:0.44833\n",
      "[6]\tvalidation_0-mlogloss:0.42640\n",
      "[7]\tvalidation_0-mlogloss:0.41356\n",
      "[8]\tvalidation_0-mlogloss:0.41496\n",
      "[9]\tvalidation_0-mlogloss:0.41679\n",
      "[10]\tvalidation_0-mlogloss:0.40637\n",
      "[11]\tvalidation_0-mlogloss:0.40427\n",
      "[12]\tvalidation_0-mlogloss:0.40954\n",
      "[13]\tvalidation_0-mlogloss:0.41279\n",
      "[14]\tvalidation_0-mlogloss:0.41483\n",
      "[15]\tvalidation_0-mlogloss:0.41639\n",
      "[16]\tvalidation_0-mlogloss:0.41834\n",
      "[17]\tvalidation_0-mlogloss:0.41759\n",
      "[18]\tvalidation_0-mlogloss:0.40974\n",
      "[19]\tvalidation_0-mlogloss:0.41122\n",
      "[20]\tvalidation_0-mlogloss:0.41536\n",
      "[21]\tvalidation_0-mlogloss:0.41488\n",
      "[22]\tvalidation_0-mlogloss:0.41304\n",
      "[23]\tvalidation_0-mlogloss:0.41629\n",
      "[24]\tvalidation_0-mlogloss:0.42162\n",
      "[25]\tvalidation_0-mlogloss:0.42244\n",
      "[26]\tvalidation_0-mlogloss:0.42211\n",
      "[27]\tvalidation_0-mlogloss:0.41583\n",
      "[28]\tvalidation_0-mlogloss:0.41708\n",
      "[29]\tvalidation_0-mlogloss:0.41538\n",
      "[30]\tvalidation_0-mlogloss:0.42000\n",
      "[31]\tvalidation_0-mlogloss:0.42221\n",
      "[0]\tvalidation_0-mlogloss:0.86441\n",
      "[1]\tvalidation_0-mlogloss:0.72570\n",
      "[2]\tvalidation_0-mlogloss:0.61999\n",
      "[3]\tvalidation_0-mlogloss:0.55738\n",
      "[4]\tvalidation_0-mlogloss:0.50666\n",
      "[5]\tvalidation_0-mlogloss:0.48013\n",
      "[6]\tvalidation_0-mlogloss:0.45555\n",
      "[7]\tvalidation_0-mlogloss:0.43501\n",
      "[8]\tvalidation_0-mlogloss:0.42236\n",
      "[9]\tvalidation_0-mlogloss:0.41761\n",
      "[10]\tvalidation_0-mlogloss:0.40639\n",
      "[11]\tvalidation_0-mlogloss:0.41611\n",
      "[12]\tvalidation_0-mlogloss:0.42237\n",
      "[13]\tvalidation_0-mlogloss:0.42671\n",
      "[14]\tvalidation_0-mlogloss:0.42896\n",
      "[15]\tvalidation_0-mlogloss:0.42630\n",
      "[16]\tvalidation_0-mlogloss:0.43292\n",
      "[17]\tvalidation_0-mlogloss:0.43274\n",
      "[18]\tvalidation_0-mlogloss:0.43094\n",
      "[19]\tvalidation_0-mlogloss:0.43636\n",
      "[20]\tvalidation_0-mlogloss:0.43640\n",
      "[21]\tvalidation_0-mlogloss:0.43002\n",
      "[22]\tvalidation_0-mlogloss:0.43022\n",
      "[23]\tvalidation_0-mlogloss:0.43732\n",
      "[24]\tvalidation_0-mlogloss:0.43908\n",
      "[25]\tvalidation_0-mlogloss:0.43718\n",
      "[26]\tvalidation_0-mlogloss:0.44207\n",
      "[27]\tvalidation_0-mlogloss:0.44497\n",
      "[28]\tvalidation_0-mlogloss:0.44422\n",
      "[29]\tvalidation_0-mlogloss:0.44795\n",
      "[30]\tvalidation_0-mlogloss:0.45075\n",
      "[0]\tvalidation_0-mlogloss:0.96607\n",
      "[1]\tvalidation_0-mlogloss:0.87633\n",
      "[2]\tvalidation_0-mlogloss:0.81562\n",
      "[3]\tvalidation_0-mlogloss:0.76035\n",
      "[4]\tvalidation_0-mlogloss:0.69864\n",
      "[5]\tvalidation_0-mlogloss:0.67735\n",
      "[6]\tvalidation_0-mlogloss:0.64437\n",
      "[7]\tvalidation_0-mlogloss:0.63850\n",
      "[8]\tvalidation_0-mlogloss:0.61085\n",
      "[9]\tvalidation_0-mlogloss:0.60460\n",
      "[10]\tvalidation_0-mlogloss:0.60173\n",
      "[11]\tvalidation_0-mlogloss:0.59620\n",
      "[12]\tvalidation_0-mlogloss:0.57020\n",
      "[13]\tvalidation_0-mlogloss:0.54620\n",
      "[14]\tvalidation_0-mlogloss:0.54086\n",
      "[15]\tvalidation_0-mlogloss:0.52654\n",
      "[16]\tvalidation_0-mlogloss:0.52267\n",
      "[17]\tvalidation_0-mlogloss:0.52080\n",
      "[18]\tvalidation_0-mlogloss:0.52422\n",
      "[19]\tvalidation_0-mlogloss:0.51679\n",
      "[20]\tvalidation_0-mlogloss:0.51886\n",
      "[21]\tvalidation_0-mlogloss:0.52165\n",
      "[22]\tvalidation_0-mlogloss:0.53270\n",
      "[23]\tvalidation_0-mlogloss:0.52596\n",
      "[24]\tvalidation_0-mlogloss:0.53102\n",
      "[25]\tvalidation_0-mlogloss:0.53893\n",
      "[26]\tvalidation_0-mlogloss:0.54362\n",
      "[27]\tvalidation_0-mlogloss:0.53787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28]\tvalidation_0-mlogloss:0.53232\n",
      "[29]\tvalidation_0-mlogloss:0.53315\n",
      "[30]\tvalidation_0-mlogloss:0.52233\n",
      "[31]\tvalidation_0-mlogloss:0.52261\n",
      "[32]\tvalidation_0-mlogloss:0.53075\n",
      "[33]\tvalidation_0-mlogloss:0.53251\n",
      "[34]\tvalidation_0-mlogloss:0.52875\n",
      "[35]\tvalidation_0-mlogloss:0.52810\n",
      "[36]\tvalidation_0-mlogloss:0.54207\n",
      "[37]\tvalidation_0-mlogloss:0.54290\n",
      "[38]\tvalidation_0-mlogloss:0.53631\n",
      "[0]\tvalidation_0-mlogloss:0.89777\n",
      "[1]\tvalidation_0-mlogloss:0.76063\n",
      "[2]\tvalidation_0-mlogloss:0.66868\n",
      "[3]\tvalidation_0-mlogloss:0.60883\n",
      "[4]\tvalidation_0-mlogloss:0.55450\n",
      "[5]\tvalidation_0-mlogloss:0.52922\n",
      "[6]\tvalidation_0-mlogloss:0.50608\n",
      "[7]\tvalidation_0-mlogloss:0.48786\n",
      "[8]\tvalidation_0-mlogloss:0.47597\n",
      "[9]\tvalidation_0-mlogloss:0.46468\n",
      "[10]\tvalidation_0-mlogloss:0.44858\n",
      "[11]\tvalidation_0-mlogloss:0.44312\n",
      "[12]\tvalidation_0-mlogloss:0.44223\n",
      "[13]\tvalidation_0-mlogloss:0.44209\n",
      "[14]\tvalidation_0-mlogloss:0.43977\n",
      "[15]\tvalidation_0-mlogloss:0.43805\n",
      "[16]\tvalidation_0-mlogloss:0.43049\n",
      "[17]\tvalidation_0-mlogloss:0.42929\n",
      "[18]\tvalidation_0-mlogloss:0.42398\n",
      "[19]\tvalidation_0-mlogloss:0.41337\n",
      "[20]\tvalidation_0-mlogloss:0.40974\n",
      "[21]\tvalidation_0-mlogloss:0.40426\n",
      "[22]\tvalidation_0-mlogloss:0.40780\n",
      "[23]\tvalidation_0-mlogloss:0.40381\n",
      "[24]\tvalidation_0-mlogloss:0.40427\n",
      "[25]\tvalidation_0-mlogloss:0.40341\n",
      "[26]\tvalidation_0-mlogloss:0.40468\n",
      "[27]\tvalidation_0-mlogloss:0.40400\n",
      "[28]\tvalidation_0-mlogloss:0.40725\n",
      "[29]\tvalidation_0-mlogloss:0.39917\n",
      "[30]\tvalidation_0-mlogloss:0.40184\n",
      "[31]\tvalidation_0-mlogloss:0.40017\n",
      "[32]\tvalidation_0-mlogloss:0.40170\n",
      "[33]\tvalidation_0-mlogloss:0.40470\n",
      "[34]\tvalidation_0-mlogloss:0.40398\n",
      "[35]\tvalidation_0-mlogloss:0.40853\n",
      "[36]\tvalidation_0-mlogloss:0.41258\n",
      "[37]\tvalidation_0-mlogloss:0.41431\n",
      "[38]\tvalidation_0-mlogloss:0.41413\n",
      "[39]\tvalidation_0-mlogloss:0.40979\n",
      "[40]\tvalidation_0-mlogloss:0.41134\n",
      "[41]\tvalidation_0-mlogloss:0.41136\n",
      "[42]\tvalidation_0-mlogloss:0.41323\n",
      "[43]\tvalidation_0-mlogloss:0.41288\n",
      "[44]\tvalidation_0-mlogloss:0.41237\n",
      "[45]\tvalidation_0-mlogloss:0.41218\n",
      "[46]\tvalidation_0-mlogloss:0.41189\n",
      "[47]\tvalidation_0-mlogloss:0.41337\n",
      "[48]\tvalidation_0-mlogloss:0.41379\n",
      "[0]\tvalidation_0-mlogloss:0.87065\n",
      "[1]\tvalidation_0-mlogloss:0.73645\n",
      "[2]\tvalidation_0-mlogloss:0.64067\n",
      "[3]\tvalidation_0-mlogloss:0.59072\n",
      "[4]\tvalidation_0-mlogloss:0.54140\n",
      "[5]\tvalidation_0-mlogloss:0.53422\n",
      "[6]\tvalidation_0-mlogloss:0.52229\n",
      "[7]\tvalidation_0-mlogloss:0.51227\n",
      "[8]\tvalidation_0-mlogloss:0.50540\n",
      "[9]\tvalidation_0-mlogloss:0.48866\n",
      "[10]\tvalidation_0-mlogloss:0.48662\n",
      "[11]\tvalidation_0-mlogloss:0.48992\n",
      "[12]\tvalidation_0-mlogloss:0.47884\n",
      "[13]\tvalidation_0-mlogloss:0.47808\n",
      "[14]\tvalidation_0-mlogloss:0.46957\n",
      "[15]\tvalidation_0-mlogloss:0.46833\n",
      "[16]\tvalidation_0-mlogloss:0.46626\n",
      "[17]\tvalidation_0-mlogloss:0.47554\n",
      "[18]\tvalidation_0-mlogloss:0.47816\n",
      "[19]\tvalidation_0-mlogloss:0.48088\n",
      "[20]\tvalidation_0-mlogloss:0.48042\n",
      "[21]\tvalidation_0-mlogloss:0.48512\n",
      "[22]\tvalidation_0-mlogloss:0.47573\n",
      "[23]\tvalidation_0-mlogloss:0.47517\n",
      "[24]\tvalidation_0-mlogloss:0.47530\n",
      "[25]\tvalidation_0-mlogloss:0.48562\n",
      "[26]\tvalidation_0-mlogloss:0.48642\n",
      "[27]\tvalidation_0-mlogloss:0.48702\n",
      "[28]\tvalidation_0-mlogloss:0.49257\n",
      "[29]\tvalidation_0-mlogloss:0.49002\n",
      "[30]\tvalidation_0-mlogloss:0.49226\n",
      "[31]\tvalidation_0-mlogloss:0.48037\n",
      "[32]\tvalidation_0-mlogloss:0.48609\n",
      "[33]\tvalidation_0-mlogloss:0.48302\n",
      "[34]\tvalidation_0-mlogloss:0.48901\n",
      "[35]\tvalidation_0-mlogloss:0.48421\n",
      "[36]\tvalidation_0-mlogloss:0.49219\n",
      "[0]\tvalidation_0-mlogloss:0.94848\n",
      "[1]\tvalidation_0-mlogloss:0.86704\n",
      "[2]\tvalidation_0-mlogloss:0.81675\n",
      "[3]\tvalidation_0-mlogloss:0.77656\n",
      "[4]\tvalidation_0-mlogloss:0.76566\n",
      "[5]\tvalidation_0-mlogloss:0.75365\n",
      "[6]\tvalidation_0-mlogloss:0.72130\n",
      "[7]\tvalidation_0-mlogloss:0.70949\n",
      "[8]\tvalidation_0-mlogloss:0.70959\n",
      "[9]\tvalidation_0-mlogloss:0.68196\n",
      "[10]\tvalidation_0-mlogloss:0.67192\n",
      "[11]\tvalidation_0-mlogloss:0.68510\n",
      "[12]\tvalidation_0-mlogloss:0.67709\n",
      "[13]\tvalidation_0-mlogloss:0.65944\n",
      "[14]\tvalidation_0-mlogloss:0.65200\n",
      "[15]\tvalidation_0-mlogloss:0.64831\n",
      "[16]\tvalidation_0-mlogloss:0.63357\n",
      "[17]\tvalidation_0-mlogloss:0.62595\n",
      "[18]\tvalidation_0-mlogloss:0.62773\n",
      "[19]\tvalidation_0-mlogloss:0.63337\n",
      "[20]\tvalidation_0-mlogloss:0.63167\n",
      "[21]\tvalidation_0-mlogloss:0.62060\n",
      "[22]\tvalidation_0-mlogloss:0.62746\n",
      "[23]\tvalidation_0-mlogloss:0.62717\n",
      "[24]\tvalidation_0-mlogloss:0.62314\n",
      "[25]\tvalidation_0-mlogloss:0.62208\n",
      "[26]\tvalidation_0-mlogloss:0.62710\n",
      "[27]\tvalidation_0-mlogloss:0.63455\n",
      "[28]\tvalidation_0-mlogloss:0.63611\n",
      "[29]\tvalidation_0-mlogloss:0.63854\n",
      "[30]\tvalidation_0-mlogloss:0.63456\n",
      "[31]\tvalidation_0-mlogloss:0.63979\n",
      "[32]\tvalidation_0-mlogloss:0.64112\n",
      "[33]\tvalidation_0-mlogloss:0.63701\n",
      "[34]\tvalidation_0-mlogloss:0.63602\n",
      "[35]\tvalidation_0-mlogloss:0.63859\n",
      "[36]\tvalidation_0-mlogloss:0.63938\n",
      "[37]\tvalidation_0-mlogloss:0.64231\n",
      "[38]\tvalidation_0-mlogloss:0.64036\n",
      "[39]\tvalidation_0-mlogloss:0.64492\n",
      "[40]\tvalidation_0-mlogloss:0.65392\n",
      "[41]\tvalidation_0-mlogloss:0.65521\n",
      "[0]\tvalidation_0-mlogloss:0.80467\n",
      "[1]\tvalidation_0-mlogloss:0.64741\n",
      "[2]\tvalidation_0-mlogloss:0.53692\n",
      "[3]\tvalidation_0-mlogloss:0.46996\n",
      "[4]\tvalidation_0-mlogloss:0.43067\n",
      "[5]\tvalidation_0-mlogloss:0.40613\n",
      "[6]\tvalidation_0-mlogloss:0.38655\n",
      "[7]\tvalidation_0-mlogloss:0.37753\n",
      "[8]\tvalidation_0-mlogloss:0.38272\n",
      "[9]\tvalidation_0-mlogloss:0.38155\n",
      "[10]\tvalidation_0-mlogloss:0.37776\n",
      "[11]\tvalidation_0-mlogloss:0.38563\n",
      "[12]\tvalidation_0-mlogloss:0.38696\n",
      "[13]\tvalidation_0-mlogloss:0.39495\n",
      "[14]\tvalidation_0-mlogloss:0.39886\n",
      "[15]\tvalidation_0-mlogloss:0.39719\n",
      "[16]\tvalidation_0-mlogloss:0.40614\n",
      "[17]\tvalidation_0-mlogloss:0.41419\n",
      "[18]\tvalidation_0-mlogloss:0.41497\n",
      "[19]\tvalidation_0-mlogloss:0.41264\n",
      "[20]\tvalidation_0-mlogloss:0.41709\n",
      "[21]\tvalidation_0-mlogloss:0.42092\n",
      "[22]\tvalidation_0-mlogloss:0.42637\n",
      "[23]\tvalidation_0-mlogloss:0.42376\n",
      "[24]\tvalidation_0-mlogloss:0.42730\n",
      "[25]\tvalidation_0-mlogloss:0.43236\n",
      "[26]\tvalidation_0-mlogloss:0.43381\n",
      "[0]\tvalidation_0-mlogloss:0.83703\n",
      "[1]\tvalidation_0-mlogloss:0.68170\n",
      "[2]\tvalidation_0-mlogloss:0.57088\n",
      "[3]\tvalidation_0-mlogloss:0.49280\n",
      "[4]\tvalidation_0-mlogloss:0.43180\n",
      "[5]\tvalidation_0-mlogloss:0.38984\n",
      "[6]\tvalidation_0-mlogloss:0.35718\n",
      "[7]\tvalidation_0-mlogloss:0.34480\n",
      "[8]\tvalidation_0-mlogloss:0.33814\n",
      "[9]\tvalidation_0-mlogloss:0.33797\n",
      "[10]\tvalidation_0-mlogloss:0.33962\n",
      "[11]\tvalidation_0-mlogloss:0.34147\n",
      "[12]\tvalidation_0-mlogloss:0.33518\n",
      "[13]\tvalidation_0-mlogloss:0.34119\n",
      "[14]\tvalidation_0-mlogloss:0.34197\n",
      "[15]\tvalidation_0-mlogloss:0.34993\n",
      "[16]\tvalidation_0-mlogloss:0.35591\n",
      "[17]\tvalidation_0-mlogloss:0.36314\n",
      "[18]\tvalidation_0-mlogloss:0.36228\n",
      "[19]\tvalidation_0-mlogloss:0.37257\n",
      "[20]\tvalidation_0-mlogloss:0.37557\n",
      "[21]\tvalidation_0-mlogloss:0.38208\n",
      "[22]\tvalidation_0-mlogloss:0.39020\n",
      "[23]\tvalidation_0-mlogloss:0.39179\n",
      "[24]\tvalidation_0-mlogloss:0.39466\n",
      "[25]\tvalidation_0-mlogloss:0.39717\n",
      "[26]\tvalidation_0-mlogloss:0.40268\n",
      "[27]\tvalidation_0-mlogloss:0.41054\n",
      "[28]\tvalidation_0-mlogloss:0.41697\n",
      "[29]\tvalidation_0-mlogloss:0.42174\n",
      "[30]\tvalidation_0-mlogloss:0.42674\n",
      "[31]\tvalidation_0-mlogloss:0.43137\n",
      "[32]\tvalidation_0-mlogloss:0.43567\n",
      "[0]\tvalidation_0-mlogloss:0.94990\n",
      "[1]\tvalidation_0-mlogloss:0.86213\n",
      "[2]\tvalidation_0-mlogloss:0.81082\n",
      "[3]\tvalidation_0-mlogloss:0.76821\n",
      "[4]\tvalidation_0-mlogloss:0.73253\n",
      "[5]\tvalidation_0-mlogloss:0.67870\n",
      "[6]\tvalidation_0-mlogloss:0.65253\n",
      "[7]\tvalidation_0-mlogloss:0.63008\n",
      "[8]\tvalidation_0-mlogloss:0.62652\n",
      "[9]\tvalidation_0-mlogloss:0.61296\n",
      "[10]\tvalidation_0-mlogloss:0.62892\n",
      "[11]\tvalidation_0-mlogloss:0.59668\n",
      "[12]\tvalidation_0-mlogloss:0.58734\n",
      "[13]\tvalidation_0-mlogloss:0.58406\n",
      "[14]\tvalidation_0-mlogloss:0.58588\n",
      "[15]\tvalidation_0-mlogloss:0.58971\n",
      "[16]\tvalidation_0-mlogloss:0.57237\n",
      "[17]\tvalidation_0-mlogloss:0.57579\n",
      "[18]\tvalidation_0-mlogloss:0.57353\n",
      "[19]\tvalidation_0-mlogloss:0.56524\n",
      "[20]\tvalidation_0-mlogloss:0.56376\n",
      "[21]\tvalidation_0-mlogloss:0.55011\n",
      "[22]\tvalidation_0-mlogloss:0.54979\n",
      "[23]\tvalidation_0-mlogloss:0.54750\n",
      "[24]\tvalidation_0-mlogloss:0.53893\n",
      "[25]\tvalidation_0-mlogloss:0.53441\n",
      "[26]\tvalidation_0-mlogloss:0.54016\n",
      "[27]\tvalidation_0-mlogloss:0.55027\n",
      "[28]\tvalidation_0-mlogloss:0.53390\n",
      "[29]\tvalidation_0-mlogloss:0.53624\n",
      "[30]\tvalidation_0-mlogloss:0.53058\n",
      "[31]\tvalidation_0-mlogloss:0.53951\n",
      "[32]\tvalidation_0-mlogloss:0.54594\n",
      "[33]\tvalidation_0-mlogloss:0.54796\n",
      "[34]\tvalidation_0-mlogloss:0.55038\n",
      "[35]\tvalidation_0-mlogloss:0.55006\n",
      "[36]\tvalidation_0-mlogloss:0.55290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37]\tvalidation_0-mlogloss:0.55547\n",
      "[38]\tvalidation_0-mlogloss:0.56283\n",
      "[39]\tvalidation_0-mlogloss:0.55983\n",
      "[40]\tvalidation_0-mlogloss:0.56468\n",
      "[41]\tvalidation_0-mlogloss:0.55980\n",
      "[42]\tvalidation_0-mlogloss:0.56168\n",
      "[43]\tvalidation_0-mlogloss:0.56228\n",
      "[44]\tvalidation_0-mlogloss:0.56161\n",
      "[45]\tvalidation_0-mlogloss:0.56492\n",
      "[46]\tvalidation_0-mlogloss:0.56491\n",
      "[47]\tvalidation_0-mlogloss:0.56115\n",
      "[48]\tvalidation_0-mlogloss:0.56128\n",
      "[49]\tvalidation_0-mlogloss:0.56020\n",
      "[50]\tvalidation_0-mlogloss:0.55857\n",
      "[0]\tvalidation_0-mlogloss:0.84658\n",
      "[1]\tvalidation_0-mlogloss:0.67239\n",
      "[2]\tvalidation_0-mlogloss:0.58583\n",
      "[3]\tvalidation_0-mlogloss:0.51811\n",
      "[4]\tvalidation_0-mlogloss:0.45745\n",
      "[5]\tvalidation_0-mlogloss:0.42760\n",
      "[6]\tvalidation_0-mlogloss:0.40417\n",
      "[7]\tvalidation_0-mlogloss:0.38103\n",
      "[8]\tvalidation_0-mlogloss:0.37547\n",
      "[9]\tvalidation_0-mlogloss:0.37695\n",
      "[10]\tvalidation_0-mlogloss:0.37481\n",
      "[11]\tvalidation_0-mlogloss:0.37520\n",
      "[12]\tvalidation_0-mlogloss:0.36853\n",
      "[13]\tvalidation_0-mlogloss:0.37304\n",
      "[14]\tvalidation_0-mlogloss:0.38209\n",
      "[15]\tvalidation_0-mlogloss:0.38058\n",
      "[16]\tvalidation_0-mlogloss:0.38885\n",
      "[17]\tvalidation_0-mlogloss:0.39127\n",
      "[18]\tvalidation_0-mlogloss:0.38939\n",
      "[19]\tvalidation_0-mlogloss:0.38449\n",
      "[20]\tvalidation_0-mlogloss:0.38321\n",
      "[21]\tvalidation_0-mlogloss:0.38060\n",
      "[22]\tvalidation_0-mlogloss:0.37571\n",
      "[23]\tvalidation_0-mlogloss:0.37420\n",
      "[24]\tvalidation_0-mlogloss:0.37823\n",
      "[25]\tvalidation_0-mlogloss:0.37917\n",
      "[26]\tvalidation_0-mlogloss:0.37900\n",
      "[27]\tvalidation_0-mlogloss:0.37806\n",
      "[28]\tvalidation_0-mlogloss:0.37915\n",
      "[29]\tvalidation_0-mlogloss:0.38282\n",
      "[30]\tvalidation_0-mlogloss:0.38546\n",
      "[31]\tvalidation_0-mlogloss:0.38324\n",
      "[0]\tvalidation_0-mlogloss:0.87094\n",
      "[1]\tvalidation_0-mlogloss:0.72219\n",
      "[2]\tvalidation_0-mlogloss:0.62048\n",
      "[3]\tvalidation_0-mlogloss:0.55034\n",
      "[4]\tvalidation_0-mlogloss:0.50326\n",
      "[5]\tvalidation_0-mlogloss:0.47324\n",
      "[6]\tvalidation_0-mlogloss:0.45940\n",
      "[7]\tvalidation_0-mlogloss:0.42737\n",
      "[8]\tvalidation_0-mlogloss:0.42547\n",
      "[9]\tvalidation_0-mlogloss:0.41993\n",
      "[10]\tvalidation_0-mlogloss:0.41119\n",
      "[11]\tvalidation_0-mlogloss:0.40603\n",
      "[12]\tvalidation_0-mlogloss:0.40227\n",
      "[13]\tvalidation_0-mlogloss:0.40418\n",
      "[14]\tvalidation_0-mlogloss:0.40760\n",
      "[15]\tvalidation_0-mlogloss:0.41435\n",
      "[16]\tvalidation_0-mlogloss:0.41758\n",
      "[17]\tvalidation_0-mlogloss:0.41742\n",
      "[18]\tvalidation_0-mlogloss:0.41827\n",
      "[19]\tvalidation_0-mlogloss:0.42033\n",
      "[20]\tvalidation_0-mlogloss:0.42777\n",
      "[21]\tvalidation_0-mlogloss:0.43199\n",
      "[22]\tvalidation_0-mlogloss:0.43733\n",
      "[23]\tvalidation_0-mlogloss:0.44189\n",
      "[24]\tvalidation_0-mlogloss:0.44446\n",
      "[25]\tvalidation_0-mlogloss:0.44678\n",
      "[26]\tvalidation_0-mlogloss:0.44520\n",
      "[27]\tvalidation_0-mlogloss:0.44759\n",
      "[28]\tvalidation_0-mlogloss:0.45247\n",
      "[29]\tvalidation_0-mlogloss:0.45430\n",
      "[30]\tvalidation_0-mlogloss:0.45186\n",
      "[31]\tvalidation_0-mlogloss:0.45503\n",
      "[32]\tvalidation_0-mlogloss:0.45761\n",
      "[0]\tvalidation_0-mlogloss:0.98133\n",
      "[1]\tvalidation_0-mlogloss:0.89579\n",
      "[2]\tvalidation_0-mlogloss:0.83965\n",
      "[3]\tvalidation_0-mlogloss:0.78161\n",
      "[4]\tvalidation_0-mlogloss:0.71780\n",
      "[5]\tvalidation_0-mlogloss:0.68843\n",
      "[6]\tvalidation_0-mlogloss:0.64250\n",
      "[7]\tvalidation_0-mlogloss:0.62635\n",
      "[8]\tvalidation_0-mlogloss:0.58934\n",
      "[9]\tvalidation_0-mlogloss:0.58883\n",
      "[10]\tvalidation_0-mlogloss:0.57689\n",
      "[11]\tvalidation_0-mlogloss:0.56698\n",
      "[12]\tvalidation_0-mlogloss:0.55174\n",
      "[13]\tvalidation_0-mlogloss:0.54690\n",
      "[14]\tvalidation_0-mlogloss:0.54459\n",
      "[15]\tvalidation_0-mlogloss:0.53241\n",
      "[16]\tvalidation_0-mlogloss:0.52255\n",
      "[17]\tvalidation_0-mlogloss:0.51314\n",
      "[18]\tvalidation_0-mlogloss:0.52653\n",
      "[19]\tvalidation_0-mlogloss:0.51462\n",
      "[20]\tvalidation_0-mlogloss:0.50683\n",
      "[21]\tvalidation_0-mlogloss:0.50428\n",
      "[22]\tvalidation_0-mlogloss:0.50315\n",
      "[23]\tvalidation_0-mlogloss:0.50496\n",
      "[24]\tvalidation_0-mlogloss:0.49875\n",
      "[25]\tvalidation_0-mlogloss:0.48852\n",
      "[26]\tvalidation_0-mlogloss:0.48481\n",
      "[27]\tvalidation_0-mlogloss:0.47613\n",
      "[28]\tvalidation_0-mlogloss:0.48571\n",
      "[29]\tvalidation_0-mlogloss:0.48233\n",
      "[30]\tvalidation_0-mlogloss:0.48672\n",
      "[31]\tvalidation_0-mlogloss:0.49127\n",
      "[32]\tvalidation_0-mlogloss:0.49226\n",
      "[33]\tvalidation_0-mlogloss:0.49322\n",
      "[34]\tvalidation_0-mlogloss:0.49759\n",
      "[35]\tvalidation_0-mlogloss:0.49542\n",
      "[36]\tvalidation_0-mlogloss:0.49437\n",
      "[37]\tvalidation_0-mlogloss:0.49606\n",
      "[38]\tvalidation_0-mlogloss:0.50265\n",
      "[39]\tvalidation_0-mlogloss:0.50352\n",
      "[40]\tvalidation_0-mlogloss:0.50290\n",
      "[41]\tvalidation_0-mlogloss:0.49915\n",
      "[42]\tvalidation_0-mlogloss:0.50150\n",
      "[43]\tvalidation_0-mlogloss:0.50428\n",
      "[44]\tvalidation_0-mlogloss:0.50499\n",
      "[45]\tvalidation_0-mlogloss:0.50393\n",
      "[46]\tvalidation_0-mlogloss:0.50302\n",
      "[0]\tvalidation_0-mlogloss:0.88723\n",
      "[1]\tvalidation_0-mlogloss:0.73456\n",
      "[2]\tvalidation_0-mlogloss:0.65055\n",
      "[3]\tvalidation_0-mlogloss:0.57124\n",
      "[4]\tvalidation_0-mlogloss:0.52171\n",
      "[5]\tvalidation_0-mlogloss:0.49343\n",
      "[6]\tvalidation_0-mlogloss:0.47965\n",
      "[7]\tvalidation_0-mlogloss:0.45868\n",
      "[8]\tvalidation_0-mlogloss:0.44672\n",
      "[9]\tvalidation_0-mlogloss:0.44565\n",
      "[10]\tvalidation_0-mlogloss:0.42892\n",
      "[11]\tvalidation_0-mlogloss:0.42348\n",
      "[12]\tvalidation_0-mlogloss:0.42571\n",
      "[13]\tvalidation_0-mlogloss:0.42543\n",
      "[14]\tvalidation_0-mlogloss:0.42022\n",
      "[15]\tvalidation_0-mlogloss:0.41582\n",
      "[16]\tvalidation_0-mlogloss:0.41508\n",
      "[17]\tvalidation_0-mlogloss:0.40950\n",
      "[18]\tvalidation_0-mlogloss:0.40174\n",
      "[19]\tvalidation_0-mlogloss:0.39792\n",
      "[20]\tvalidation_0-mlogloss:0.40095\n",
      "[21]\tvalidation_0-mlogloss:0.39218\n",
      "[22]\tvalidation_0-mlogloss:0.39163\n",
      "[23]\tvalidation_0-mlogloss:0.39322\n",
      "[24]\tvalidation_0-mlogloss:0.39173\n",
      "[25]\tvalidation_0-mlogloss:0.39606\n",
      "[26]\tvalidation_0-mlogloss:0.39944\n",
      "[27]\tvalidation_0-mlogloss:0.39758\n",
      "[28]\tvalidation_0-mlogloss:0.39999\n",
      "[29]\tvalidation_0-mlogloss:0.40259\n",
      "[30]\tvalidation_0-mlogloss:0.39713\n",
      "[31]\tvalidation_0-mlogloss:0.39827\n",
      "[32]\tvalidation_0-mlogloss:0.39852\n",
      "[33]\tvalidation_0-mlogloss:0.40146\n",
      "[34]\tvalidation_0-mlogloss:0.40501\n",
      "[35]\tvalidation_0-mlogloss:0.40563\n",
      "[36]\tvalidation_0-mlogloss:0.40733\n",
      "[37]\tvalidation_0-mlogloss:0.40811\n",
      "[38]\tvalidation_0-mlogloss:0.40648\n",
      "[39]\tvalidation_0-mlogloss:0.40665\n",
      "[40]\tvalidation_0-mlogloss:0.40858\n",
      "[41]\tvalidation_0-mlogloss:0.41001\n",
      "[42]\tvalidation_0-mlogloss:0.40978\n",
      "[0]\tvalidation_0-mlogloss:0.87475\n",
      "[1]\tvalidation_0-mlogloss:0.73320\n",
      "[2]\tvalidation_0-mlogloss:0.64685\n",
      "[3]\tvalidation_0-mlogloss:0.59198\n",
      "[4]\tvalidation_0-mlogloss:0.53897\n",
      "[5]\tvalidation_0-mlogloss:0.52792\n",
      "[6]\tvalidation_0-mlogloss:0.50018\n",
      "[7]\tvalidation_0-mlogloss:0.48808\n",
      "[8]\tvalidation_0-mlogloss:0.48572\n",
      "[9]\tvalidation_0-mlogloss:0.47159\n",
      "[10]\tvalidation_0-mlogloss:0.46823\n",
      "[11]\tvalidation_0-mlogloss:0.46032\n",
      "[12]\tvalidation_0-mlogloss:0.46583\n",
      "[13]\tvalidation_0-mlogloss:0.45809\n",
      "[14]\tvalidation_0-mlogloss:0.45611\n",
      "[15]\tvalidation_0-mlogloss:0.46440\n",
      "[16]\tvalidation_0-mlogloss:0.46032\n",
      "[17]\tvalidation_0-mlogloss:0.46550\n",
      "[18]\tvalidation_0-mlogloss:0.46869\n",
      "[19]\tvalidation_0-mlogloss:0.47409\n",
      "[20]\tvalidation_0-mlogloss:0.47013\n",
      "[21]\tvalidation_0-mlogloss:0.47656\n",
      "[22]\tvalidation_0-mlogloss:0.47460\n",
      "[23]\tvalidation_0-mlogloss:0.46990\n",
      "[24]\tvalidation_0-mlogloss:0.47426\n",
      "[25]\tvalidation_0-mlogloss:0.48003\n",
      "[26]\tvalidation_0-mlogloss:0.48398\n",
      "[27]\tvalidation_0-mlogloss:0.48119\n",
      "[28]\tvalidation_0-mlogloss:0.48693\n",
      "[29]\tvalidation_0-mlogloss:0.48798\n",
      "[30]\tvalidation_0-mlogloss:0.48446\n",
      "[31]\tvalidation_0-mlogloss:0.47757\n",
      "[32]\tvalidation_0-mlogloss:0.48563\n",
      "[33]\tvalidation_0-mlogloss:0.47962\n",
      "[0]\tvalidation_0-mlogloss:0.81611\n",
      "[1]\tvalidation_0-mlogloss:0.64618\n",
      "[2]\tvalidation_0-mlogloss:0.51240\n",
      "[3]\tvalidation_0-mlogloss:0.43247\n",
      "[4]\tvalidation_0-mlogloss:0.36894\n",
      "[5]\tvalidation_0-mlogloss:0.31966\n",
      "[6]\tvalidation_0-mlogloss:0.26877\n",
      "[7]\tvalidation_0-mlogloss:0.23921\n",
      "[8]\tvalidation_0-mlogloss:0.20687\n",
      "[9]\tvalidation_0-mlogloss:0.19259\n",
      "[10]\tvalidation_0-mlogloss:0.17428\n",
      "[11]\tvalidation_0-mlogloss:0.16395\n",
      "[12]\tvalidation_0-mlogloss:0.13913\n",
      "[13]\tvalidation_0-mlogloss:0.12472\n",
      "[14]\tvalidation_0-mlogloss:0.11225\n",
      "[15]\tvalidation_0-mlogloss:0.10204\n",
      "[16]\tvalidation_0-mlogloss:0.09650\n",
      "[17]\tvalidation_0-mlogloss:0.09020\n",
      "[18]\tvalidation_0-mlogloss:0.08469\n",
      "[19]\tvalidation_0-mlogloss:0.07714\n",
      "[20]\tvalidation_0-mlogloss:0.07165\n",
      "[21]\tvalidation_0-mlogloss:0.06712\n",
      "[22]\tvalidation_0-mlogloss:0.06387\n",
      "[23]\tvalidation_0-mlogloss:0.05897\n",
      "[24]\tvalidation_0-mlogloss:0.05707\n",
      "[25]\tvalidation_0-mlogloss:0.05443\n",
      "[26]\tvalidation_0-mlogloss:0.05279\n",
      "[27]\tvalidation_0-mlogloss:0.04979\n",
      "[28]\tvalidation_0-mlogloss:0.04894\n",
      "[29]\tvalidation_0-mlogloss:0.04682\n",
      "[30]\tvalidation_0-mlogloss:0.04531\n",
      "[31]\tvalidation_0-mlogloss:0.04527\n",
      "[32]\tvalidation_0-mlogloss:0.04332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33]\tvalidation_0-mlogloss:0.04302\n",
      "[34]\tvalidation_0-mlogloss:0.04144\n",
      "[35]\tvalidation_0-mlogloss:0.04025\n",
      "[36]\tvalidation_0-mlogloss:0.03941\n",
      "[37]\tvalidation_0-mlogloss:0.03851\n",
      "[38]\tvalidation_0-mlogloss:0.03717\n",
      "[39]\tvalidation_0-mlogloss:0.03742\n",
      "[40]\tvalidation_0-mlogloss:0.03671\n",
      "[41]\tvalidation_0-mlogloss:0.03590\n",
      "[42]\tvalidation_0-mlogloss:0.03564\n",
      "[43]\tvalidation_0-mlogloss:0.03554\n",
      "[44]\tvalidation_0-mlogloss:0.03430\n",
      "[45]\tvalidation_0-mlogloss:0.03389\n",
      "[46]\tvalidation_0-mlogloss:0.03307\n",
      "[47]\tvalidation_0-mlogloss:0.03239\n",
      "[48]\tvalidation_0-mlogloss:0.03231\n",
      "[49]\tvalidation_0-mlogloss:0.03147\n",
      "[50]\tvalidation_0-mlogloss:0.03135\n",
      "[51]\tvalidation_0-mlogloss:0.03054\n",
      "[52]\tvalidation_0-mlogloss:0.03072\n",
      "[53]\tvalidation_0-mlogloss:0.03039\n",
      "[54]\tvalidation_0-mlogloss:0.03011\n",
      "[55]\tvalidation_0-mlogloss:0.02979\n",
      "[56]\tvalidation_0-mlogloss:0.02947\n",
      "[57]\tvalidation_0-mlogloss:0.02919\n",
      "[58]\tvalidation_0-mlogloss:0.02880\n",
      "[59]\tvalidation_0-mlogloss:0.02841\n",
      "[60]\tvalidation_0-mlogloss:0.02806\n",
      "[61]\tvalidation_0-mlogloss:0.02773\n",
      "[62]\tvalidation_0-mlogloss:0.02756\n",
      "[63]\tvalidation_0-mlogloss:0.02719\n",
      "[64]\tvalidation_0-mlogloss:0.02711\n",
      "[65]\tvalidation_0-mlogloss:0.02673\n",
      "[66]\tvalidation_0-mlogloss:0.02653\n",
      "[67]\tvalidation_0-mlogloss:0.02654\n",
      "[68]\tvalidation_0-mlogloss:0.02640\n",
      "[69]\tvalidation_0-mlogloss:0.02607\n",
      "[70]\tvalidation_0-mlogloss:0.02586\n",
      "[71]\tvalidation_0-mlogloss:0.02543\n",
      "[72]\tvalidation_0-mlogloss:0.02533\n",
      "[73]\tvalidation_0-mlogloss:0.02526\n",
      "[74]\tvalidation_0-mlogloss:0.02536\n",
      "[75]\tvalidation_0-mlogloss:0.02518\n",
      "[76]\tvalidation_0-mlogloss:0.02511\n",
      "[77]\tvalidation_0-mlogloss:0.02503\n",
      "[78]\tvalidation_0-mlogloss:0.02483\n",
      "[79]\tvalidation_0-mlogloss:0.02461\n",
      "[80]\tvalidation_0-mlogloss:0.02447\n",
      "[81]\tvalidation_0-mlogloss:0.02452\n",
      "[82]\tvalidation_0-mlogloss:0.02434\n",
      "[83]\tvalidation_0-mlogloss:0.02416\n",
      "[84]\tvalidation_0-mlogloss:0.02399\n",
      "[85]\tvalidation_0-mlogloss:0.02384\n",
      "[86]\tvalidation_0-mlogloss:0.02377\n",
      "[87]\tvalidation_0-mlogloss:0.02375\n",
      "[88]\tvalidation_0-mlogloss:0.02362\n",
      "[89]\tvalidation_0-mlogloss:0.02346\n",
      "[90]\tvalidation_0-mlogloss:0.02349\n",
      "[91]\tvalidation_0-mlogloss:0.02334\n",
      "[92]\tvalidation_0-mlogloss:0.02326\n",
      "[93]\tvalidation_0-mlogloss:0.02311\n",
      "[94]\tvalidation_0-mlogloss:0.02308\n",
      "[95]\tvalidation_0-mlogloss:0.02305\n",
      "[96]\tvalidation_0-mlogloss:0.02300\n",
      "[97]\tvalidation_0-mlogloss:0.02286\n",
      "[98]\tvalidation_0-mlogloss:0.02292\n",
      "[99]\tvalidation_0-mlogloss:0.02278\n",
      "[100]\tvalidation_0-mlogloss:0.02270\n",
      "[101]\tvalidation_0-mlogloss:0.02257\n",
      "[102]\tvalidation_0-mlogloss:0.02254\n",
      "[103]\tvalidation_0-mlogloss:0.02246\n",
      "[104]\tvalidation_0-mlogloss:0.02250\n",
      "[105]\tvalidation_0-mlogloss:0.02238\n",
      "[106]\tvalidation_0-mlogloss:0.02226\n",
      "[107]\tvalidation_0-mlogloss:0.02218\n",
      "[108]\tvalidation_0-mlogloss:0.02214\n",
      "[109]\tvalidation_0-mlogloss:0.02201\n",
      "[110]\tvalidation_0-mlogloss:0.02205\n",
      "[111]\tvalidation_0-mlogloss:0.02201\n",
      "[112]\tvalidation_0-mlogloss:0.02199\n",
      "[113]\tvalidation_0-mlogloss:0.02186\n",
      "[114]\tvalidation_0-mlogloss:0.02188\n",
      "[115]\tvalidation_0-mlogloss:0.02186\n",
      "[116]\tvalidation_0-mlogloss:0.02185\n",
      "[117]\tvalidation_0-mlogloss:0.02177\n",
      "[118]\tvalidation_0-mlogloss:0.02177\n",
      "[119]\tvalidation_0-mlogloss:0.02165\n",
      "[120]\tvalidation_0-mlogloss:0.02176\n",
      "[121]\tvalidation_0-mlogloss:0.02171\n",
      "[122]\tvalidation_0-mlogloss:0.02175\n",
      "[123]\tvalidation_0-mlogloss:0.02160\n",
      "[124]\tvalidation_0-mlogloss:0.02156\n",
      "[125]\tvalidation_0-mlogloss:0.02144\n",
      "[126]\tvalidation_0-mlogloss:0.02133\n",
      "[127]\tvalidation_0-mlogloss:0.02127\n",
      "[128]\tvalidation_0-mlogloss:0.02131\n",
      "[129]\tvalidation_0-mlogloss:0.02125\n",
      "[130]\tvalidation_0-mlogloss:0.02118\n",
      "[131]\tvalidation_0-mlogloss:0.02110\n",
      "[132]\tvalidation_0-mlogloss:0.02109\n",
      "[133]\tvalidation_0-mlogloss:0.02105\n",
      "[134]\tvalidation_0-mlogloss:0.02105\n",
      "[135]\tvalidation_0-mlogloss:0.02099\n",
      "[136]\tvalidation_0-mlogloss:0.02111\n",
      "[137]\tvalidation_0-mlogloss:0.02099\n",
      "[138]\tvalidation_0-mlogloss:0.02098\n",
      "[139]\tvalidation_0-mlogloss:0.02088\n",
      "[140]\tvalidation_0-mlogloss:0.02085\n",
      "[141]\tvalidation_0-mlogloss:0.02077\n",
      "[142]\tvalidation_0-mlogloss:0.02075\n",
      "[143]\tvalidation_0-mlogloss:0.02071\n",
      "[144]\tvalidation_0-mlogloss:0.02065\n",
      "[145]\tvalidation_0-mlogloss:0.02063\n",
      "[146]\tvalidation_0-mlogloss:0.02063\n",
      "[147]\tvalidation_0-mlogloss:0.02052\n",
      "[148]\tvalidation_0-mlogloss:0.02055\n",
      "[149]\tvalidation_0-mlogloss:0.02059\n",
      "[150]\tvalidation_0-mlogloss:0.02049\n",
      "[151]\tvalidation_0-mlogloss:0.02042\n",
      "[152]\tvalidation_0-mlogloss:0.02040\n",
      "[153]\tvalidation_0-mlogloss:0.02031\n",
      "[154]\tvalidation_0-mlogloss:0.02032\n",
      "[155]\tvalidation_0-mlogloss:0.02031\n",
      "[156]\tvalidation_0-mlogloss:0.02030\n",
      "[157]\tvalidation_0-mlogloss:0.02026\n",
      "[158]\tvalidation_0-mlogloss:0.02026\n",
      "[159]\tvalidation_0-mlogloss:0.02016\n",
      "[160]\tvalidation_0-mlogloss:0.02026\n",
      "[161]\tvalidation_0-mlogloss:0.02020\n",
      "[162]\tvalidation_0-mlogloss:0.02022\n",
      "[163]\tvalidation_0-mlogloss:0.02014\n",
      "[164]\tvalidation_0-mlogloss:0.02004\n",
      "[165]\tvalidation_0-mlogloss:0.01999\n",
      "[166]\tvalidation_0-mlogloss:0.01998\n",
      "[167]\tvalidation_0-mlogloss:0.01996\n",
      "[168]\tvalidation_0-mlogloss:0.01990\n",
      "[169]\tvalidation_0-mlogloss:0.01994\n",
      "[170]\tvalidation_0-mlogloss:0.01987\n",
      "[171]\tvalidation_0-mlogloss:0.01981\n",
      "[172]\tvalidation_0-mlogloss:0.01990\n",
      "[173]\tvalidation_0-mlogloss:0.01985\n",
      "[174]\tvalidation_0-mlogloss:0.01983\n",
      "[175]\tvalidation_0-mlogloss:0.01982\n",
      "[176]\tvalidation_0-mlogloss:0.01980\n",
      "[177]\tvalidation_0-mlogloss:0.01971\n",
      "[178]\tvalidation_0-mlogloss:0.01970\n",
      "[179]\tvalidation_0-mlogloss:0.01964\n",
      "[180]\tvalidation_0-mlogloss:0.01967\n",
      "[181]\tvalidation_0-mlogloss:0.01966\n",
      "[182]\tvalidation_0-mlogloss:0.01962\n",
      "[183]\tvalidation_0-mlogloss:0.01966\n",
      "[184]\tvalidation_0-mlogloss:0.01964\n",
      "[185]\tvalidation_0-mlogloss:0.01959\n",
      "[186]\tvalidation_0-mlogloss:0.01951\n",
      "[187]\tvalidation_0-mlogloss:0.01945\n",
      "[188]\tvalidation_0-mlogloss:0.01946\n",
      "[189]\tvalidation_0-mlogloss:0.01937\n",
      "[190]\tvalidation_0-mlogloss:0.01935\n",
      "[191]\tvalidation_0-mlogloss:0.01934\n",
      "[192]\tvalidation_0-mlogloss:0.01934\n",
      "[193]\tvalidation_0-mlogloss:0.01929\n",
      "[194]\tvalidation_0-mlogloss:0.01928\n",
      "[195]\tvalidation_0-mlogloss:0.01922\n",
      "[196]\tvalidation_0-mlogloss:0.01926\n",
      "[197]\tvalidation_0-mlogloss:0.01920\n",
      "[198]\tvalidation_0-mlogloss:0.01915\n",
      "[199]\tvalidation_0-mlogloss:0.01911\n",
      "{'colsample_bytree': 1, 'max_depth': 6, 'min_child_weight': 3}\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgb_model = XGBClassifier(n_estimators=200)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_x, train_y, \n",
    "                                                    test_size=0.1, \n",
    "                                                    stratify=train_y, \n",
    "                                                    random_state=37)\n",
    "\n",
    "# 후보 파라미터 선정\n",
    "params = {'max_depth':[6], 'min_child_weight':[1,3,5], 'colsample_bytree':[0.75,1]}\n",
    "          #'learning_rate' :[0.01, 0.02, 0.03, 0.035]\n",
    "\n",
    "# gridsearchcv 객체 정보 입력(어떤 모델, 파라미터 후보, 교차검증 몇 번)\n",
    "gridcv = GridSearchCV(xgb_model, param_grid=params, cv=3)\n",
    "\n",
    "# 파라미터 튜닝 시작\n",
    "gridcv.fit(train_x, train_y, early_stopping_rounds=20, eval_metric='mlogloss', eval_set=[(X_val, y_val)])\n",
    "\n",
    "#튜닝된 파라미터 출력\n",
    "print(gridcv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b695dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1차적으로 튜닝된 파라미터를 가지고 객체 생성\n",
    "xgb_model = XGBClassifier(n_estimators=1000, learning_rate=0.02, max_depth=7, min_child_weight=1, colsample_bytree=0.75, reg_alpha=0.03)\n",
    "\n",
    "# 학습\n",
    "xgb_model.fit(X_train, y_train, early_stopping_rounds=200, eval_metric='mlogloss', eval_set=[(X_val, y_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dabbaee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c981d35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d17671e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82c8815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "164ed437",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"early_stopping\", \"eval_set\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-mlogloss:1.05972\teval-mlogloss:1.07173\n",
      "[1]\ttrain-mlogloss:1.02242\teval-mlogloss:1.04669\n",
      "[2]\ttrain-mlogloss:0.98684\teval-mlogloss:1.02306\n",
      "[3]\ttrain-mlogloss:0.95344\teval-mlogloss:1.00009\n",
      "[4]\ttrain-mlogloss:0.92220\teval-mlogloss:0.97894\n",
      "[5]\ttrain-mlogloss:0.89228\teval-mlogloss:0.95901\n",
      "[6]\ttrain-mlogloss:0.86367\teval-mlogloss:0.94035\n",
      "[7]\ttrain-mlogloss:0.83676\teval-mlogloss:0.92235\n",
      "[8]\ttrain-mlogloss:0.81038\teval-mlogloss:0.90631\n",
      "[9]\ttrain-mlogloss:0.78413\teval-mlogloss:0.89372\n",
      "[10]\ttrain-mlogloss:0.76006\teval-mlogloss:0.87879\n",
      "[11]\ttrain-mlogloss:0.73582\teval-mlogloss:0.86668\n",
      "[12]\ttrain-mlogloss:0.71379\teval-mlogloss:0.85385\n",
      "[13]\ttrain-mlogloss:0.69135\teval-mlogloss:0.84564\n",
      "[14]\ttrain-mlogloss:0.67105\teval-mlogloss:0.83448\n",
      "[15]\ttrain-mlogloss:0.65003\teval-mlogloss:0.82630\n",
      "[16]\ttrain-mlogloss:0.63039\teval-mlogloss:0.82047\n",
      "[17]\ttrain-mlogloss:0.61122\teval-mlogloss:0.81387\n",
      "[18]\ttrain-mlogloss:0.59278\teval-mlogloss:0.80783\n",
      "[19]\ttrain-mlogloss:0.57442\teval-mlogloss:0.80229\n",
      "[20]\ttrain-mlogloss:0.55721\teval-mlogloss:0.79641\n",
      "[21]\ttrain-mlogloss:0.54034\teval-mlogloss:0.79140\n",
      "[22]\ttrain-mlogloss:0.52451\teval-mlogloss:0.78528\n",
      "[23]\ttrain-mlogloss:0.50930\teval-mlogloss:0.77924\n",
      "[24]\ttrain-mlogloss:0.49435\teval-mlogloss:0.77364\n",
      "[25]\ttrain-mlogloss:0.47982\teval-mlogloss:0.76876\n",
      "[26]\ttrain-mlogloss:0.46617\teval-mlogloss:0.76494\n",
      "[27]\ttrain-mlogloss:0.45299\teval-mlogloss:0.76188\n",
      "[28]\ttrain-mlogloss:0.44018\teval-mlogloss:0.75789\n",
      "[29]\ttrain-mlogloss:0.42759\teval-mlogloss:0.75243\n",
      "[30]\ttrain-mlogloss:0.41569\teval-mlogloss:0.74947\n",
      "[31]\ttrain-mlogloss:0.40420\teval-mlogloss:0.74728\n",
      "[32]\ttrain-mlogloss:0.39329\teval-mlogloss:0.74493\n",
      "[33]\ttrain-mlogloss:0.38183\teval-mlogloss:0.74289\n",
      "[34]\ttrain-mlogloss:0.37158\teval-mlogloss:0.74151\n",
      "[35]\ttrain-mlogloss:0.36168\teval-mlogloss:0.74140\n",
      "[36]\ttrain-mlogloss:0.35132\teval-mlogloss:0.73779\n",
      "[37]\ttrain-mlogloss:0.34193\teval-mlogloss:0.73660\n",
      "[38]\ttrain-mlogloss:0.33218\teval-mlogloss:0.73567\n",
      "[39]\ttrain-mlogloss:0.32369\teval-mlogloss:0.73352\n",
      "[40]\ttrain-mlogloss:0.31471\teval-mlogloss:0.73206\n",
      "[41]\ttrain-mlogloss:0.30613\teval-mlogloss:0.73231\n",
      "[42]\ttrain-mlogloss:0.29751\teval-mlogloss:0.73179\n",
      "[43]\ttrain-mlogloss:0.28928\teval-mlogloss:0.73022\n",
      "[44]\ttrain-mlogloss:0.28151\teval-mlogloss:0.72968\n",
      "[45]\ttrain-mlogloss:0.27371\teval-mlogloss:0.73091\n",
      "[46]\ttrain-mlogloss:0.26645\teval-mlogloss:0.73113\n",
      "[47]\ttrain-mlogloss:0.25949\teval-mlogloss:0.73096\n",
      "[48]\ttrain-mlogloss:0.25270\teval-mlogloss:0.73086\n",
      "[49]\ttrain-mlogloss:0.24611\teval-mlogloss:0.73054\n",
      "[50]\ttrain-mlogloss:0.23971\teval-mlogloss:0.73128\n",
      "[51]\ttrain-mlogloss:0.23397\teval-mlogloss:0.73139\n",
      "[52]\ttrain-mlogloss:0.22802\teval-mlogloss:0.73051\n",
      "[53]\ttrain-mlogloss:0.22224\teval-mlogloss:0.73079\n",
      "[54]\ttrain-mlogloss:0.21653\teval-mlogloss:0.73179\n",
      "[55]\ttrain-mlogloss:0.21098\teval-mlogloss:0.73177\n",
      "[56]\ttrain-mlogloss:0.20564\teval-mlogloss:0.73447\n",
      "[57]\ttrain-mlogloss:0.20057\teval-mlogloss:0.73638\n",
      "[58]\ttrain-mlogloss:0.19562\teval-mlogloss:0.73721\n",
      "[59]\ttrain-mlogloss:0.19088\teval-mlogloss:0.73972\n",
      "[60]\ttrain-mlogloss:0.18619\teval-mlogloss:0.74048\n",
      "[61]\ttrain-mlogloss:0.18171\teval-mlogloss:0.74230\n",
      "[62]\ttrain-mlogloss:0.17739\teval-mlogloss:0.74401\n",
      "[63]\ttrain-mlogloss:0.17314\teval-mlogloss:0.74439\n",
      "[64]\ttrain-mlogloss:0.16908\teval-mlogloss:0.74592\n",
      "[65]\ttrain-mlogloss:0.16545\teval-mlogloss:0.74707\n",
      "[66]\ttrain-mlogloss:0.16145\teval-mlogloss:0.74617\n",
      "[67]\ttrain-mlogloss:0.15777\teval-mlogloss:0.74788\n",
      "[68]\ttrain-mlogloss:0.15416\teval-mlogloss:0.74887\n",
      "[69]\ttrain-mlogloss:0.15049\teval-mlogloss:0.74923\n",
      "[70]\ttrain-mlogloss:0.14703\teval-mlogloss:0.74925\n",
      "[71]\ttrain-mlogloss:0.14373\teval-mlogloss:0.75220\n",
      "[72]\ttrain-mlogloss:0.14046\teval-mlogloss:0.75304\n",
      "[73]\ttrain-mlogloss:0.13723\teval-mlogloss:0.75458\n",
      "[74]\ttrain-mlogloss:0.13428\teval-mlogloss:0.75664\n",
      "[75]\ttrain-mlogloss:0.13139\teval-mlogloss:0.75707\n",
      "[76]\ttrain-mlogloss:0.12846\teval-mlogloss:0.75717\n",
      "[77]\ttrain-mlogloss:0.12580\teval-mlogloss:0.76036\n",
      "[78]\ttrain-mlogloss:0.12301\teval-mlogloss:0.76009\n",
      "[79]\ttrain-mlogloss:0.12038\teval-mlogloss:0.76246\n",
      "[80]\ttrain-mlogloss:0.11776\teval-mlogloss:0.76581\n",
      "[81]\ttrain-mlogloss:0.11525\teval-mlogloss:0.76819\n",
      "[82]\ttrain-mlogloss:0.11302\teval-mlogloss:0.77063\n",
      "[83]\ttrain-mlogloss:0.11068\teval-mlogloss:0.77283\n",
      "[84]\ttrain-mlogloss:0.10845\teval-mlogloss:0.77402\n",
      "[85]\ttrain-mlogloss:0.10632\teval-mlogloss:0.77598\n",
      "[86]\ttrain-mlogloss:0.10424\teval-mlogloss:0.77802\n",
      "[87]\ttrain-mlogloss:0.10219\teval-mlogloss:0.77863\n",
      "[88]\ttrain-mlogloss:0.10027\teval-mlogloss:0.78190\n",
      "[89]\ttrain-mlogloss:0.09828\teval-mlogloss:0.78243\n",
      "[90]\ttrain-mlogloss:0.09635\teval-mlogloss:0.78434\n",
      "[91]\ttrain-mlogloss:0.09455\teval-mlogloss:0.78345\n",
      "[92]\ttrain-mlogloss:0.09274\teval-mlogloss:0.78682\n",
      "[93]\ttrain-mlogloss:0.09101\teval-mlogloss:0.78829\n",
      "[94]\ttrain-mlogloss:0.08931\teval-mlogloss:0.78917\n",
      "[95]\ttrain-mlogloss:0.08764\teval-mlogloss:0.79147\n",
      "[96]\ttrain-mlogloss:0.08605\teval-mlogloss:0.79312\n",
      "[97]\ttrain-mlogloss:0.08449\teval-mlogloss:0.79384\n",
      "[98]\ttrain-mlogloss:0.08302\teval-mlogloss:0.79661\n",
      "[99]\ttrain-mlogloss:0.08159\teval-mlogloss:0.79810\n",
      "[100]\ttrain-mlogloss:0.08011\teval-mlogloss:0.80008\n",
      "[101]\ttrain-mlogloss:0.07874\teval-mlogloss:0.80163\n",
      "[102]\ttrain-mlogloss:0.07731\teval-mlogloss:0.80427\n",
      "[103]\ttrain-mlogloss:0.07604\teval-mlogloss:0.80640\n",
      "[104]\ttrain-mlogloss:0.07478\teval-mlogloss:0.80755\n",
      "[105]\ttrain-mlogloss:0.07353\teval-mlogloss:0.80890\n",
      "[106]\ttrain-mlogloss:0.07237\teval-mlogloss:0.81099\n",
      "[107]\ttrain-mlogloss:0.07126\teval-mlogloss:0.81277\n",
      "[108]\ttrain-mlogloss:0.07010\teval-mlogloss:0.81416\n",
      "[109]\ttrain-mlogloss:0.06904\teval-mlogloss:0.81822\n",
      "[110]\ttrain-mlogloss:0.06793\teval-mlogloss:0.82068\n",
      "[111]\ttrain-mlogloss:0.06687\teval-mlogloss:0.82237\n",
      "[112]\ttrain-mlogloss:0.06589\teval-mlogloss:0.82358\n",
      "[113]\ttrain-mlogloss:0.06491\teval-mlogloss:0.82460\n",
      "[114]\ttrain-mlogloss:0.06394\teval-mlogloss:0.82720\n",
      "[115]\ttrain-mlogloss:0.06299\teval-mlogloss:0.82756\n",
      "[116]\ttrain-mlogloss:0.06210\teval-mlogloss:0.82979\n",
      "[117]\ttrain-mlogloss:0.06117\teval-mlogloss:0.83088\n",
      "[118]\ttrain-mlogloss:0.06031\teval-mlogloss:0.83351\n",
      "[119]\ttrain-mlogloss:0.05944\teval-mlogloss:0.83584\n",
      "[120]\ttrain-mlogloss:0.05861\teval-mlogloss:0.83798\n",
      "[121]\ttrain-mlogloss:0.05782\teval-mlogloss:0.83982\n",
      "[122]\ttrain-mlogloss:0.05704\teval-mlogloss:0.84108\n",
      "[123]\ttrain-mlogloss:0.05623\teval-mlogloss:0.84304\n",
      "[124]\ttrain-mlogloss:0.05551\teval-mlogloss:0.84523\n",
      "[125]\ttrain-mlogloss:0.05479\teval-mlogloss:0.84781\n",
      "[126]\ttrain-mlogloss:0.05405\teval-mlogloss:0.84834\n",
      "[127]\ttrain-mlogloss:0.05334\teval-mlogloss:0.85144\n",
      "[128]\ttrain-mlogloss:0.05263\teval-mlogloss:0.85282\n",
      "[129]\ttrain-mlogloss:0.05196\teval-mlogloss:0.85219\n",
      "[130]\ttrain-mlogloss:0.05130\teval-mlogloss:0.85377\n",
      "[131]\ttrain-mlogloss:0.05064\teval-mlogloss:0.85555\n",
      "[132]\ttrain-mlogloss:0.04997\teval-mlogloss:0.85616\n",
      "[133]\ttrain-mlogloss:0.04934\teval-mlogloss:0.85774\n",
      "[134]\ttrain-mlogloss:0.04871\teval-mlogloss:0.85841\n",
      "[135]\ttrain-mlogloss:0.04812\teval-mlogloss:0.85886\n",
      "[136]\ttrain-mlogloss:0.04756\teval-mlogloss:0.86114\n",
      "[137]\ttrain-mlogloss:0.04699\teval-mlogloss:0.86256\n",
      "[138]\ttrain-mlogloss:0.04648\teval-mlogloss:0.86425\n",
      "[139]\ttrain-mlogloss:0.04596\teval-mlogloss:0.86701\n",
      "[140]\ttrain-mlogloss:0.04541\teval-mlogloss:0.86988\n",
      "[141]\ttrain-mlogloss:0.04492\teval-mlogloss:0.87169\n",
      "[142]\ttrain-mlogloss:0.04438\teval-mlogloss:0.87402\n",
      "[143]\ttrain-mlogloss:0.04392\teval-mlogloss:0.87557\n"
     ]
    }
   ],
   "source": [
    "#t7_0.53219 ########성능 0.683 train데이터내에서 train validation test 나눠서\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, \n",
    "                                                    test_size=0.1, \n",
    "                                                    stratify=train_y, \n",
    "                                                    random_state=37)\n",
    "\n",
    "dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(data=X_test, label=y_test)\n",
    "dtest_x = xgb.DMatrix(data=test_x)\n",
    "\n",
    "params = {'max_depth' : 6,\n",
    "          'eta': 0.035,\n",
    "          'objective':'multi:softmax',\n",
    "          'num_class':3,\n",
    "          'eval_metric':'mlogloss',\n",
    "          'eval_set': [(X_test, y_test)], #적용이 안 되고 있다고 뜸\n",
    "          'early_stopping':100 #적용이 안 되고 있다고 뜸\n",
    "          }\n",
    "num_rounds = 400\n",
    "\n",
    "wlist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "xgb_model = xgb.train(params=params, \n",
    "                      dtrain=dtrain, \n",
    "                      num_boost_round=num_rounds, \n",
    "                      early_stopping_rounds=100, \n",
    "                      evals=wlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "127aa3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "44\n",
      "0.7244108068943024\n"
     ]
    }
   ],
   "source": [
    "print(xgb_model.best_iteration)\n",
    "print(xgb_model.best_ntree_limit)\n",
    "print(xgb_model.best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f817d5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 저장\n",
    "with open('model_XGB_0683.pickle','wb') as fw:\n",
    "    pickle.dump(xgb_model, fw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pas",
   "language": "python",
   "name": "pas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

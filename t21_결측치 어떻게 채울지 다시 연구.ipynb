{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0c732c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings; warnings.filterwarnings(action='ignore')\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from bayes_opt import BayesianOptimization\n",
    "from xgboost import XGBClassifier # model \n",
    "from xgboost import plot_importance\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from scipy.stats import randint\n",
    "import sklearn.svm as svm\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "393dad2e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement time (from versions: none)\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for time\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import sys   \n",
    "!{sys.executable} -m pip install time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c407cb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed) #파이썬 자체 모듈 random 모듈의 시드 고정\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) \n",
    "    np.random.seed(seed) #넘파이를 사용할 경우\n",
    "#     torch.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(37) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33209ff9",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "864c76d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터프레임 불러오기\n",
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "149a45e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "subGBM = pd.read_csv('./sample_submission.csv')\n",
    "subRFSVM = pd.read_csv('./sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1230dced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['T050304', 'T050307', 'T010306', 'T010305', 'T100304', 'T100306'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['LINE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "55ae7c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>Y_Class</th>\n",
       "      <th>Y_Quality</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>LINE</th>\n",
       "      <th>PRODUCT_CODE</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>...</th>\n",
       "      <th>X_2866</th>\n",
       "      <th>X_2867</th>\n",
       "      <th>X_2868</th>\n",
       "      <th>X_2869</th>\n",
       "      <th>X_2870</th>\n",
       "      <th>X_2871</th>\n",
       "      <th>X_2872</th>\n",
       "      <th>X_2873</th>\n",
       "      <th>X_2874</th>\n",
       "      <th>X_2875</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533433</td>\n",
       "      <td>2022-06-13 5:14</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>39.34</td>\n",
       "      <td>40.89</td>\n",
       "      <td>32.56</td>\n",
       "      <td>34.09</td>\n",
       "      <td>77.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.541819</td>\n",
       "      <td>2022-06-13 5:22</td>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38.89</td>\n",
       "      <td>42.82</td>\n",
       "      <td>43.92</td>\n",
       "      <td>35.34</td>\n",
       "      <td>72.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531267</td>\n",
       "      <td>2022-06-13 5:30</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>39.19</td>\n",
       "      <td>36.65</td>\n",
       "      <td>42.47</td>\n",
       "      <td>36.53</td>\n",
       "      <td>78.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_003</td>\n",
       "      <td>2</td>\n",
       "      <td>0.537325</td>\n",
       "      <td>2022-06-13 5:39</td>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>37.74</td>\n",
       "      <td>39.17</td>\n",
       "      <td>52.17</td>\n",
       "      <td>30.58</td>\n",
       "      <td>71.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_004</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531590</td>\n",
       "      <td>2022-06-13 5:47</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38.70</td>\n",
       "      <td>41.89</td>\n",
       "      <td>46.93</td>\n",
       "      <td>33.09</td>\n",
       "      <td>76.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>TRAIN_593</td>\n",
       "      <td>1</td>\n",
       "      <td>0.526546</td>\n",
       "      <td>2022-09-08 14:30</td>\n",
       "      <td>T100306</td>\n",
       "      <td>T_31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>TRAIN_594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524022</td>\n",
       "      <td>2022-09-08 22:38</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>49.47</td>\n",
       "      <td>53.07</td>\n",
       "      <td>50.89</td>\n",
       "      <td>55.10</td>\n",
       "      <td>66.49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>TRAIN_595</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521289</td>\n",
       "      <td>2022-09-08 22:47</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>TRAIN_596</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531375</td>\n",
       "      <td>2022-09-08 14:38</td>\n",
       "      <td>T100304</td>\n",
       "      <td>O_31</td>\n",
       "      <td>40.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>TRAIN_597</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533702</td>\n",
       "      <td>2022-09-08 14:46</td>\n",
       "      <td>T100306</td>\n",
       "      <td>O_31</td>\n",
       "      <td>21.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>598 rows × 2881 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PRODUCT_ID  Y_Class  Y_Quality         TIMESTAMP     LINE PRODUCT_CODE  \\\n",
       "0    TRAIN_000        1   0.533433   2022-06-13 5:14  T050304         A_31   \n",
       "1    TRAIN_001        2   0.541819   2022-06-13 5:22  T050307         A_31   \n",
       "2    TRAIN_002        1   0.531267   2022-06-13 5:30  T050304         A_31   \n",
       "3    TRAIN_003        2   0.537325   2022-06-13 5:39  T050307         A_31   \n",
       "4    TRAIN_004        1   0.531590   2022-06-13 5:47  T050304         A_31   \n",
       "..         ...      ...        ...               ...      ...          ...   \n",
       "593  TRAIN_593        1   0.526546  2022-09-08 14:30  T100306         T_31   \n",
       "594  TRAIN_594        0   0.524022  2022-09-08 22:38  T050304         A_31   \n",
       "595  TRAIN_595        0   0.521289  2022-09-08 22:47  T050304         A_31   \n",
       "596  TRAIN_596        1   0.531375  2022-09-08 14:38  T100304         O_31   \n",
       "597  TRAIN_597        1   0.533702  2022-09-08 14:46  T100306         O_31   \n",
       "\n",
       "      X_1   X_2  X_3   X_4  ...  X_2866  X_2867  X_2868  X_2869  X_2870  \\\n",
       "0     NaN   NaN  NaN   NaN  ...   39.34   40.89   32.56   34.09   77.77   \n",
       "1     NaN   NaN  NaN   NaN  ...   38.89   42.82   43.92   35.34   72.55   \n",
       "2     NaN   NaN  NaN   NaN  ...   39.19   36.65   42.47   36.53   78.35   \n",
       "3     NaN   NaN  NaN   NaN  ...   37.74   39.17   52.17   30.58   71.78   \n",
       "4     NaN   NaN  NaN   NaN  ...   38.70   41.89   46.93   33.09   76.97   \n",
       "..    ...   ...  ...   ...  ...     ...     ...     ...     ...     ...   \n",
       "593   2.0  95.0  0.0  45.0  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "594   NaN   NaN  NaN   NaN  ...   49.47   53.07   50.89   55.10   66.49   \n",
       "595   NaN   NaN  NaN   NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "596  40.0  94.0  0.0  45.0  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "597  21.0  87.0  0.0  45.0  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "     X_2871  X_2872  X_2873  X_2874  X_2875  \n",
       "0       NaN     NaN     NaN     NaN     NaN  \n",
       "1       NaN     NaN     NaN     NaN     NaN  \n",
       "2       NaN     NaN     NaN     NaN     NaN  \n",
       "3       NaN     NaN     NaN     NaN     NaN  \n",
       "4       NaN     NaN     NaN     NaN     NaN  \n",
       "..      ...     ...     ...     ...     ...  \n",
       "593     NaN     NaN     NaN     NaN     NaN  \n",
       "594     1.0     NaN     NaN     NaN     NaN  \n",
       "595     1.0     NaN     NaN     NaN     NaN  \n",
       "596     NaN     NaN     NaN     NaN     NaN  \n",
       "597     NaN     NaN     NaN     NaN     NaN  \n",
       "\n",
       "[598 rows x 2881 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5bc5d1",
   "metadata": {},
   "source": [
    "# EDA 데이터 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18ff6d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRODUCT_CODE  LINE   \n",
       "A_31          T010305    0\n",
       "              T010306    0\n",
       "              T050304    0\n",
       "              T050307    0\n",
       "Name: X_1, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hier = train_df[train_df['X_1'].isnull()].groupby(['PRODUCT_CODE', 'LINE'])['X_1'].count()\n",
    "hier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49cad24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>Y_Class</th>\n",
       "      <th>Y_Quality</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>LINE</th>\n",
       "      <th>PRODUCT_CODE</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>...</th>\n",
       "      <th>X_2866</th>\n",
       "      <th>X_2867</th>\n",
       "      <th>X_2868</th>\n",
       "      <th>X_2869</th>\n",
       "      <th>X_2870</th>\n",
       "      <th>X_2871</th>\n",
       "      <th>X_2872</th>\n",
       "      <th>X_2873</th>\n",
       "      <th>X_2874</th>\n",
       "      <th>X_2875</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>TRAIN_569</td>\n",
       "      <td>1</td>\n",
       "      <td>0.530533</td>\n",
       "      <td>2022-09-03 18:32</td>\n",
       "      <td>T100304</td>\n",
       "      <td>O_31</td>\n",
       "      <td>4.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>TRAIN_570</td>\n",
       "      <td>2</td>\n",
       "      <td>0.534951</td>\n",
       "      <td>2022-09-03 18:40</td>\n",
       "      <td>T100306</td>\n",
       "      <td>O_31</td>\n",
       "      <td>6.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>TRAIN_571</td>\n",
       "      <td>1</td>\n",
       "      <td>0.525916</td>\n",
       "      <td>2022-09-03 18:48</td>\n",
       "      <td>T100304</td>\n",
       "      <td>O_31</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>TRAIN_572</td>\n",
       "      <td>2</td>\n",
       "      <td>0.535205</td>\n",
       "      <td>2022-09-03 18:56</td>\n",
       "      <td>T100306</td>\n",
       "      <td>O_31</td>\n",
       "      <td>6.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>TRAIN_596</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531375</td>\n",
       "      <td>2022-09-08 14:38</td>\n",
       "      <td>T100304</td>\n",
       "      <td>O_31</td>\n",
       "      <td>40.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>TRAIN_597</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533702</td>\n",
       "      <td>2022-09-08 14:46</td>\n",
       "      <td>T100306</td>\n",
       "      <td>O_31</td>\n",
       "      <td>21.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 2881 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PRODUCT_ID  Y_Class  Y_Quality         TIMESTAMP     LINE PRODUCT_CODE  \\\n",
       "569  TRAIN_569        1   0.530533  2022-09-03 18:32  T100304         O_31   \n",
       "570  TRAIN_570        2   0.534951  2022-09-03 18:40  T100306         O_31   \n",
       "571  TRAIN_571        1   0.525916  2022-09-03 18:48  T100304         O_31   \n",
       "572  TRAIN_572        2   0.535205  2022-09-03 18:56  T100306         O_31   \n",
       "596  TRAIN_596        1   0.531375  2022-09-08 14:38  T100304         O_31   \n",
       "597  TRAIN_597        1   0.533702  2022-09-08 14:46  T100306         O_31   \n",
       "\n",
       "      X_1    X_2  X_3   X_4  ...  X_2866  X_2867  X_2868  X_2869  X_2870  \\\n",
       "569   4.0   98.0  0.0  45.0  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "570   6.0   90.0  0.0  45.0  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "571   4.0  100.0  0.0  45.0  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "572   6.0   89.0  0.0  45.0  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "596  40.0   94.0  0.0  45.0  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "597  21.0   87.0  0.0  45.0  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "     X_2871  X_2872  X_2873  X_2874  X_2875  \n",
       "569     NaN     NaN     NaN     NaN     NaN  \n",
       "570     NaN     NaN     NaN     NaN     NaN  \n",
       "571     NaN     NaN     NaN     NaN     NaN  \n",
       "572     NaN     NaN     NaN     NaN     NaN  \n",
       "596     NaN     NaN     NaN     NaN     NaN  \n",
       "597     NaN     NaN     NaN     NaN     NaN  \n",
       "\n",
       "[6 rows x 2881 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['PRODUCT_CODE']== 'O_31']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bf4a52",
   "metadata": {},
   "source": [
    "['T050304', 'T050307', 'T100304', 'T100306', 'T010306', 'T010305']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "91844895",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_981</th>\n",
       "      <th>X_982</th>\n",
       "      <th>X_983</th>\n",
       "      <th>X_984</th>\n",
       "      <th>X_985</th>\n",
       "      <th>X_986</th>\n",
       "      <th>X_987</th>\n",
       "      <th>X_988</th>\n",
       "      <th>X_989</th>\n",
       "      <th>X_990</th>\n",
       "      <th>X_991</th>\n",
       "      <th>X_992</th>\n",
       "      <th>X_993</th>\n",
       "      <th>X_994</th>\n",
       "      <th>X_995</th>\n",
       "      <th>X_996</th>\n",
       "      <th>X_997</th>\n",
       "      <th>X_998</th>\n",
       "      <th>X_999</th>\n",
       "      <th>X_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>24.6</td>\n",
       "      <td>24.441935</td>\n",
       "      <td>24.3</td>\n",
       "      <td>74.5</td>\n",
       "      <td>74.383871</td>\n",
       "      <td>74.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1507.0</td>\n",
       "      <td>1507.000000</td>\n",
       "      <td>1507.0</td>\n",
       "      <td>180076.0</td>\n",
       "      <td>180054.25810</td>\n",
       "      <td>180034.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>541.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>24.3</td>\n",
       "      <td>24.254839</td>\n",
       "      <td>24.2</td>\n",
       "      <td>73.4</td>\n",
       "      <td>73.303226</td>\n",
       "      <td>73.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>322.516129</td>\n",
       "      <td>322.0</td>\n",
       "      <td>37342.0</td>\n",
       "      <td>37322.58065</td>\n",
       "      <td>37302.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>24.5</td>\n",
       "      <td>24.341935</td>\n",
       "      <td>24.2</td>\n",
       "      <td>74.0</td>\n",
       "      <td>73.967742</td>\n",
       "      <td>73.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>257.935484</td>\n",
       "      <td>257.0</td>\n",
       "      <td>30363.0</td>\n",
       "      <td>30341.58065</td>\n",
       "      <td>30322.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>25.1</td>\n",
       "      <td>24.964516</td>\n",
       "      <td>24.8</td>\n",
       "      <td>73.3</td>\n",
       "      <td>73.196774</td>\n",
       "      <td>73.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>924.0</td>\n",
       "      <td>924.000000</td>\n",
       "      <td>924.0</td>\n",
       "      <td>115928.0</td>\n",
       "      <td>115908.70970</td>\n",
       "      <td>115888.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>25.2</td>\n",
       "      <td>25.006452</td>\n",
       "      <td>24.8</td>\n",
       "      <td>73.2</td>\n",
       "      <td>73.129032</td>\n",
       "      <td>73.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>938.0</td>\n",
       "      <td>937.354839</td>\n",
       "      <td>937.0</td>\n",
       "      <td>117438.0</td>\n",
       "      <td>117416.58060</td>\n",
       "      <td>117397.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>336.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>24.3</td>\n",
       "      <td>24.148387</td>\n",
       "      <td>24.0</td>\n",
       "      <td>74.3</td>\n",
       "      <td>74.267742</td>\n",
       "      <td>74.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>1036.000000</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>124324.0</td>\n",
       "      <td>124303.93550</td>\n",
       "      <td>124283.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>402.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>24.3</td>\n",
       "      <td>24.232258</td>\n",
       "      <td>24.1</td>\n",
       "      <td>74.6</td>\n",
       "      <td>74.506452</td>\n",
       "      <td>74.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>240.0</td>\n",
       "      <td>29062.0</td>\n",
       "      <td>29042.41935</td>\n",
       "      <td>29021.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>24.6</td>\n",
       "      <td>24.441935</td>\n",
       "      <td>24.2</td>\n",
       "      <td>74.6</td>\n",
       "      <td>74.512903</td>\n",
       "      <td>74.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1538.0</td>\n",
       "      <td>1538.000000</td>\n",
       "      <td>1538.0</td>\n",
       "      <td>196685.0</td>\n",
       "      <td>196663.83870</td>\n",
       "      <td>196644.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>555.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>24.5</td>\n",
       "      <td>24.290625</td>\n",
       "      <td>24.2</td>\n",
       "      <td>74.1</td>\n",
       "      <td>73.993750</td>\n",
       "      <td>73.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>1566.000000</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>200477.0</td>\n",
       "      <td>200454.40630</td>\n",
       "      <td>200432.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>565.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>24.5</td>\n",
       "      <td>24.334375</td>\n",
       "      <td>24.1</td>\n",
       "      <td>75.0</td>\n",
       "      <td>74.887500</td>\n",
       "      <td>74.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1624.0</td>\n",
       "      <td>1623.812500</td>\n",
       "      <td>1623.0</td>\n",
       "      <td>207968.0</td>\n",
       "      <td>207947.50000</td>\n",
       "      <td>207927.0</td>\n",
       "      <td>586.0</td>\n",
       "      <td>586.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>24.6</td>\n",
       "      <td>24.322581</td>\n",
       "      <td>24.1</td>\n",
       "      <td>73.3</td>\n",
       "      <td>73.200000</td>\n",
       "      <td>73.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1209.0</td>\n",
       "      <td>1208.419355</td>\n",
       "      <td>1208.0</td>\n",
       "      <td>168716.0</td>\n",
       "      <td>168695.03230</td>\n",
       "      <td>168675.0</td>\n",
       "      <td>436.0</td>\n",
       "      <td>436.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>24.6</td>\n",
       "      <td>24.396774</td>\n",
       "      <td>24.2</td>\n",
       "      <td>73.7</td>\n",
       "      <td>73.658065</td>\n",
       "      <td>73.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>1238.000000</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>172513.0</td>\n",
       "      <td>172492.77420</td>\n",
       "      <td>172472.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>446.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>25.4</td>\n",
       "      <td>25.222581</td>\n",
       "      <td>25.0</td>\n",
       "      <td>73.7</td>\n",
       "      <td>73.661290</td>\n",
       "      <td>73.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1419.0</td>\n",
       "      <td>1419.000000</td>\n",
       "      <td>1419.0</td>\n",
       "      <td>208191.0</td>\n",
       "      <td>208169.83870</td>\n",
       "      <td>208150.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>24.5</td>\n",
       "      <td>24.319355</td>\n",
       "      <td>24.1</td>\n",
       "      <td>74.0</td>\n",
       "      <td>73.974194</td>\n",
       "      <td>73.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>301.0</td>\n",
       "      <td>39780.0</td>\n",
       "      <td>39760.48387</td>\n",
       "      <td>39739.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>24.6</td>\n",
       "      <td>24.437500</td>\n",
       "      <td>24.3</td>\n",
       "      <td>74.4</td>\n",
       "      <td>74.359375</td>\n",
       "      <td>74.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>380.000000</td>\n",
       "      <td>380.0</td>\n",
       "      <td>49273.0</td>\n",
       "      <td>49252.00000</td>\n",
       "      <td>49231.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>24.4</td>\n",
       "      <td>24.250000</td>\n",
       "      <td>24.1</td>\n",
       "      <td>73.1</td>\n",
       "      <td>73.065625</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>432.000000</td>\n",
       "      <td>432.0</td>\n",
       "      <td>64495.0</td>\n",
       "      <td>64473.15625</td>\n",
       "      <td>64451.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>24.6</td>\n",
       "      <td>24.412903</td>\n",
       "      <td>24.3</td>\n",
       "      <td>73.6</td>\n",
       "      <td>73.477419</td>\n",
       "      <td>73.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>1018.000000</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>122391.0</td>\n",
       "      <td>122370.29030</td>\n",
       "      <td>122350.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>418.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>25.1</td>\n",
       "      <td>24.958065</td>\n",
       "      <td>24.8</td>\n",
       "      <td>75.1</td>\n",
       "      <td>75.096774</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>341.000000</td>\n",
       "      <td>341.0</td>\n",
       "      <td>51618.0</td>\n",
       "      <td>51598.09677</td>\n",
       "      <td>51577.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>24.4</td>\n",
       "      <td>24.303226</td>\n",
       "      <td>24.1</td>\n",
       "      <td>72.9</td>\n",
       "      <td>72.851613</td>\n",
       "      <td>72.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1301.0</td>\n",
       "      <td>1301.000000</td>\n",
       "      <td>1301.0</td>\n",
       "      <td>164416.0</td>\n",
       "      <td>164395.67740</td>\n",
       "      <td>164374.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>505.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>24.6</td>\n",
       "      <td>24.509677</td>\n",
       "      <td>24.4</td>\n",
       "      <td>74.6</td>\n",
       "      <td>74.493548</td>\n",
       "      <td>74.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>737.0</td>\n",
       "      <td>737.000000</td>\n",
       "      <td>737.0</td>\n",
       "      <td>87100.0</td>\n",
       "      <td>87080.54839</td>\n",
       "      <td>87059.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>263.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>24.7</td>\n",
       "      <td>24.529032</td>\n",
       "      <td>24.4</td>\n",
       "      <td>74.4</td>\n",
       "      <td>74.309677</td>\n",
       "      <td>74.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.0</td>\n",
       "      <td>88623.0</td>\n",
       "      <td>88603.16129</td>\n",
       "      <td>88582.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>24.4</td>\n",
       "      <td>24.231250</td>\n",
       "      <td>24.0</td>\n",
       "      <td>73.5</td>\n",
       "      <td>73.462500</td>\n",
       "      <td>73.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>1057.000000</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>137727.0</td>\n",
       "      <td>137706.25000</td>\n",
       "      <td>137686.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>24.5</td>\n",
       "      <td>24.312903</td>\n",
       "      <td>24.2</td>\n",
       "      <td>73.7</td>\n",
       "      <td>73.612903</td>\n",
       "      <td>73.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>1158.741935</td>\n",
       "      <td>1158.0</td>\n",
       "      <td>149805.0</td>\n",
       "      <td>149783.51610</td>\n",
       "      <td>149764.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>461.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>24.4</td>\n",
       "      <td>24.300000</td>\n",
       "      <td>24.1</td>\n",
       "      <td>73.5</td>\n",
       "      <td>73.403226</td>\n",
       "      <td>73.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>125984.0</td>\n",
       "      <td>125963.35480</td>\n",
       "      <td>125944.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>417.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>24.5</td>\n",
       "      <td>24.309677</td>\n",
       "      <td>24.2</td>\n",
       "      <td>74.1</td>\n",
       "      <td>74.032258</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>999.580645</td>\n",
       "      <td>999.0</td>\n",
       "      <td>120459.0</td>\n",
       "      <td>120439.29030</td>\n",
       "      <td>120418.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>422.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>24.5</td>\n",
       "      <td>24.341935</td>\n",
       "      <td>24.2</td>\n",
       "      <td>74.3</td>\n",
       "      <td>74.248387</td>\n",
       "      <td>74.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1616.0</td>\n",
       "      <td>1615.483871</td>\n",
       "      <td>1615.0</td>\n",
       "      <td>191702.0</td>\n",
       "      <td>191681.16130</td>\n",
       "      <td>191661.0</td>\n",
       "      <td>634.0</td>\n",
       "      <td>634.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>24.6</td>\n",
       "      <td>24.393548</td>\n",
       "      <td>24.3</td>\n",
       "      <td>73.5</td>\n",
       "      <td>73.425806</td>\n",
       "      <td>73.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>1025.612903</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>129259.0</td>\n",
       "      <td>129237.58060</td>\n",
       "      <td>129218.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>24.4</td>\n",
       "      <td>24.271875</td>\n",
       "      <td>24.1</td>\n",
       "      <td>74.5</td>\n",
       "      <td>74.487500</td>\n",
       "      <td>74.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.0</td>\n",
       "      <td>39763.0</td>\n",
       "      <td>39741.53125</td>\n",
       "      <td>39720.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>24.5</td>\n",
       "      <td>24.348387</td>\n",
       "      <td>24.2</td>\n",
       "      <td>74.0</td>\n",
       "      <td>73.896774</td>\n",
       "      <td>73.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>610.0</td>\n",
       "      <td>610.000000</td>\n",
       "      <td>610.0</td>\n",
       "      <td>71943.0</td>\n",
       "      <td>71921.58065</td>\n",
       "      <td>71902.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>24.8</td>\n",
       "      <td>24.606452</td>\n",
       "      <td>24.5</td>\n",
       "      <td>74.6</td>\n",
       "      <td>74.506452</td>\n",
       "      <td>74.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1788.0</td>\n",
       "      <td>1787.354839</td>\n",
       "      <td>1787.0</td>\n",
       "      <td>227395.0</td>\n",
       "      <td>227374.29030</td>\n",
       "      <td>227354.0</td>\n",
       "      <td>708.0</td>\n",
       "      <td>708.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>24.6</td>\n",
       "      <td>24.441935</td>\n",
       "      <td>24.3</td>\n",
       "      <td>74.0</td>\n",
       "      <td>73.932258</td>\n",
       "      <td>73.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>942.0</td>\n",
       "      <td>942.000000</td>\n",
       "      <td>942.0</td>\n",
       "      <td>117333.0</td>\n",
       "      <td>117313.41940</td>\n",
       "      <td>117292.0</td>\n",
       "      <td>369.0</td>\n",
       "      <td>368.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>24.5</td>\n",
       "      <td>24.393548</td>\n",
       "      <td>24.2</td>\n",
       "      <td>74.3</td>\n",
       "      <td>74.219355</td>\n",
       "      <td>74.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1411.0</td>\n",
       "      <td>1411.000000</td>\n",
       "      <td>1411.0</td>\n",
       "      <td>173522.0</td>\n",
       "      <td>173500.96770</td>\n",
       "      <td>173481.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>555.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>24.7</td>\n",
       "      <td>24.483871</td>\n",
       "      <td>24.3</td>\n",
       "      <td>75.0</td>\n",
       "      <td>74.964516</td>\n",
       "      <td>74.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1945.0</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.0</td>\n",
       "      <td>236437.0</td>\n",
       "      <td>236415.38710</td>\n",
       "      <td>236395.0</td>\n",
       "      <td>765.0</td>\n",
       "      <td>764.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>24.7</td>\n",
       "      <td>24.551613</td>\n",
       "      <td>24.4</td>\n",
       "      <td>74.6</td>\n",
       "      <td>74.570968</td>\n",
       "      <td>74.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>1007.000000</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>190099.0</td>\n",
       "      <td>190078.96770</td>\n",
       "      <td>190059.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>359.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>24.6</td>\n",
       "      <td>24.483871</td>\n",
       "      <td>24.3</td>\n",
       "      <td>74.1</td>\n",
       "      <td>74.006452</td>\n",
       "      <td>73.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>1022.000000</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>191934.0</td>\n",
       "      <td>191914.03230</td>\n",
       "      <td>191893.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>24.6</td>\n",
       "      <td>24.458065</td>\n",
       "      <td>24.3</td>\n",
       "      <td>73.8</td>\n",
       "      <td>73.725806</td>\n",
       "      <td>73.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>138.0</td>\n",
       "      <td>16556.0</td>\n",
       "      <td>16536.29032</td>\n",
       "      <td>16515.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>24.7</td>\n",
       "      <td>24.535484</td>\n",
       "      <td>24.4</td>\n",
       "      <td>74.7</td>\n",
       "      <td>74.619355</td>\n",
       "      <td>74.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>516.000000</td>\n",
       "      <td>516.0</td>\n",
       "      <td>62666.0</td>\n",
       "      <td>62645.90323</td>\n",
       "      <td>62625.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>24.7</td>\n",
       "      <td>24.532258</td>\n",
       "      <td>24.3</td>\n",
       "      <td>74.1</td>\n",
       "      <td>74.090323</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>628.0</td>\n",
       "      <td>628.000000</td>\n",
       "      <td>628.0</td>\n",
       "      <td>75906.0</td>\n",
       "      <td>75884.90323</td>\n",
       "      <td>75865.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>24.5</td>\n",
       "      <td>24.406452</td>\n",
       "      <td>24.3</td>\n",
       "      <td>74.2</td>\n",
       "      <td>74.161290</td>\n",
       "      <td>74.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>1009.000000</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>120043.0</td>\n",
       "      <td>120023.29030</td>\n",
       "      <td>120002.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>24.7</td>\n",
       "      <td>24.506250</td>\n",
       "      <td>24.3</td>\n",
       "      <td>74.0</td>\n",
       "      <td>73.903125</td>\n",
       "      <td>73.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1697.0</td>\n",
       "      <td>1696.812500</td>\n",
       "      <td>1696.0</td>\n",
       "      <td>202928.0</td>\n",
       "      <td>202907.37500</td>\n",
       "      <td>202887.0</td>\n",
       "      <td>607.0</td>\n",
       "      <td>607.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>24.7</td>\n",
       "      <td>24.540625</td>\n",
       "      <td>24.4</td>\n",
       "      <td>74.0</td>\n",
       "      <td>73.931250</td>\n",
       "      <td>73.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1713.0</td>\n",
       "      <td>1712.281250</td>\n",
       "      <td>1712.0</td>\n",
       "      <td>204750.0</td>\n",
       "      <td>204728.03130</td>\n",
       "      <td>204706.0</td>\n",
       "      <td>613.0</td>\n",
       "      <td>612.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>24.7</td>\n",
       "      <td>24.409677</td>\n",
       "      <td>24.2</td>\n",
       "      <td>74.3</td>\n",
       "      <td>74.219355</td>\n",
       "      <td>74.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>675.0</td>\n",
       "      <td>674.612903</td>\n",
       "      <td>674.0</td>\n",
       "      <td>79669.0</td>\n",
       "      <td>79648.41935</td>\n",
       "      <td>79629.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>24.9</td>\n",
       "      <td>24.825806</td>\n",
       "      <td>24.7</td>\n",
       "      <td>74.5</td>\n",
       "      <td>74.477419</td>\n",
       "      <td>74.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>1129.000000</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>165221.0</td>\n",
       "      <td>165200.22580</td>\n",
       "      <td>165180.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>408.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>25.0</td>\n",
       "      <td>24.868750</td>\n",
       "      <td>24.6</td>\n",
       "      <td>74.9</td>\n",
       "      <td>74.759375</td>\n",
       "      <td>74.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1137.0</td>\n",
       "      <td>1136.500000</td>\n",
       "      <td>1136.0</td>\n",
       "      <td>166077.0</td>\n",
       "      <td>166056.25000</td>\n",
       "      <td>166036.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>25.1</td>\n",
       "      <td>24.980645</td>\n",
       "      <td>24.9</td>\n",
       "      <td>73.6</td>\n",
       "      <td>73.558065</td>\n",
       "      <td>73.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>432.870968</td>\n",
       "      <td>432.0</td>\n",
       "      <td>75956.0</td>\n",
       "      <td>75935.03226</td>\n",
       "      <td>75915.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>24.7</td>\n",
       "      <td>24.467742</td>\n",
       "      <td>24.4</td>\n",
       "      <td>74.3</td>\n",
       "      <td>74.238710</td>\n",
       "      <td>74.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>224.0</td>\n",
       "      <td>26546.0</td>\n",
       "      <td>26525.29032</td>\n",
       "      <td>26506.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>24.6</td>\n",
       "      <td>24.483871</td>\n",
       "      <td>24.3</td>\n",
       "      <td>74.1</td>\n",
       "      <td>73.993548</td>\n",
       "      <td>73.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1268.0</td>\n",
       "      <td>1268.000000</td>\n",
       "      <td>1268.0</td>\n",
       "      <td>152525.0</td>\n",
       "      <td>152503.64520</td>\n",
       "      <td>152484.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>468.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>24.7</td>\n",
       "      <td>24.522581</td>\n",
       "      <td>24.4</td>\n",
       "      <td>74.6</td>\n",
       "      <td>74.551613</td>\n",
       "      <td>74.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1735.0</td>\n",
       "      <td>1734.483871</td>\n",
       "      <td>1734.0</td>\n",
       "      <td>236085.0</td>\n",
       "      <td>236064.16130</td>\n",
       "      <td>236045.0</td>\n",
       "      <td>631.0</td>\n",
       "      <td>631.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>24.6</td>\n",
       "      <td>24.490323</td>\n",
       "      <td>24.3</td>\n",
       "      <td>74.3</td>\n",
       "      <td>74.270968</td>\n",
       "      <td>74.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>417.806452</td>\n",
       "      <td>417.0</td>\n",
       "      <td>49132.0</td>\n",
       "      <td>49110.54839</td>\n",
       "      <td>49091.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>24.7</td>\n",
       "      <td>24.548387</td>\n",
       "      <td>24.4</td>\n",
       "      <td>74.4</td>\n",
       "      <td>74.309677</td>\n",
       "      <td>74.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>431.000000</td>\n",
       "      <td>431.0</td>\n",
       "      <td>50659.0</td>\n",
       "      <td>50639.09677</td>\n",
       "      <td>50618.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>24.5</td>\n",
       "      <td>24.367742</td>\n",
       "      <td>24.3</td>\n",
       "      <td>74.2</td>\n",
       "      <td>74.200000</td>\n",
       "      <td>74.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1175.0</td>\n",
       "      <td>1175.000000</td>\n",
       "      <td>1175.0</td>\n",
       "      <td>145708.0</td>\n",
       "      <td>145688.09680</td>\n",
       "      <td>145667.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>502.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>24.6</td>\n",
       "      <td>24.443750</td>\n",
       "      <td>24.3</td>\n",
       "      <td>74.5</td>\n",
       "      <td>74.456250</td>\n",
       "      <td>74.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>1191.000000</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>162258.0</td>\n",
       "      <td>162237.81250</td>\n",
       "      <td>162217.0</td>\n",
       "      <td>443.0</td>\n",
       "      <td>443.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>24.5</td>\n",
       "      <td>24.446875</td>\n",
       "      <td>24.3</td>\n",
       "      <td>74.4</td>\n",
       "      <td>74.309375</td>\n",
       "      <td>74.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1204.0</td>\n",
       "      <td>1204.000000</td>\n",
       "      <td>1204.0</td>\n",
       "      <td>163784.0</td>\n",
       "      <td>163763.40630</td>\n",
       "      <td>163743.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>24.5</td>\n",
       "      <td>24.277419</td>\n",
       "      <td>24.1</td>\n",
       "      <td>74.7</td>\n",
       "      <td>74.632258</td>\n",
       "      <td>74.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1107.0</td>\n",
       "      <td>1107.000000</td>\n",
       "      <td>1107.0</td>\n",
       "      <td>138557.0</td>\n",
       "      <td>138536.90320</td>\n",
       "      <td>138516.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>405.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>24.5</td>\n",
       "      <td>24.325806</td>\n",
       "      <td>24.2</td>\n",
       "      <td>73.4</td>\n",
       "      <td>73.364516</td>\n",
       "      <td>73.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>779.000000</td>\n",
       "      <td>779.0</td>\n",
       "      <td>94145.0</td>\n",
       "      <td>94124.67742</td>\n",
       "      <td>94104.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>317.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>24.4</td>\n",
       "      <td>24.274194</td>\n",
       "      <td>24.1</td>\n",
       "      <td>73.8</td>\n",
       "      <td>73.703226</td>\n",
       "      <td>73.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>790.000000</td>\n",
       "      <td>790.0</td>\n",
       "      <td>96678.0</td>\n",
       "      <td>96657.90323</td>\n",
       "      <td>96637.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>24.7</td>\n",
       "      <td>24.519355</td>\n",
       "      <td>24.4</td>\n",
       "      <td>74.7</td>\n",
       "      <td>74.616129</td>\n",
       "      <td>74.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>714.0</td>\n",
       "      <td>713.645161</td>\n",
       "      <td>713.0</td>\n",
       "      <td>96975.0</td>\n",
       "      <td>96955.22581</td>\n",
       "      <td>96934.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>24.7</td>\n",
       "      <td>24.537500</td>\n",
       "      <td>24.4</td>\n",
       "      <td>74.7</td>\n",
       "      <td>74.593750</td>\n",
       "      <td>74.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>742.0</td>\n",
       "      <td>742.000000</td>\n",
       "      <td>742.0</td>\n",
       "      <td>100876.0</td>\n",
       "      <td>100855.50000</td>\n",
       "      <td>100835.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>307.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>24.7</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>24.3</td>\n",
       "      <td>73.9</td>\n",
       "      <td>73.796875</td>\n",
       "      <td>73.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>701.781250</td>\n",
       "      <td>701.0</td>\n",
       "      <td>83567.0</td>\n",
       "      <td>83545.31250</td>\n",
       "      <td>83523.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>287.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X_981      X_982  X_983  X_984      X_985  X_986  X_987  X_988  X_989  \\\n",
       "28    24.6  24.441935   24.3   74.5  74.383871   74.3    1.0    1.0    1.0   \n",
       "33    24.3  24.254839   24.2   73.4  73.303226   73.2    1.0    1.0    1.0   \n",
       "39    24.5  24.341935   24.2   74.0  73.967742   73.9    1.0    1.0    1.0   \n",
       "40    25.1  24.964516   24.8   73.3  73.196774   73.1    1.0    1.0    1.0   \n",
       "41    25.2  25.006452   24.8   73.2  73.129032   73.1    1.0    1.0    1.0   \n",
       "48    24.3  24.148387   24.0   74.3  74.267742   74.2    1.0    1.0    1.0   \n",
       "52    24.3  24.232258   24.1   74.6  74.506452   74.5    1.0    1.0    1.0   \n",
       "57    24.6  24.441935   24.2   74.6  74.512903   74.5    1.0    1.0    1.0   \n",
       "58    24.5  24.290625   24.2   74.1  73.993750   73.9    1.0    1.0    1.0   \n",
       "59    24.5  24.334375   24.1   75.0  74.887500   74.8    1.0    1.0    1.0   \n",
       "64    24.6  24.322581   24.1   73.3  73.200000   73.1    1.0    1.0    1.0   \n",
       "65    24.6  24.396774   24.2   73.7  73.658065   73.6    1.0    1.0    1.0   \n",
       "66    25.4  25.222581   25.0   73.7  73.661290   73.6    1.0    1.0    1.0   \n",
       "69    24.5  24.319355   24.1   74.0  73.974194   73.8    1.0    1.0    1.0   \n",
       "71    24.6  24.437500   24.3   74.4  74.359375   74.3    1.0    1.0    1.0   \n",
       "75    24.4  24.250000   24.1   73.1  73.065625   73.0    1.0    1.0    1.0   \n",
       "77    24.6  24.412903   24.3   73.6  73.477419   73.4    1.0    1.0    1.0   \n",
       "84    25.1  24.958065   24.8   75.1  75.096774   75.0    1.0    1.0    1.0   \n",
       "90    24.4  24.303226   24.1   72.9  72.851613   72.8    1.0    1.0    1.0   \n",
       "94    24.6  24.509677   24.4   74.6  74.493548   74.4    1.0    1.0    1.0   \n",
       "95    24.7  24.529032   24.4   74.4  74.309677   74.2    1.0    1.0    1.0   \n",
       "116   24.4  24.231250   24.0   73.5  73.462500   73.4    1.0    1.0    1.0   \n",
       "118   24.5  24.312903   24.2   73.7  73.612903   73.6    1.0    1.0    1.0   \n",
       "123   24.4  24.300000   24.1   73.5  73.403226   73.4    1.0    1.0    1.0   \n",
       "129   24.5  24.309677   24.2   74.1  74.032258   74.0    1.0    1.0    1.0   \n",
       "179   24.5  24.341935   24.2   74.3  74.248387   74.2    1.0    1.0    1.0   \n",
       "190   24.6  24.393548   24.3   73.5  73.425806   73.4    1.0    1.0    1.0   \n",
       "208   24.4  24.271875   24.1   74.5  74.487500   74.4    1.0    1.0    1.0   \n",
       "220   24.5  24.348387   24.2   74.0  73.896774   73.8    1.0    1.0    1.0   \n",
       "230   24.8  24.606452   24.5   74.6  74.506452   74.5    1.0    1.0    1.0   \n",
       "235   24.6  24.441935   24.3   74.0  73.932258   73.8    1.0    1.0    1.0   \n",
       "239   24.5  24.393548   24.2   74.3  74.219355   74.2    1.0    1.0    1.0   \n",
       "244   24.7  24.483871   24.3   75.0  74.964516   74.9    1.0    1.0    1.0   \n",
       "281   24.7  24.551613   24.4   74.6  74.570968   74.5    1.0    1.0    1.0   \n",
       "283   24.6  24.483871   24.3   74.1  74.006452   73.9    1.0    1.0    1.0   \n",
       "287   24.6  24.458065   24.3   73.8  73.725806   73.7    1.0    1.0    1.0   \n",
       "291   24.7  24.535484   24.4   74.7  74.619355   74.6    1.0    1.0    1.0   \n",
       "292   24.7  24.532258   24.3   74.1  74.090323   74.0    1.0    1.0    1.0   \n",
       "295   24.5  24.406452   24.3   74.2  74.161290   74.1    1.0    1.0    1.0   \n",
       "299   24.7  24.506250   24.3   74.0  73.903125   73.8    1.0    1.0    1.0   \n",
       "300   24.7  24.540625   24.4   74.0  73.931250   73.8    1.0    1.0    1.0   \n",
       "312   24.7  24.409677   24.2   74.3  74.219355   74.2    1.0    1.0    1.0   \n",
       "332   24.9  24.825806   24.7   74.5  74.477419   74.4    1.0    1.0    1.0   \n",
       "334   25.0  24.868750   24.6   74.9  74.759375   74.7    1.0    1.0    1.0   \n",
       "404   25.1  24.980645   24.9   73.6  73.558065   73.4    1.0    1.0    1.0   \n",
       "410   24.7  24.467742   24.4   74.3  74.238710   74.2    1.0    1.0    1.0   \n",
       "436   24.6  24.483871   24.3   74.1  73.993548   73.9    1.0    1.0    1.0   \n",
       "449   24.7  24.522581   24.4   74.6  74.551613   74.5    1.0    1.0    1.0   \n",
       "455   24.6  24.490323   24.3   74.3  74.270968   74.2    1.0    1.0    1.0   \n",
       "456   24.7  24.548387   24.4   74.4  74.309677   74.2    1.0    1.0    1.0   \n",
       "480   24.5  24.367742   24.3   74.2  74.200000   74.2    1.0    1.0    1.0   \n",
       "490   24.6  24.443750   24.3   74.5  74.456250   74.4    1.0    1.0    1.0   \n",
       "491   24.5  24.446875   24.3   74.4  74.309375   74.3    1.0    1.0    1.0   \n",
       "500   24.5  24.277419   24.1   74.7  74.632258   74.6    1.0    1.0    1.0   \n",
       "521   24.5  24.325806   24.2   73.4  73.364516   73.3    1.0    1.0    1.0   \n",
       "530   24.4  24.274194   24.1   73.8  73.703226   73.7    1.0    1.0    1.0   \n",
       "553   24.7  24.519355   24.4   74.7  74.616129   74.5    1.0    1.0    1.0   \n",
       "554   24.7  24.537500   24.4   74.7  74.593750   74.5    1.0    1.0    1.0   \n",
       "584   24.7  24.500000   24.3   73.9  73.796875   73.7    1.0    1.0    1.0   \n",
       "\n",
       "     X_990  X_991  X_992   X_993        X_994   X_995     X_996         X_997  \\\n",
       "28     NaN    NaN    0.0  1507.0  1507.000000  1507.0  180076.0  180054.25810   \n",
       "33     NaN    NaN    0.0   323.0   322.516129   322.0   37342.0   37322.58065   \n",
       "39     NaN    NaN    0.0   258.0   257.935484   257.0   30363.0   30341.58065   \n",
       "40     NaN    NaN    0.0   924.0   924.000000   924.0  115928.0  115908.70970   \n",
       "41     NaN    NaN    0.0   938.0   937.354839   937.0  117438.0  117416.58060   \n",
       "48     NaN    NaN    0.0  1036.0  1036.000000  1036.0  124324.0  124303.93550   \n",
       "52     NaN    NaN    0.0   240.0   240.000000   240.0   29062.0   29042.41935   \n",
       "57     NaN    NaN    0.0  1538.0  1538.000000  1538.0  196685.0  196663.83870   \n",
       "58     NaN    NaN    0.0  1566.0  1566.000000  1566.0  200477.0  200454.40630   \n",
       "59     NaN    NaN    0.0  1624.0  1623.812500  1623.0  207968.0  207947.50000   \n",
       "64     NaN    NaN    0.0  1209.0  1208.419355  1208.0  168716.0  168695.03230   \n",
       "65     NaN    NaN    0.0  1238.0  1238.000000  1238.0  172513.0  172492.77420   \n",
       "66     NaN    NaN    0.0  1419.0  1419.000000  1419.0  208191.0  208169.83870   \n",
       "69     NaN    NaN    0.0   301.0   301.000000   301.0   39780.0   39760.48387   \n",
       "71     NaN    NaN    0.0   380.0   380.000000   380.0   49273.0   49252.00000   \n",
       "75     NaN    NaN    0.0   432.0   432.000000   432.0   64495.0   64473.15625   \n",
       "77     NaN    NaN    0.0  1018.0  1018.000000  1018.0  122391.0  122370.29030   \n",
       "84     NaN    NaN    0.0   341.0   341.000000   341.0   51618.0   51598.09677   \n",
       "90     NaN    NaN    0.0  1301.0  1301.000000  1301.0  164416.0  164395.67740   \n",
       "94     NaN    NaN    0.0   737.0   737.000000   737.0   87100.0   87080.54839   \n",
       "95     NaN    NaN    0.0   750.0   750.000000   750.0   88623.0   88603.16129   \n",
       "116    NaN    NaN    0.0  1057.0  1057.000000  1057.0  137727.0  137706.25000   \n",
       "118    NaN    NaN    0.0  1159.0  1158.741935  1158.0  149805.0  149783.51610   \n",
       "123    NaN    NaN    0.0  1000.0  1000.000000  1000.0  125984.0  125963.35480   \n",
       "129    NaN    NaN    0.0  1000.0   999.580645   999.0  120459.0  120439.29030   \n",
       "179    NaN    NaN    0.0  1616.0  1615.483871  1615.0  191702.0  191681.16130   \n",
       "190    NaN    NaN    0.0  1026.0  1025.612903  1025.0  129259.0  129237.58060   \n",
       "208    NaN    NaN    0.0   300.0   300.000000   300.0   39763.0   39741.53125   \n",
       "220    NaN    NaN    0.0   610.0   610.000000   610.0   71943.0   71921.58065   \n",
       "230    NaN    NaN    0.0  1788.0  1787.354839  1787.0  227395.0  227374.29030   \n",
       "235    NaN    NaN    0.0   942.0   942.000000   942.0  117333.0  117313.41940   \n",
       "239    NaN    NaN    0.0  1411.0  1411.000000  1411.0  173522.0  173500.96770   \n",
       "244    NaN    NaN    0.0  1945.0  1945.000000  1945.0  236437.0  236415.38710   \n",
       "281    NaN    NaN    0.0  1007.0  1007.000000  1007.0  190099.0  190078.96770   \n",
       "283    NaN    NaN    0.0  1022.0  1022.000000  1022.0  191934.0  191914.03230   \n",
       "287    NaN    NaN    0.0   138.0   138.000000   138.0   16556.0   16536.29032   \n",
       "291    NaN    NaN    0.0   516.0   516.000000   516.0   62666.0   62645.90323   \n",
       "292    NaN    NaN    0.0   628.0   628.000000   628.0   75906.0   75884.90323   \n",
       "295    NaN    NaN    0.0  1009.0  1009.000000  1009.0  120043.0  120023.29030   \n",
       "299    NaN    NaN    0.0  1697.0  1696.812500  1696.0  202928.0  202907.37500   \n",
       "300    NaN    NaN    0.0  1713.0  1712.281250  1712.0  204750.0  204728.03130   \n",
       "312    NaN    NaN    0.0   675.0   674.612903   674.0   79669.0   79648.41935   \n",
       "332    NaN    NaN    0.0  1129.0  1129.000000  1129.0  165221.0  165200.22580   \n",
       "334    NaN    NaN    0.0  1137.0  1136.500000  1136.0  166077.0  166056.25000   \n",
       "404    NaN    NaN    0.0   433.0   432.870968   432.0   75956.0   75935.03226   \n",
       "410    NaN    NaN    0.0   224.0   224.000000   224.0   26546.0   26525.29032   \n",
       "436    NaN    NaN    0.0  1268.0  1268.000000  1268.0  152525.0  152503.64520   \n",
       "449    NaN    NaN    0.0  1735.0  1734.483871  1734.0  236085.0  236064.16130   \n",
       "455    NaN    NaN    0.0   418.0   417.806452   417.0   49132.0   49110.54839   \n",
       "456    NaN    NaN    0.0   431.0   431.000000   431.0   50659.0   50639.09677   \n",
       "480    NaN    NaN    0.0  1175.0  1175.000000  1175.0  145708.0  145688.09680   \n",
       "490    NaN    NaN    0.0  1191.0  1191.000000  1191.0  162258.0  162237.81250   \n",
       "491    NaN    NaN    0.0  1204.0  1204.000000  1204.0  163784.0  163763.40630   \n",
       "500    NaN    NaN    0.0  1107.0  1107.000000  1107.0  138557.0  138536.90320   \n",
       "521    NaN    NaN    0.0   779.0   779.000000   779.0   94145.0   94124.67742   \n",
       "530    NaN    NaN    0.0   790.0   790.000000   790.0   96678.0   96657.90323   \n",
       "553    NaN    NaN    0.0   714.0   713.645161   713.0   96975.0   96955.22581   \n",
       "554    NaN    NaN    0.0   742.0   742.000000   742.0  100876.0  100855.50000   \n",
       "584    NaN    NaN    0.0   702.0   701.781250   701.0   83567.0   83545.31250   \n",
       "\n",
       "        X_998  X_999  X_1000  \n",
       "28   180034.0  541.0   541.0  \n",
       "33    37302.0  107.0   107.0  \n",
       "39    30322.0   92.0    92.0  \n",
       "40   115888.0  331.0   331.0  \n",
       "41   117397.0  336.0   336.0  \n",
       "48   124283.0  402.0   402.0  \n",
       "52    29021.0   91.0    91.0  \n",
       "57   196644.0  555.0   555.0  \n",
       "58   200432.0  565.0   565.0  \n",
       "59   207927.0  586.0   586.0  \n",
       "64   168675.0  436.0   436.0  \n",
       "65   172472.0  446.0   446.0  \n",
       "66   208150.0  510.0   510.0  \n",
       "69    39739.0  110.0   110.0  \n",
       "71    49231.0  139.0   139.0  \n",
       "75    64451.0  154.0   153.0  \n",
       "77   122350.0  418.0   418.0  \n",
       "84    51577.0  156.0   156.0  \n",
       "90   164374.0  506.0   505.0  \n",
       "94    87059.0  263.0   263.0  \n",
       "95    88582.0  268.0   268.0  \n",
       "116  137686.0  420.0   420.0  \n",
       "118  149764.0  461.0   461.0  \n",
       "123  125944.0  417.0   417.0  \n",
       "129  120418.0  423.0   422.0  \n",
       "179  191661.0  634.0   634.0  \n",
       "190  129218.0  399.0   399.0  \n",
       "208   39720.0  384.0   383.0  \n",
       "220   71902.0  240.0   240.0  \n",
       "230  227354.0  708.0   708.0  \n",
       "235  117292.0  369.0   368.0  \n",
       "239  173481.0  555.0   555.0  \n",
       "244  236395.0  765.0   764.0  \n",
       "281  190059.0  359.0   359.0  \n",
       "283  191893.0  365.0   365.0  \n",
       "287   16515.0   50.0    50.0  \n",
       "291   62625.0  185.0   185.0  \n",
       "292   75865.0  225.0   225.0  \n",
       "295  120002.0  360.0   360.0  \n",
       "299  202887.0  607.0   607.0  \n",
       "300  204706.0  613.0   612.0  \n",
       "312   79629.0  243.0   242.0  \n",
       "332  165180.0  408.0   408.0  \n",
       "334  166036.0  411.0   411.0  \n",
       "404   75915.0  159.0   158.0  \n",
       "410   26506.0   81.0    81.0  \n",
       "436  152484.0  468.0   468.0  \n",
       "449  236045.0  631.0   631.0  \n",
       "455   49091.0  150.0   150.0  \n",
       "456   50618.0  155.0   155.0  \n",
       "480  145667.0  503.0   502.0  \n",
       "490  162217.0  443.0   443.0  \n",
       "491  163743.0  448.0   448.0  \n",
       "500  138516.0  405.0   405.0  \n",
       "521   94104.0  317.0   317.0  \n",
       "530   96637.0  458.0   457.0  \n",
       "553   96934.0  295.0   295.0  \n",
       "554  100835.0  307.0   307.0  \n",
       "584   83523.0  287.0   287.0  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_pl = train_df[(train_df['PRODUCT_CODE']=='A_31') & (train_df['LINE']=='T010305')]\n",
    "#train_df_pl = train_df[train_df['PRODUCT_CODE']=='A_31']\n",
    "train_df_pl.iloc[:,986:1006]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "33a5e59b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_331</th>\n",
       "      <th>X_332</th>\n",
       "      <th>X_333</th>\n",
       "      <th>X_334</th>\n",
       "      <th>X_335</th>\n",
       "      <th>X_336</th>\n",
       "      <th>X_337</th>\n",
       "      <th>X_338</th>\n",
       "      <th>X_339</th>\n",
       "      <th>X_340</th>\n",
       "      <th>X_341</th>\n",
       "      <th>X_342</th>\n",
       "      <th>X_343</th>\n",
       "      <th>X_344</th>\n",
       "      <th>X_345</th>\n",
       "      <th>X_346</th>\n",
       "      <th>X_347</th>\n",
       "      <th>X_348</th>\n",
       "      <th>X_349</th>\n",
       "      <th>X_350</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00061</td>\n",
       "      <td>0.00095</td>\n",
       "      <td>0.00049</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>127.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00086</td>\n",
       "      <td>0.00140</td>\n",
       "      <td>0.00081</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00077</td>\n",
       "      <td>0.00130</td>\n",
       "      <td>0.00072</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00083</td>\n",
       "      <td>0.00091</td>\n",
       "      <td>0.00081</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>127.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00083</td>\n",
       "      <td>0.00110</td>\n",
       "      <td>0.00078</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00079</td>\n",
       "      <td>0.00120</td>\n",
       "      <td>0.00074</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00078</td>\n",
       "      <td>0.00130</td>\n",
       "      <td>0.00071</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00076</td>\n",
       "      <td>0.00130</td>\n",
       "      <td>0.00051</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00081</td>\n",
       "      <td>0.00140</td>\n",
       "      <td>0.00076</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00082</td>\n",
       "      <td>0.00140</td>\n",
       "      <td>0.00053</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     X_331  X_332  X_333  X_334  X_335  X_336  X_337  X_338  X_339  X_340  \\\n",
       "27   128.0  128.0  127.0  130.0   36.0  999.0    NaN    NaN    NaN   0.22   \n",
       "31   127.0  128.0  127.0  130.0   37.0  999.0    NaN    NaN    NaN   0.22   \n",
       "32   128.0  128.0  127.0  130.0   35.0  999.0    NaN    NaN    NaN   0.22   \n",
       "38   128.0  128.0  127.0  130.0   36.0  999.0    NaN    NaN    NaN   0.22   \n",
       "47   127.0  128.0  127.0  130.0   36.0  999.0    NaN    NaN    NaN   0.22   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "479  128.0  128.0  127.0  130.0   36.0  999.0    NaN    NaN    NaN   0.22   \n",
       "501  128.0  128.0  128.0  130.0   36.0  999.0    NaN    NaN    NaN   0.22   \n",
       "523  128.0  128.0  127.0  130.0   36.0  999.0    NaN    NaN    NaN   0.22   \n",
       "531  128.0  128.0  127.0  130.0   35.0  999.0    NaN    NaN    NaN   0.22   \n",
       "585  128.0  128.0  127.0  130.0   37.0  999.0    NaN    NaN    NaN   0.22   \n",
       "\n",
       "     X_341  X_342  X_343    X_344    X_345    X_346  X_347     X_348  \\\n",
       "27    0.23   0.22    2.0  0.00061  0.00095  0.00049   18.0  0.000084   \n",
       "31    0.23   0.22    2.0  0.00086  0.00140  0.00081   18.0  0.000086   \n",
       "32    0.23   0.22    2.0  0.00077  0.00130  0.00072   18.0  0.000088   \n",
       "38    0.22   0.22    2.0  0.00083  0.00091  0.00081   18.0  0.000093   \n",
       "47    0.23   0.22    2.0  0.00083  0.00110  0.00078   18.0  0.000089   \n",
       "..     ...    ...    ...      ...      ...      ...    ...       ...   \n",
       "479   0.23   0.22    2.0  0.00079  0.00120  0.00074   18.0  0.000088   \n",
       "501   0.23   0.22    2.0  0.00078  0.00130  0.00071   18.0  0.000095   \n",
       "523   0.23   0.22    2.0  0.00076  0.00130  0.00051   18.0  0.000094   \n",
       "531   0.23   0.22    2.0  0.00081  0.00140  0.00076   18.0  0.000089   \n",
       "585   0.23   0.22    2.0  0.00082  0.00140  0.00053   18.0  0.000087   \n",
       "\n",
       "        X_349     X_350  \n",
       "27   0.000100  0.000062  \n",
       "31   0.000098  0.000061  \n",
       "32   0.000100  0.000064  \n",
       "38   0.000110  0.000068  \n",
       "47   0.000100  0.000067  \n",
       "..        ...       ...  \n",
       "479  0.000097  0.000068  \n",
       "501  0.000110  0.000065  \n",
       "523  0.000110  0.000065  \n",
       "531  0.000099  0.000067  \n",
       "585  0.000097  0.000063  \n",
       "\n",
       "[70 rows x 20 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_pl = train_df[(train_df['PRODUCT_CODE']=='A_31') & (train_df['LINE']=='T010306')] #70row\n",
    "train_df_pl.iloc[:,336:356] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "59a84936",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_241</th>\n",
       "      <th>X_242</th>\n",
       "      <th>X_243</th>\n",
       "      <th>X_244</th>\n",
       "      <th>X_245</th>\n",
       "      <th>X_246</th>\n",
       "      <th>X_247</th>\n",
       "      <th>X_248</th>\n",
       "      <th>X_249</th>\n",
       "      <th>X_250</th>\n",
       "      <th>X_251</th>\n",
       "      <th>X_252</th>\n",
       "      <th>X_253</th>\n",
       "      <th>X_254</th>\n",
       "      <th>X_255</th>\n",
       "      <th>X_256</th>\n",
       "      <th>X_257</th>\n",
       "      <th>X_258</th>\n",
       "      <th>X_259</th>\n",
       "      <th>X_260</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>999.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>999.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>999.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>999.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>999.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>999.0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>35.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>999.0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>35.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>999.0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>35.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>999.0</td>\n",
       "      <td>35.7</td>\n",
       "      <td>35.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>999.0</td>\n",
       "      <td>35.7</td>\n",
       "      <td>35.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     X_241  X_242  X_243  X_244  X_245  X_246  X_247  X_248  X_249  X_250  \\\n",
       "0    999.0   35.0   35.0    3.0    3.0    NaN    NaN    NaN    NaN    NaN   \n",
       "2    999.0   35.0   35.0    3.0    3.0    NaN    NaN    NaN    NaN    NaN   \n",
       "4    999.0   35.0   35.0    3.0    3.0    NaN    NaN    NaN    NaN    NaN   \n",
       "6    999.0   35.0   35.0    3.0    3.0    NaN    NaN    NaN    NaN    NaN   \n",
       "8    999.0   35.0   35.0    3.0    3.0    NaN    NaN    NaN    NaN    NaN   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "581  999.0   35.3   35.3    3.0    3.0    NaN    NaN    NaN    NaN    NaN   \n",
       "582  999.0   35.3   35.3    3.0    3.0    NaN    NaN    NaN    NaN    NaN   \n",
       "583  999.0   35.3   35.3    3.0    3.0    NaN    NaN    NaN    NaN    NaN   \n",
       "594  999.0   35.7   35.7    3.0    3.0    NaN    NaN    NaN    NaN    NaN   \n",
       "595  999.0   35.7   35.7    3.0    3.0    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "     X_251  X_252  X_253  X_254  X_255  X_256  X_257  X_258  X_259  X_260  \n",
       "0      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "2      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "4      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "6      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "8      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "581    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "582    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "583    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "594    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "595    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "\n",
       "[78 rows x 20 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_pl = train_df[(train_df['PRODUCT_CODE']=='A_31') & (train_df['LINE']=='T050304')] #78rows\n",
    "train_df_pl.iloc[:,246:266] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ae590c86",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_241</th>\n",
       "      <th>X_242</th>\n",
       "      <th>X_243</th>\n",
       "      <th>X_244</th>\n",
       "      <th>X_245</th>\n",
       "      <th>X_246</th>\n",
       "      <th>X_247</th>\n",
       "      <th>X_248</th>\n",
       "      <th>X_249</th>\n",
       "      <th>X_250</th>\n",
       "      <th>X_251</th>\n",
       "      <th>X_252</th>\n",
       "      <th>X_253</th>\n",
       "      <th>X_254</th>\n",
       "      <th>X_255</th>\n",
       "      <th>X_256</th>\n",
       "      <th>X_257</th>\n",
       "      <th>X_258</th>\n",
       "      <th>X_259</th>\n",
       "      <th>X_260</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>999.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>999.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>999.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>999.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>999.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>999.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>999.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>999.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>999.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>999.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>999.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>999.0</td>\n",
       "      <td>36.1</td>\n",
       "      <td>36.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>999.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>999.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>999.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>999.0</td>\n",
       "      <td>35.1</td>\n",
       "      <td>35.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>999.0</td>\n",
       "      <td>34.8</td>\n",
       "      <td>34.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>999.0</td>\n",
       "      <td>34.9</td>\n",
       "      <td>34.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>999.0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>35.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>999.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>999.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>999.0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>35.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>999.0</td>\n",
       "      <td>34.8</td>\n",
       "      <td>34.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>999.0</td>\n",
       "      <td>35.4</td>\n",
       "      <td>35.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>999.0</td>\n",
       "      <td>33.8</td>\n",
       "      <td>33.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>999.0</td>\n",
       "      <td>33.8</td>\n",
       "      <td>33.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>999.0</td>\n",
       "      <td>34.6</td>\n",
       "      <td>34.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>999.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>999.0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>35.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>999.0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>35.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>999.0</td>\n",
       "      <td>35.6</td>\n",
       "      <td>35.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>999.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>999.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>999.0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>35.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>999.0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>35.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>999.0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>35.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>999.0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>35.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>999.0</td>\n",
       "      <td>34.3</td>\n",
       "      <td>34.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>999.0</td>\n",
       "      <td>34.3</td>\n",
       "      <td>34.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>999.0</td>\n",
       "      <td>34.7</td>\n",
       "      <td>34.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>999.0</td>\n",
       "      <td>34.7</td>\n",
       "      <td>34.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>999.0</td>\n",
       "      <td>34.9</td>\n",
       "      <td>34.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X_241  X_242  X_243  X_244  X_245  X_246  X_247  X_248  X_249  X_250  \\\n",
       "1    999.0   36.0   36.0    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "3    999.0   36.0   36.0    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "5    999.0   36.0   36.0    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "7    999.0   36.0   36.0    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "9    999.0   36.0   36.0    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "11   999.0   36.0   36.0    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "13   999.0   36.0   36.0    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "15   999.0   36.0   36.0    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "17   999.0   36.0   36.0    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "19   999.0   36.0   36.0    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "24   999.0   34.0   34.0    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "35   999.0   36.1   36.1    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "81   999.0   35.0   35.0    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "82   999.0   35.0   35.0    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "187  999.0   34.0   34.0    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "195  999.0   35.1   35.1    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "198  999.0   34.8   34.8    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "256  999.0   34.9   34.9    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "261  999.0   35.9   35.9    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "296  999.0   36.0   36.0    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "298  999.0   36.0   36.0    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "307  999.0   35.5   35.5    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "316  999.0   34.8   34.8    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "336  999.0   35.4   35.4    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "355  999.0   33.8   33.8    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "356  999.0   33.8   33.8    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "369  999.0   34.6   34.6    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "432  999.0   35.0   35.0    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "444  999.0   35.3   35.3    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "454  999.0   35.5   35.5    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "477  999.0   35.6   35.6    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "541  999.0   36.0   36.0    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "542  999.0   36.0   36.0    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "543  999.0   35.9   35.9    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "544  999.0   35.9   35.9    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "545  999.0   35.9   35.9    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "546  999.0   35.9   35.9    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "549  999.0   34.3   34.3    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "550  999.0   34.3   34.3    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "551  999.0   34.7   34.7    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "552  999.0   34.7   34.7    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "555  999.0   34.9   34.9    3.0    6.0    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "     X_251  X_252  X_253  X_254  X_255  X_256  X_257  X_258  X_259  X_260  \n",
       "1      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "3      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "5      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "7      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "9      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "11     NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "13     NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "15     NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "17     NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "19     NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "24     NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "35     NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "81     NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "82     NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "187    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "195    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "198    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "256    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "261    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "296    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "298    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "307    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "316    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "336    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "355    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "356    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "369    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "432    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "444    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "454    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "477    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "541    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "542    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "543    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "544    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "545    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "546    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "549    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "550    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "551    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "552    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "555    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_pl = train_df[(train_df['PRODUCT_CODE']=='A_31') & (train_df['LINE']=='T050307')]\n",
    "train_df_pl.iloc[:,246:266] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7269622f",
   "metadata": {},
   "source": [
    "['T050304', 'T050307', 'T100304', 'T100306', 'T010306', 'T010305']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ed2c0d91",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_85</th>\n",
       "      <th>X_86</th>\n",
       "      <th>X_87</th>\n",
       "      <th>X_88</th>\n",
       "      <th>X_89</th>\n",
       "      <th>X_90</th>\n",
       "      <th>X_91</th>\n",
       "      <th>X_92</th>\n",
       "      <th>X_93</th>\n",
       "      <th>X_94</th>\n",
       "      <th>X_95</th>\n",
       "      <th>X_96</th>\n",
       "      <th>X_97</th>\n",
       "      <th>X_98</th>\n",
       "      <th>X_99</th>\n",
       "      <th>X_100</th>\n",
       "      <th>X_101</th>\n",
       "      <th>X_102</th>\n",
       "      <th>X_103</th>\n",
       "      <th>X_104</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     X_85   X_86   X_87   X_88   X_89  X_90   X_91  X_92  X_93  X_94  X_95  \\\n",
       "22    0.0  130.0  130.0  130.0  130.0  37.0  999.0  28.0   NaN   NaN   NaN   \n",
       "23    0.0  130.0  130.0  130.0  130.0  37.0  999.0  28.0   NaN   NaN   NaN   \n",
       "25    0.0  130.0  130.0  130.0  130.0  37.0  999.0  28.0   NaN   NaN   NaN   \n",
       "29    0.0  130.0  130.0  130.0  130.0  37.0  999.0  28.0   NaN   NaN   NaN   \n",
       "37    0.0  130.0  130.0  130.0  130.0  37.0  999.0  28.0   NaN   NaN   NaN   \n",
       "..    ...    ...    ...    ...    ...   ...    ...   ...   ...   ...   ...   \n",
       "371   0.0  130.0  130.0  130.0  130.0  36.0  999.0  28.0   NaN   NaN   NaN   \n",
       "372   0.0  130.0  130.0  130.0  130.0  36.0  999.0  28.0   NaN   NaN   NaN   \n",
       "377   0.0  130.0  130.0  130.0  130.0  36.0  999.0  28.0   NaN   NaN   NaN   \n",
       "378   0.0  130.0  130.0  130.0  130.0  36.0  999.0  28.0   NaN   NaN   NaN   \n",
       "379   0.0  130.0  130.0  130.0  130.0  36.0  999.0  28.0   NaN   NaN   NaN   \n",
       "\n",
       "     X_96    X_97    X_98    X_99  X_100     X_101     X_102     X_103  X_104  \n",
       "22    2.0  0.0013  0.0013  0.0012   18.0  0.000043  0.000057  0.000030    NaN  \n",
       "23    2.0  0.0013  0.0013  0.0012   18.0  0.000042  0.000053  0.000027    NaN  \n",
       "25    2.0  0.0013  0.0014  0.0013   18.0  0.000037  0.000047  0.000028    NaN  \n",
       "29    2.0  0.0013  0.0014  0.0012   18.0  0.000045  0.000074  0.000029    NaN  \n",
       "37    2.0  0.0013  0.0013  0.0013   18.0  0.000037  0.000047  0.000027    NaN  \n",
       "..    ...     ...     ...     ...    ...       ...       ...       ...    ...  \n",
       "371   2.0  0.0013  0.0013  0.0012   18.0  0.000038  0.000053  0.000022    NaN  \n",
       "372   2.0  0.0013  0.0013  0.0012   18.0  0.000034  0.000058  0.000021    NaN  \n",
       "377   2.0  0.0013  0.0013  0.0012   18.0  0.000033  0.000050  0.000022    NaN  \n",
       "378   2.0  0.0013  0.0013  0.0012   18.0  0.000033  0.000043  0.000021    NaN  \n",
       "379   2.0  0.0013  0.0013  0.0012   18.0  0.000038  0.000050  0.000027    NaN  \n",
       "\n",
       "[100 rows x 20 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_pl = train_df[(train_df['PRODUCT_CODE']=='T_31') & (train_df['LINE']=='T100304')]\n",
    "train_df_pl.iloc[0:100, 90:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a5982002",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_101</th>\n",
       "      <th>X_102</th>\n",
       "      <th>X_103</th>\n",
       "      <th>X_104</th>\n",
       "      <th>X_105</th>\n",
       "      <th>X_106</th>\n",
       "      <th>X_107</th>\n",
       "      <th>X_108</th>\n",
       "      <th>X_109</th>\n",
       "      <th>X_110</th>\n",
       "      <th>X_111</th>\n",
       "      <th>X_112</th>\n",
       "      <th>X_113</th>\n",
       "      <th>X_114</th>\n",
       "      <th>X_115</th>\n",
       "      <th>X_116</th>\n",
       "      <th>X_117</th>\n",
       "      <th>X_118</th>\n",
       "      <th>X_119</th>\n",
       "      <th>X_120</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>34.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>34.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>34.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>34.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>34.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>34.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>34.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>34.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>34.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        X_101     X_102     X_103  X_104     X_105     X_106     X_107  X_108  \\\n",
       "26   0.000063  0.000072  0.000044   28.0  0.000013  0.000015  0.000004   32.0   \n",
       "30   0.000069  0.000082  0.000044   28.0  0.000012  0.000014  0.000004   32.0   \n",
       "36   0.000061  0.000070  0.000042   28.0  0.000011  0.000014  0.000004   32.0   \n",
       "42   0.000063  0.000071  0.000043   28.0  0.000010  0.000012  0.000005   32.0   \n",
       "43   0.000061  0.000069  0.000046   28.0  0.000009  0.000012  0.000005   32.0   \n",
       "..        ...       ...       ...    ...       ...       ...       ...    ...   \n",
       "364  0.000058  0.000068  0.000040   28.0  0.000008  0.000010  0.000003   32.0   \n",
       "365  0.000059  0.000069  0.000040   28.0  0.000006  0.000008  0.000003   32.0   \n",
       "373  0.000059  0.000068  0.000042   28.0  0.000009  0.000011  0.000003   32.0   \n",
       "374  0.000059  0.000069  0.000041   28.0  0.000009  0.000010  0.000003   32.0   \n",
       "376  0.000056  0.000066  0.000041   28.0  0.000008  0.000011  0.000003   32.0   \n",
       "\n",
       "        X_109     X_110     X_111  X_112  X_113  X_114  X_115  X_116  \\\n",
       "26   0.000004  0.000004  0.000003   40.0    NaN    NaN    NaN   44.0   \n",
       "30   0.000003  0.000005  0.000003   40.0    NaN    NaN    NaN   44.0   \n",
       "36   0.000004  0.000004  0.000003   40.0    NaN    NaN    NaN   44.0   \n",
       "42   0.000003  0.000005  0.000003   40.0    NaN    NaN    NaN   44.0   \n",
       "43   0.000004  0.000004  0.000003   40.0    NaN    NaN    NaN   44.0   \n",
       "..        ...       ...       ...    ...    ...    ...    ...    ...   \n",
       "364  0.000003  0.000005  0.000003   40.0    NaN    NaN    NaN   44.0   \n",
       "365  0.000003  0.000004  0.000003   40.0    NaN    NaN    NaN   44.0   \n",
       "373  0.000003  0.000004  0.000003   40.0    NaN    NaN    NaN   44.0   \n",
       "374  0.000003  0.000005  0.000003   40.0    NaN    NaN    NaN   44.0   \n",
       "376  0.000004  0.000005  0.000003   40.0    NaN    NaN    NaN   44.0   \n",
       "\n",
       "        X_117     X_118     X_119  X_120  \n",
       "26   0.000037  0.000038  0.000032   34.4  \n",
       "30   0.000036  0.000040  0.000035   34.4  \n",
       "36   0.000037  0.000039  0.000034   34.3  \n",
       "42   0.000036  0.000037  0.000032   34.3  \n",
       "43   0.000037  0.000038  0.000035   34.4  \n",
       "..        ...       ...       ...    ...  \n",
       "364  0.000034  0.000034  0.000031   34.7  \n",
       "365  0.000033  0.000034  0.000032   34.8  \n",
       "373  0.000033  0.000034  0.000030   34.9  \n",
       "374  0.000032  0.000034  0.000030   34.8  \n",
       "376  0.000033  0.000036  0.000031   34.8  \n",
       "\n",
       "[100 rows x 20 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_pl = train_df[(train_df['PRODUCT_CODE']=='T_31') & (train_df['LINE']=='T100306')]\n",
    "train_df_pl.iloc[:100,106:126]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1e2e89fd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_112</th>\n",
       "      <th>X_113</th>\n",
       "      <th>X_114</th>\n",
       "      <th>X_115</th>\n",
       "      <th>X_116</th>\n",
       "      <th>X_117</th>\n",
       "      <th>X_118</th>\n",
       "      <th>X_119</th>\n",
       "      <th>X_120</th>\n",
       "      <th>X_121</th>\n",
       "      <th>X_122</th>\n",
       "      <th>X_123</th>\n",
       "      <th>X_124</th>\n",
       "      <th>X_125</th>\n",
       "      <th>X_126</th>\n",
       "      <th>X_127</th>\n",
       "      <th>X_128</th>\n",
       "      <th>X_129</th>\n",
       "      <th>X_130</th>\n",
       "      <th>X_131</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>34.4</td>\n",
       "      <td>34.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19461.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4905.0</td>\n",
       "      <td>4905.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>34.4</td>\n",
       "      <td>34.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19472.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4931.0</td>\n",
       "      <td>4931.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>34.3</td>\n",
       "      <td>34.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20174.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6626.0</td>\n",
       "      <td>6626.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X_112  X_113  X_114  X_115  X_116     X_117     X_118     X_119  X_120  \\\n",
       "570   40.0    NaN    NaN    NaN   44.0  0.000034  0.000036  0.000032   34.4   \n",
       "572   40.0    NaN    NaN    NaN   44.0  0.000034  0.000035  0.000032   34.4   \n",
       "597   40.0    NaN    NaN    NaN   44.0  0.000034  0.000037  0.000031   34.3   \n",
       "\n",
       "     X_121  X_122    X_123  X_124  X_125   X_126   X_127  X_128  X_129  X_130  \\\n",
       "570   34.1    2.0  19461.0    NaN    NaN  4905.0  4905.0    NaN    NaN    NaN   \n",
       "572   34.1    2.0  19472.0    NaN    NaN  4931.0  4931.0    NaN    NaN    NaN   \n",
       "597   34.1    2.0  20174.0    NaN    NaN  6626.0  6626.0    NaN    NaN    NaN   \n",
       "\n",
       "     X_131  \n",
       "570    NaN  \n",
       "572    NaN  \n",
       "597    NaN  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_pl = train_df[(train_df['PRODUCT_CODE']=='O_31') & (train_df['LINE']=='T100306')]\n",
    "train_df_pl.iloc[:,117:137]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "35264d20",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_303</th>\n",
       "      <th>X_304</th>\n",
       "      <th>X_305</th>\n",
       "      <th>X_306</th>\n",
       "      <th>X_307</th>\n",
       "      <th>X_308</th>\n",
       "      <th>X_309</th>\n",
       "      <th>X_310</th>\n",
       "      <th>X_311</th>\n",
       "      <th>X_312</th>\n",
       "      <th>X_313</th>\n",
       "      <th>X_314</th>\n",
       "      <th>X_315</th>\n",
       "      <th>X_316</th>\n",
       "      <th>X_317</th>\n",
       "      <th>X_318</th>\n",
       "      <th>X_319</th>\n",
       "      <th>X_320</th>\n",
       "      <th>X_321</th>\n",
       "      <th>X_322</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X_303  X_304  X_305  X_306  X_307  X_308  X_309  X_310  X_311  X_312  \\\n",
       "569    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "571    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "596    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "     X_313  X_314  X_315  X_316  X_317  X_318  X_319  X_320  X_321  X_322  \n",
       "569    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "571    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "596    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_pl = train_df[(train_df['PRODUCT_CODE']=='O_31') & (train_df['LINE']=='T100304')]\n",
    "train_df_pl.iloc[0:100, 308:328]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "03c594a0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_303</th>\n",
       "      <th>X_304</th>\n",
       "      <th>X_305</th>\n",
       "      <th>X_306</th>\n",
       "      <th>X_307</th>\n",
       "      <th>X_308</th>\n",
       "      <th>X_309</th>\n",
       "      <th>X_310</th>\n",
       "      <th>X_311</th>\n",
       "      <th>X_312</th>\n",
       "      <th>X_313</th>\n",
       "      <th>X_314</th>\n",
       "      <th>X_315</th>\n",
       "      <th>X_316</th>\n",
       "      <th>X_317</th>\n",
       "      <th>X_318</th>\n",
       "      <th>X_319</th>\n",
       "      <th>X_320</th>\n",
       "      <th>X_321</th>\n",
       "      <th>X_322</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     X_303  X_304  X_305  X_306  X_307  X_308  X_309  X_310  X_311  X_312  \\\n",
       "22     NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "23     NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "25     NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "29     NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "37     NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "371    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "372    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "377    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "378    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "379    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "     X_313  X_314  X_315  X_316  X_317  X_318  X_319  X_320  X_321  X_322  \n",
       "22     NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "23     NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "25     NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "29     NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "37     NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "371    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "372    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "377    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "378    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "379    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "\n",
       "[100 rows x 20 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_pl = train_df[(train_df['PRODUCT_CODE']=='T_31') & (train_df['LINE']=='T100304')]\n",
    "train_df_pl.iloc[0:100, 308:328]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8c7839",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "데이터 전처리(Data preprocessing)의 목적은 \n",
    "\n",
    "주어진원본 데이터를 신경망에 적용하기 쉽도록 만드는 것이다.\n",
    "\n",
    "벡터화(vectorization), 정규화(normalization), \n",
    "\n",
    "특성 추출(Feature Engineering)등이 포함된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "206b9d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_a = train_df[train_df['PRODUCT_CODE']== 'A_31'] #4개의 라인\n",
    "# train_df_t = train_df[train_df['PRODUCT_CODE']== 'T_31'] #2개의 라인\n",
    "# train_df_o = train_df[train_df['PRODUCT_CODE']== 'O_31'] #2개의 라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "111b5807",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Y_Class'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/pas/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pas/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pas/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Y_Class'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rc/3jzqjhp56_v2qxb49fkb1x880000gn/T/ipykernel_62072/2517264462.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_df0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y_Class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#4개의 라인\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_df1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y_Class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#2개의 라인\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_df2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y_Class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#2개의 라인\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pas/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pas/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Y_Class'"
     ]
    }
   ],
   "source": [
    "# test_df0 = test_df[test_df['Y_Class']== 0] #4개의 라인\n",
    "# test_df1 = test_df[test_df['Y_Class']== 1] #2개의 라인\n",
    "# test_df2 = test_df[test_df['Y_Class']== 2] #2개의 라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4561b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분명 제품 별로 측정하는 값 종류가 다를 것이다. 그래도 아예 없는 값으로 만들어주기 위해 -100, -200을 넣는 것 보다 그냥 다른 제품의 것을 넣어보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "90a3678e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#값이 있어야 하는 결측치 채우기함수\n",
    "def fill_nan_med(df):\n",
    "    for col in df.columns[-2875:]:\n",
    "        if df[col].isnull().sum() >= 1: #한 행에서 결측치가 하나라도 있다면,\n",
    "            nan_lst = list(df[df[col].isnull()==True].index)\n",
    "            v010 = df[col][(df['LINE']=='T010305')&(df['LINE']=='T010306')].median()\n",
    "            v050 = df[col][(df['LINE']=='T050304')&(df['LINE']=='T050307')].median()\n",
    "            v100 = df[col][(df['LINE']=='T100304')&(df['LINE']=='T100306')].median()\n",
    "            for j in nan_lst: #j들은 value값이 nan인 index들. index들을 돌면서 \n",
    "                if df['LINE'][j]=='T010305' or df['LINE'][j]=='T010306':\n",
    "                    df[col][j] = v010\n",
    "                if df['LINE'][j]=='T050304' or df['LINE'][j]=='T050307':\n",
    "                    df[col][j] = v050\n",
    "                if df['LINE'][j]=='T100304' or df['LINE'][j]=='T100306':\n",
    "                    df[col][j] = v100\n",
    "    fill_df = df\n",
    "    return fill_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "acf717c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan_mean(df):\n",
    "    for col in df.columns[-2875:]:\n",
    "        if df[col].isnull().sum() >= 1: #한 행에서 결측치가 하나라도 있다면,\n",
    "            nan_lst = list(df[df[col].isnull()==True].index)\n",
    "            for j in nan_lst: #j들은 value값이 nan인 index들. index들을 돌면서 \n",
    "                df[col][j] = df[col].mean()\n",
    "    fill_df = df\n",
    "    return fill_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "765442cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 699.330543756485\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train_df = fill_nan_med(train_df)\n",
    "test_df = fill_nan_med(test_df)\n",
    "end = time.time()\n",
    "print(f'time elapsed: {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5eb7d4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 715.0176129341125\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train_df = fill_nan_mean(train_df)\n",
    "test_df = fill_nan_mean(test_df)\n",
    "end = time.time()\n",
    "print(f'time elapsed: {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0f918c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_2831</th>\n",
       "      <th>X_2832</th>\n",
       "      <th>X_2833</th>\n",
       "      <th>X_2834</th>\n",
       "      <th>X_2835</th>\n",
       "      <th>X_2836</th>\n",
       "      <th>X_2837</th>\n",
       "      <th>X_2838</th>\n",
       "      <th>X_2839</th>\n",
       "      <th>X_2840</th>\n",
       "      <th>X_2841</th>\n",
       "      <th>X_2842</th>\n",
       "      <th>X_2843</th>\n",
       "      <th>X_2844</th>\n",
       "      <th>X_2845</th>\n",
       "      <th>X_2846</th>\n",
       "      <th>X_2847</th>\n",
       "      <th>X_2848</th>\n",
       "      <th>X_2849</th>\n",
       "      <th>X_2850</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.3000</td>\n",
       "      <td>58.70</td>\n",
       "      <td>55.400000</td>\n",
       "      <td>50.5000</td>\n",
       "      <td>50.5000</td>\n",
       "      <td>50.100000</td>\n",
       "      <td>9.040000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.020000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>40.060000</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.200000</td>\n",
       "      <td>47.094444</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>32.722222</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.4000</td>\n",
       "      <td>61.10</td>\n",
       "      <td>56.400000</td>\n",
       "      <td>52.0000</td>\n",
       "      <td>52.0000</td>\n",
       "      <td>51.900000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.050000</td>\n",
       "      <td>36.540000</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.100000</td>\n",
       "      <td>47.084906</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>30.849057</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.3000</td>\n",
       "      <td>58.70</td>\n",
       "      <td>55.400000</td>\n",
       "      <td>50.5000</td>\n",
       "      <td>50.5000</td>\n",
       "      <td>50.100000</td>\n",
       "      <td>9.040000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.020000</td>\n",
       "      <td>6.520000</td>\n",
       "      <td>40.050000</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.200000</td>\n",
       "      <td>47.088679</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>30.603774</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.4000</td>\n",
       "      <td>61.10</td>\n",
       "      <td>56.400000</td>\n",
       "      <td>52.0000</td>\n",
       "      <td>52.0000</td>\n",
       "      <td>51.900000</td>\n",
       "      <td>7.490000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.010000</td>\n",
       "      <td>7.030000</td>\n",
       "      <td>40.030000</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.200000</td>\n",
       "      <td>47.105660</td>\n",
       "      <td>46.900000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>32.698113</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.3000</td>\n",
       "      <td>58.70</td>\n",
       "      <td>55.400000</td>\n",
       "      <td>50.5000</td>\n",
       "      <td>50.5000</td>\n",
       "      <td>50.100000</td>\n",
       "      <td>9.040000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.030000</td>\n",
       "      <td>6.520000</td>\n",
       "      <td>40.070000</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.200000</td>\n",
       "      <td>47.107407</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>32.888889</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>53.5325</td>\n",
       "      <td>59.51</td>\n",
       "      <td>55.766667</td>\n",
       "      <td>51.3575</td>\n",
       "      <td>51.3575</td>\n",
       "      <td>50.696667</td>\n",
       "      <td>8.184583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.959333</td>\n",
       "      <td>6.938917</td>\n",
       "      <td>40.069667</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.302008</td>\n",
       "      <td>24.101903</td>\n",
       "      <td>23.908835</td>\n",
       "      <td>38.554217</td>\n",
       "      <td>33.823200</td>\n",
       "      <td>28.514056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>52.3000</td>\n",
       "      <td>58.70</td>\n",
       "      <td>55.400000</td>\n",
       "      <td>50.5000</td>\n",
       "      <td>50.5000</td>\n",
       "      <td>50.100000</td>\n",
       "      <td>8.510000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.990000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>40.590000</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>47.254717</td>\n",
       "      <td>47.100000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>31.188679</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>52.3000</td>\n",
       "      <td>58.70</td>\n",
       "      <td>55.400000</td>\n",
       "      <td>50.5000</td>\n",
       "      <td>50.5000</td>\n",
       "      <td>50.100000</td>\n",
       "      <td>8.990000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>40.540000</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>47.220755</td>\n",
       "      <td>47.100000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>31.207547</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>53.5325</td>\n",
       "      <td>59.51</td>\n",
       "      <td>55.766667</td>\n",
       "      <td>51.3575</td>\n",
       "      <td>51.3575</td>\n",
       "      <td>50.696667</td>\n",
       "      <td>8.184583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.959333</td>\n",
       "      <td>6.938917</td>\n",
       "      <td>40.069667</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.302008</td>\n",
       "      <td>24.101903</td>\n",
       "      <td>23.908835</td>\n",
       "      <td>38.554217</td>\n",
       "      <td>33.823200</td>\n",
       "      <td>28.514056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>53.5325</td>\n",
       "      <td>59.51</td>\n",
       "      <td>55.766667</td>\n",
       "      <td>51.3575</td>\n",
       "      <td>51.3575</td>\n",
       "      <td>50.696667</td>\n",
       "      <td>8.184583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.959333</td>\n",
       "      <td>6.938917</td>\n",
       "      <td>40.069667</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.302008</td>\n",
       "      <td>24.101903</td>\n",
       "      <td>23.908835</td>\n",
       "      <td>38.554217</td>\n",
       "      <td>33.823200</td>\n",
       "      <td>28.514056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>598 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      X_2831  X_2832     X_2833   X_2834   X_2835     X_2836    X_2837  \\\n",
       "0    52.3000   58.70  55.400000  50.5000  50.5000  50.100000  9.040000   \n",
       "1    54.4000   61.10  56.400000  52.0000  52.0000  51.900000  8.000000   \n",
       "2    52.3000   58.70  55.400000  50.5000  50.5000  50.100000  9.040000   \n",
       "3    54.4000   61.10  56.400000  52.0000  52.0000  51.900000  7.490000   \n",
       "4    52.3000   58.70  55.400000  50.5000  50.5000  50.100000  9.040000   \n",
       "..       ...     ...        ...      ...      ...        ...       ...   \n",
       "593  53.5325   59.51  55.766667  51.3575  51.3575  50.696667  8.184583   \n",
       "594  52.3000   58.70  55.400000  50.5000  50.5000  50.100000  8.510000   \n",
       "595  52.3000   58.70  55.400000  50.5000  50.5000  50.100000  8.990000   \n",
       "596  53.5325   59.51  55.766667  51.3575  51.3575  50.696667  8.184583   \n",
       "597  53.5325   59.51  55.766667  51.3575  51.3575  50.696667  8.184583   \n",
       "\n",
       "     X_2838    X_2839    X_2840     X_2841    X_2842    X_2843  X_2844  \\\n",
       "0       NaN  5.020000  7.000000  40.060000  0.000331  0.000033     NaN   \n",
       "1       NaN  5.000000  7.050000  36.540000  0.001150  0.000009     NaN   \n",
       "2       NaN  5.020000  6.520000  40.050000  0.000332  0.000033     NaN   \n",
       "3       NaN  5.010000  7.030000  40.030000  0.001210  0.000008     NaN   \n",
       "4       NaN  5.030000  6.520000  40.070000  0.000334  0.000041     NaN   \n",
       "..      ...       ...       ...        ...       ...       ...     ...   \n",
       "593     NaN  4.959333  6.938917  40.069667  0.000716  0.000014     NaN   \n",
       "594     NaN  4.990000  7.000000  40.590000  0.000124  0.000009     NaN   \n",
       "595     NaN  5.000000  7.000000  40.540000  0.000195  0.000009     NaN   \n",
       "596     NaN  4.959333  6.938917  40.069667  0.000716  0.000014     NaN   \n",
       "597     NaN  4.959333  6.938917  40.069667  0.000716  0.000014     NaN   \n",
       "\n",
       "        X_2845     X_2846     X_2847     X_2848     X_2849     X_2850  \n",
       "0    47.200000  47.094444  47.000000  39.000000  32.722222  26.000000  \n",
       "1    47.100000  47.084906  47.000000  34.000000  30.849057  27.000000  \n",
       "2    47.200000  47.088679  47.000000  35.000000  30.603774  27.000000  \n",
       "3    47.200000  47.105660  46.900000  38.000000  32.698113  27.000000  \n",
       "4    47.200000  47.107407  47.000000  36.000000  32.888889  28.000000  \n",
       "..         ...        ...        ...        ...        ...        ...  \n",
       "593  24.302008  24.101903  23.908835  38.554217  33.823200  28.514056  \n",
       "594  47.500000  47.254717  47.100000  35.000000  31.188679  25.000000  \n",
       "595  47.500000  47.220755  47.100000  37.000000  31.207547  25.000000  \n",
       "596  24.302008  24.101903  23.908835  38.554217  33.823200  28.514056  \n",
       "597  24.302008  24.101903  23.908835  38.554217  33.823200  28.514056  \n",
       "\n",
       "[598 rows x 20 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[:,2836:2856]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "689258f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.fillna(-100)\n",
    "test_df = test_df.fillna(-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d767dcb8",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1989ab4b",
   "metadata": {},
   "source": [
    "outlier 이상체 제거한 최종 데이터 프레임 저장하기 & 모든 value가 결측치이거나 0.0인 행 지운 test data도 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "29f9634b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('./train_fillnan_t21.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c825cef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('./test_fillnan_t21.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5e83ca",
   "metadata": {},
   "source": [
    "모델링을 하기 앞서, 독립변수 X와 종속변수 y를 설정해야한다.\n",
    "\n",
    "**학습에 사용할 변수 X와 예측할 변수 y를 분리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ae41a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_df['Y_Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eeb706",
   "metadata": {},
   "source": [
    "학습에 쓰이지 않을 column들을 제거한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "606f458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_df.drop(columns = ['PRODUCT_ID', 'TIMESTAMP', 'Y_Class', 'Y_Quality'])\n",
    "#모델 학습이 끝나고 예측에 쓰일 test데이터\n",
    "test_x = test_df.drop(columns=['PRODUCT_ID', 'TIMESTAMP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd74ac6",
   "metadata": {},
   "source": [
    "범주형 데이터를 수치 데이터로 전환하기 위해 LabelEncoder 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "53adcf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# qualitative to quantitative\n",
    "qual_col = ['LINE', 'PRODUCT_CODE']\n",
    "\n",
    "for i in qual_col:\n",
    "    le = LabelEncoder()\n",
    "    le = le.fit(train_x[i]) #원래 column 값을 기준으로 fit.\n",
    "    train_x[i] = le.transform(train_x[i]) #수치화, 수치로 변형\n",
    "    \n",
    "    for label in np.unique(test_x[i]): \n",
    "        if label not in le.classes_: \n",
    "            le.classes_ = np.append(le.classes_, label)\n",
    "    test_x[i] = le.transform(test_x[i]) \n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "112ef152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_68</th>\n",
       "      <th>X_69</th>\n",
       "      <th>X_70</th>\n",
       "      <th>X_71</th>\n",
       "      <th>X_72</th>\n",
       "      <th>X_73</th>\n",
       "      <th>X_74</th>\n",
       "      <th>X_75</th>\n",
       "      <th>X_76</th>\n",
       "      <th>X_77</th>\n",
       "      <th>...</th>\n",
       "      <th>X_91</th>\n",
       "      <th>X_92</th>\n",
       "      <th>X_93</th>\n",
       "      <th>X_94</th>\n",
       "      <th>X_95</th>\n",
       "      <th>X_96</th>\n",
       "      <th>X_97</th>\n",
       "      <th>X_98</th>\n",
       "      <th>X_99</th>\n",
       "      <th>X_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.00000</td>\n",
       "      <td>-100.00000</td>\n",
       "      <td>-100.00000</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.00000</td>\n",
       "      <td>-100.00000</td>\n",
       "      <td>-100.00000</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.00000</td>\n",
       "      <td>-100.00000</td>\n",
       "      <td>-100.00000</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.00000</td>\n",
       "      <td>-100.00000</td>\n",
       "      <td>-100.00000</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.00000</td>\n",
       "      <td>-100.00000</td>\n",
       "      <td>-100.00000</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>82.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>999.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00077</td>\n",
       "      <td>0.00079</td>\n",
       "      <td>0.00072</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.00000</td>\n",
       "      <td>-100.00000</td>\n",
       "      <td>-100.00000</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.00000</td>\n",
       "      <td>-100.00000</td>\n",
       "      <td>-100.00000</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>82.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>999.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00130</td>\n",
       "      <td>0.00150</td>\n",
       "      <td>0.00130</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>82.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>999.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00077</td>\n",
       "      <td>0.00084</td>\n",
       "      <td>0.00072</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>598 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      X_68   X_69   X_70   X_71   X_72    X_73   X_74   X_75   X_76   X_77  \\\n",
       "0   -100.0 -100.0 -100.0 -100.0 -100.0 -100.00 -100.0 -100.0 -100.0 -100.0   \n",
       "1   -100.0 -100.0 -100.0 -100.0 -100.0 -100.00 -100.0 -100.0 -100.0 -100.0   \n",
       "2   -100.0 -100.0 -100.0 -100.0 -100.0 -100.00 -100.0 -100.0 -100.0 -100.0   \n",
       "3   -100.0 -100.0 -100.0 -100.0 -100.0 -100.00 -100.0 -100.0 -100.0 -100.0   \n",
       "4   -100.0 -100.0 -100.0 -100.0 -100.0 -100.00 -100.0 -100.0 -100.0 -100.0   \n",
       "..     ...    ...    ...    ...    ...     ...    ...    ...    ...    ...   \n",
       "593   82.5    1.0    0.0    2.0    2.0   10.09    0.0    0.0    0.0    0.0   \n",
       "594 -100.0 -100.0 -100.0 -100.0 -100.0 -100.00 -100.0 -100.0 -100.0 -100.0   \n",
       "595 -100.0 -100.0 -100.0 -100.0 -100.0 -100.00 -100.0 -100.0 -100.0 -100.0   \n",
       "596   82.5    1.0    0.0    2.0    2.0   10.22    0.0    0.0    0.0    0.0   \n",
       "597   82.5    1.0    0.0    2.0    2.0   10.09    0.0    0.0    0.0    0.0   \n",
       "\n",
       "     ...   X_91   X_92    X_93    X_94    X_95   X_96       X_97       X_98  \\\n",
       "0    ... -100.0 -100.0 -100.00 -100.00 -100.00 -100.0 -100.00000 -100.00000   \n",
       "1    ... -100.0 -100.0 -100.00 -100.00 -100.00 -100.0 -100.00000 -100.00000   \n",
       "2    ... -100.0 -100.0 -100.00 -100.00 -100.00 -100.0 -100.00000 -100.00000   \n",
       "3    ... -100.0 -100.0 -100.00 -100.00 -100.00 -100.0 -100.00000 -100.00000   \n",
       "4    ... -100.0 -100.0 -100.00 -100.00 -100.00 -100.0 -100.00000 -100.00000   \n",
       "..   ...    ...    ...     ...     ...     ...    ...        ...        ...   \n",
       "593  ...  999.0 -100.0    0.19    0.19    0.19    2.0    0.00077    0.00079   \n",
       "594  ... -100.0 -100.0 -100.00 -100.00 -100.00 -100.0 -100.00000 -100.00000   \n",
       "595  ... -100.0 -100.0 -100.00 -100.00 -100.00 -100.0 -100.00000 -100.00000   \n",
       "596  ...  999.0   28.0 -100.00 -100.00 -100.00    2.0    0.00130    0.00150   \n",
       "597  ...  999.0 -100.0    0.19    0.19    0.19    2.0    0.00077    0.00084   \n",
       "\n",
       "          X_99  X_100  \n",
       "0   -100.00000 -100.0  \n",
       "1   -100.00000 -100.0  \n",
       "2   -100.00000 -100.0  \n",
       "3   -100.00000 -100.0  \n",
       "4   -100.00000 -100.0  \n",
       "..         ...    ...  \n",
       "593    0.00072   18.0  \n",
       "594 -100.00000 -100.0  \n",
       "595 -100.00000 -100.0  \n",
       "596    0.00130   18.0  \n",
       "597    0.00072   18.0  \n",
       "\n",
       "[598 rows x 33 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.iloc[:,69:102]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55a73f6",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e960f3f1",
   "metadata": {},
   "source": [
    "1.모델 선택 - sklearn라이브러리 활용 - RandomForest \n",
    "\n",
    "2.모델 학습 - train_df를 활용하여 1번에서 정의한 모델로 학습\n",
    "\n",
    "3.예측 - 학습된 모델을 바탕으로 test 데이터를 예측\n",
    "\n",
    "4.정답 파일 생성 - 정답 파일 생성 및 제출 필요(경진대회를 위해 필요한 과정.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bad9c26",
   "metadata": {},
   "source": [
    "subRF_r = pd.read_csv('./sample_submission.csv')\n",
    "subXGB_r = pd.read_csv('./sample_submission.csv')\n",
    "sub_v = pd.read_csv('./sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c78e05",
   "metadata": {},
   "source": [
    "# Randomsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2786de08",
   "metadata": {},
   "source": [
    "1.GBM randomsearch\n",
    "\n",
    "2.Randomforestregressor & SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cce2440",
   "metadata": {},
   "source": [
    "### GBM randomsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2381005d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "최적 하이퍼 파라미터: {'min_samples_leaf': 2, 'min_samples_split': 9, 'n_estimators': 112}\n",
      "최고 예측 정확도: 43.3784\n",
      "time elapsed: 1051.1275579929352\n",
      "[CV 3/5] END min_samples_leaf=16, min_samples_split=2, n_estimators=72;, score=0.447 total time=  20.6s\n",
      "[CV 5/5] END min_samples_leaf=16, min_samples_split=2, n_estimators=72;, score=0.363 total time=  20.9s\n",
      "[CV 3/5] END min_samples_leaf=9, min_samples_split=3, n_estimators=179;, score=0.326 total time=  57.3s\n",
      "[CV 5/5] END min_samples_leaf=15, min_samples_split=3, n_estimators=171;, score=0.366 total time=  52.6s\n",
      "[CV 4/5] END min_samples_leaf=1, min_samples_split=3, n_estimators=176;, score=0.454 total time=  59.6s\n",
      "[CV 3/5] END min_samples_leaf=8, min_samples_split=2, n_estimators=102;, score=0.380 total time=  34.3s\n",
      "[CV 3/5] END min_samples_leaf=13, min_samples_split=9, n_estimators=175;, score=0.402 total time=  51.3s\n",
      "[CV 4/5] END min_samples_leaf=14, min_samples_split=4, n_estimators=198;, score=0.406 total time=  59.6s\n",
      "[CV 5/5] END min_samples_leaf=15, min_samples_split=3, n_estimators=189;, score=0.358 total time=  54.8s\n",
      "[CV 1/5] END min_samples_leaf=4, min_samples_split=3, n_estimators=54;, score=0.497 total time=  15.6s\n",
      "[CV 2/5] END min_samples_leaf=2, min_samples_split=7, n_estimators=184;, score=0.451 total time= 1.0min\n",
      "[CV 5/5] END min_samples_leaf=7, min_samples_split=2, n_estimators=39;, score=0.250 total time=  13.0s\n",
      "[CV 1/5] END min_samples_leaf=13, min_samples_split=6, n_estimators=146;, score=0.421 total time=  41.9s\n",
      "[CV 4/5] END min_samples_leaf=4, min_samples_split=2, n_estimators=79;, score=0.407 total time=  25.0s\n",
      "[CV 5/5] END min_samples_leaf=4, min_samples_split=7, n_estimators=166;, score=0.211 total time=  53.1s\n",
      "[CV 1/5] END min_samples_leaf=9, min_samples_split=7, n_estimators=185;, score=0.493 total time=  53.3s\n",
      "[CV 5/5] END min_samples_leaf=13, min_samples_split=7, n_estimators=27;, score=0.377 total time=   7.9s\n",
      "[CV 2/5] END min_samples_leaf=8, min_samples_split=2, n_estimators=68;, score=0.476 total time=  20.5s\n",
      "[CV 2/5] END min_samples_leaf=6, min_samples_split=4, n_estimators=182;, score=0.511 total time=  58.0s\n",
      "[CV 4/5] END min_samples_leaf=10, min_samples_split=7, n_estimators=69;, score=0.390 total time=  21.9s\n",
      "[CV 2/5] END min_samples_leaf=1, min_samples_split=6, n_estimators=150;, score=0.421 total time=  47.5s\n",
      "[CV 2/5] END min_samples_leaf=14, min_samples_split=3, n_estimators=78;, score=0.480 total time=  23.7s\n",
      "[CV 5/5] END min_samples_leaf=6, min_samples_split=5, n_estimators=31;, score=0.267 total time=   9.8s\n",
      "[CV 1/5] END min_samples_leaf=10, min_samples_split=5, n_estimators=112;, score=0.460 total time=  32.2s\n",
      "[CV 4/5] END min_samples_leaf=10, min_samples_split=5, n_estimators=112;, score=0.362 total time=  36.5s\n",
      "[CV 2/5] END min_samples_leaf=10, min_samples_split=4, n_estimators=193;, score=0.405 total time= 1.0min\n",
      "[CV 1/5] END min_samples_leaf=1, min_samples_split=7, n_estimators=178;, score=0.449 total time=  55.1s\n",
      "[CV 4/5] END min_samples_leaf=9, min_samples_split=3, n_estimators=179;, score=0.443 total time=  58.7s\n",
      "[CV 1/5] END min_samples_leaf=1, min_samples_split=3, n_estimators=176;, score=0.455 total time=  55.7s\n",
      "[CV 4/5] END min_samples_leaf=4, min_samples_split=4, n_estimators=158;, score=0.398 total time=  53.1s\n",
      "[CV 2/5] END min_samples_leaf=8, min_samples_split=4, n_estimators=56;, score=0.495 total time=  20.8s\n",
      "[CV 1/5] END min_samples_leaf=13, min_samples_split=9, n_estimators=175;, score=0.424 total time=  50.1s\n",
      "[CV 2/5] END min_samples_leaf=14, min_samples_split=4, n_estimators=198;, score=0.452 total time=  59.6s\n",
      "[CV 3/5] END min_samples_leaf=15, min_samples_split=3, n_estimators=189;, score=0.401 total time=  54.2s\n",
      "[CV 4/5] END min_samples_leaf=11, min_samples_split=5, n_estimators=43;, score=0.359 total time=  13.0s\n",
      "[CV 5/5] END min_samples_leaf=4, min_samples_split=3, n_estimators=54;, score=0.221 total time=  16.8s\n",
      "[CV 1/5] END min_samples_leaf=7, min_samples_split=6, n_estimators=101;, score=0.488 total time=  32.2s\n",
      "[CV 4/5] END min_samples_leaf=7, min_samples_split=6, n_estimators=101;, score=0.439 total time=  34.0s\n",
      "[CV 2/5] END min_samples_leaf=13, min_samples_split=6, n_estimators=146;, score=0.474 total time=  44.7s\n",
      "[CV 5/5] END min_samples_leaf=4, min_samples_split=2, n_estimators=79;, score=0.233 total time=  25.3s\n",
      "[CV 2/5] END min_samples_leaf=11, min_samples_split=4, n_estimators=119;, score=0.432 total time=  36.9s\n",
      "[CV 1/5] END min_samples_leaf=15, min_samples_split=9, n_estimators=37;, score=0.319 total time=  10.8s\n",
      "[CV 2/5] END min_samples_leaf=9, min_samples_split=7, n_estimators=185;, score=0.404 total time=  56.9s\n",
      "[CV 2/5] END min_samples_leaf=10, min_samples_split=8, n_estimators=71;, score=0.444 total time=  21.6s\n",
      "[CV 1/5] END min_samples_leaf=14, min_samples_split=7, n_estimators=8;, score=0.350 total time=   2.2s\n",
      "[CV 3/5] END min_samples_leaf=14, min_samples_split=7, n_estimators=8;, score=0.257 total time=   2.3s\n",
      "[CV 4/5] END min_samples_leaf=6, min_samples_split=4, n_estimators=182;, score=0.438 total time=  59.5s\n",
      "[CV 1/5] END min_samples_leaf=1, min_samples_split=5, n_estimators=168;, score=0.456 total time=  51.6s\n",
      "[CV 4/5] END min_samples_leaf=1, min_samples_split=6, n_estimators=150;, score=0.501 total time=  49.2s\n",
      "[CV 2/5] END min_samples_leaf=10, min_samples_split=5, n_estimators=112;, score=0.413 total time=  34.4s\n",
      "[CV 5/5] END min_samples_leaf=10, min_samples_split=5, n_estimators=112;, score=0.294 total time=  36.6s\n",
      "[CV 3/5] END min_samples_leaf=10, min_samples_split=4, n_estimators=193;, score=0.359 total time=  59.7s\n",
      "[CV 2/5] END min_samples_leaf=1, min_samples_split=7, n_estimators=178;, score=0.455 total time=  57.4s\n",
      "[CV 2/5] END min_samples_leaf=15, min_samples_split=3, n_estimators=171;, score=0.423 total time=  53.7s\n",
      "[CV 4/5] END min_samples_leaf=1, min_samples_split=5, n_estimators=155;, score=0.459 total time=  51.5s\n",
      "[CV 2/5] END min_samples_leaf=4, min_samples_split=4, n_estimators=158;, score=0.462 total time=  52.3s\n",
      "[CV 4/5] END min_samples_leaf=8, min_samples_split=2, n_estimators=102;, score=0.407 total time=  35.7s\n",
      "[CV 4/5] END min_samples_leaf=13, min_samples_split=9, n_estimators=175;, score=0.390 total time=  53.8s\n",
      "[CV 2/5] END min_samples_leaf=8, min_samples_split=8, n_estimators=10;, score=0.366 total time=   3.5s\n",
      "[CV 5/5] END min_samples_leaf=8, min_samples_split=8, n_estimators=10;, score=0.329 total time=   3.2s\n",
      "[CV 3/5] END min_samples_leaf=5, min_samples_split=4, n_estimators=78;, score=0.376 total time=  23.0s\n",
      "[CV 1/5] END min_samples_leaf=4, min_samples_split=4, n_estimators=4;, score=0.249 total time=   1.3s\n",
      "[CV 2/5] END min_samples_leaf=4, min_samples_split=4, n_estimators=4;, score=0.267 total time=   1.4s\n",
      "[CV 3/5] END min_samples_leaf=4, min_samples_split=4, n_estimators=4;, score=0.269 total time=   1.4s\n",
      "[CV 4/5] END min_samples_leaf=4, min_samples_split=4, n_estimators=4;, score=0.268 total time=   1.3s\n",
      "[CV 1/5] END min_samples_leaf=15, min_samples_split=3, n_estimators=189;, score=0.387 total time=  52.3s\n",
      "[CV 4/5] END min_samples_leaf=8, min_samples_split=5, n_estimators=151;, score=0.397 total time=  46.1s\n",
      "[CV 2/5] END min_samples_leaf=7, min_samples_split=6, n_estimators=101;, score=0.485 total time=  33.9s\n",
      "[CV 5/5] END min_samples_leaf=7, min_samples_split=6, n_estimators=101;, score=0.267 total time=  33.8s\n",
      "[CV 3/5] END min_samples_leaf=13, min_samples_split=6, n_estimators=146;, score=0.402 total time=  43.8s\n",
      "[CV 1/5] END min_samples_leaf=4, min_samples_split=7, n_estimators=166;, score=0.521 total time=  49.8s\n",
      "[CV 4/5] END min_samples_leaf=11, min_samples_split=4, n_estimators=119;, score=0.362 total time=  37.3s\n",
      "[CV 2/5] END min_samples_leaf=15, min_samples_split=4, n_estimators=65;, score=0.480 total time=  19.4s\n",
      "[CV 5/5] END min_samples_leaf=15, min_samples_split=4, n_estimators=65;, score=0.427 total time=  19.4s\n",
      "[CV 1/5] END min_samples_leaf=10, min_samples_split=8, n_estimators=71;, score=0.462 total time=  20.5s\n",
      "[CV 4/5] END min_samples_leaf=8, min_samples_split=2, n_estimators=68;, score=0.383 total time=  21.3s\n",
      "[CV 1/5] END min_samples_leaf=12, min_samples_split=1, n_estimators=25;, score=nan total time=   0.1s\n",
      "[CV 2/5] END min_samples_leaf=12, min_samples_split=1, n_estimators=25;, score=nan total time=   0.1s\n",
      "[CV 3/5] END min_samples_leaf=12, min_samples_split=1, n_estimators=25;, score=nan total time=   0.1s\n",
      "[CV 4/5] END min_samples_leaf=12, min_samples_split=1, n_estimators=25;, score=nan total time=   0.1s\n",
      "[CV 5/5] END min_samples_leaf=12, min_samples_split=1, n_estimators=25;, score=nan total time=   0.1s\n",
      "[CV 1/5] END min_samples_leaf=9, min_samples_split=7, n_estimators=99;, score=0.489 total time=  29.2s\n",
      "[CV 4/5] END min_samples_leaf=9, min_samples_split=7, n_estimators=99;, score=0.385 total time=  32.2s\n",
      "[CV 4/5] END min_samples_leaf=1, min_samples_split=5, n_estimators=168;, score=0.459 total time=  54.7s\n",
      "[CV 5/5] END min_samples_leaf=14, min_samples_split=3, n_estimators=78;, score=0.412 total time=  23.7s\n",
      "[CV 3/5] END min_samples_leaf=10, min_samples_split=9, n_estimators=199;, score=0.359 total time= 1.0min\n",
      "[CV 4/5] END min_samples_leaf=14, min_samples_split=5, n_estimators=134;, score=0.406 total time=  43.3s\n",
      "[CV 2/5] END min_samples_leaf=2, min_samples_split=9, n_estimators=112;, score=0.459 total time=  35.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END min_samples_leaf=1, min_samples_split=7, n_estimators=178;, score=0.226 total time=  57.4s\n",
      "[CV 1/5] END min_samples_leaf=15, min_samples_split=3, n_estimators=171;, score=0.387 total time=  50.7s\n",
      "[CV 2/5] END min_samples_leaf=1, min_samples_split=5, n_estimators=155;, score=0.459 total time=  50.1s\n",
      "[CV 5/5] END min_samples_leaf=1, min_samples_split=3, n_estimators=176;, score=0.231 total time=  59.0s\n",
      "[CV 1/5] END min_samples_leaf=8, min_samples_split=4, n_estimators=56;, score=0.430 total time=  18.8s\n",
      "[CV 3/5] END min_samples_leaf=8, min_samples_split=4, n_estimators=56;, score=0.374 total time=  17.8s\n",
      "[CV 1/5] END min_samples_leaf=12, min_samples_split=4, n_estimators=83;, score=0.413 total time=  24.0s\n",
      "[CV 4/5] END min_samples_leaf=12, min_samples_split=4, n_estimators=83;, score=0.386 total time=  25.3s\n",
      "[CV 5/5] END min_samples_leaf=14, min_samples_split=4, n_estimators=198;, score=0.423 total time=  59.2s\n",
      "[CV 3/5] END min_samples_leaf=8, min_samples_split=5, n_estimators=151;, score=0.340 total time=  43.9s\n",
      "[CV 3/5] END min_samples_leaf=11, min_samples_split=5, n_estimators=43;, score=0.427 total time=  12.4s\n",
      "[CV 4/5] END min_samples_leaf=4, min_samples_split=3, n_estimators=54;, score=0.388 total time=  16.6s\n",
      "[CV 5/5] END min_samples_leaf=2, min_samples_split=7, n_estimators=184;, score=0.225 total time= 1.0min\n",
      "[CV 3/5] END min_samples_leaf=6, min_samples_split=9, n_estimators=124;, score=0.386 total time=  38.2s\n",
      "[CV 1/5] END min_samples_leaf=4, min_samples_split=2, n_estimators=79;, score=0.490 total time=  23.4s\n",
      "[CV 2/5] END min_samples_leaf=4, min_samples_split=7, n_estimators=166;, score=0.488 total time=  52.1s\n",
      "[CV 2/5] END min_samples_leaf=15, min_samples_split=9, n_estimators=37;, score=0.450 total time=  11.3s\n",
      "[CV 3/5] END min_samples_leaf=9, min_samples_split=7, n_estimators=185;, score=0.326 total time=  54.9s\n",
      "[CV 3/5] END min_samples_leaf=10, min_samples_split=8, n_estimators=71;, score=0.336 total time=  20.8s\n",
      "[CV 5/5] END min_samples_leaf=8, min_samples_split=2, n_estimators=68;, score=0.281 total time=  21.3s\n",
      "[CV 3/5] END min_samples_leaf=9, min_samples_split=7, n_estimators=99;, score=0.316 total time=  30.2s\n",
      "[CV 5/5] END min_samples_leaf=9, min_samples_split=7, n_estimators=99;, score=0.286 total time=  31.7s\n",
      "[CV 1/5] END min_samples_leaf=1, min_samples_split=6, n_estimators=150;, score=0.419 total time=  45.0s\n",
      "[CV 1/5] END min_samples_leaf=14, min_samples_split=3, n_estimators=78;, score=0.332 total time=  22.3s\n",
      "[CV 3/5] END min_samples_leaf=6, min_samples_split=5, n_estimators=31;, score=0.309 total time=   9.4s\n",
      "[CV 4/5] END min_samples_leaf=10, min_samples_split=9, n_estimators=199;, score=0.362 total time= 1.0min\n",
      "[CV 5/5] END min_samples_leaf=14, min_samples_split=5, n_estimators=134;, score=0.394 total time=  42.5s\n",
      "[CV 3/5] END min_samples_leaf=2, min_samples_split=9, n_estimators=112;, score=0.505 total time=  34.6s\n",
      "[CV 4/5] END min_samples_leaf=1, min_samples_split=7, n_estimators=178;, score=0.448 total time=  57.5s\n",
      "[CV 3/5] END min_samples_leaf=15, min_samples_split=3, n_estimators=171;, score=0.390 total time=  52.4s\n",
      "[CV 3/5] END min_samples_leaf=1, min_samples_split=5, n_estimators=155;, score=0.427 total time=  49.1s\n",
      "[CV 1/5] END min_samples_leaf=4, min_samples_split=4, n_estimators=158;, score=0.522 total time=  49.6s\n",
      "[CV 2/5] END min_samples_leaf=8, min_samples_split=2, n_estimators=102;, score=0.490 total time=  34.9s\n",
      "[CV 2/5] END min_samples_leaf=13, min_samples_split=9, n_estimators=175;, score=0.460 total time=  52.3s\n",
      "[CV 3/5] END min_samples_leaf=14, min_samples_split=4, n_estimators=198;, score=0.359 total time=  57.6s\n",
      "[CV 4/5] END min_samples_leaf=15, min_samples_split=3, n_estimators=189;, score=0.373 total time=  55.3s\n",
      "[CV 5/5] END min_samples_leaf=11, min_samples_split=5, n_estimators=43;, score=0.302 total time=  12.8s\n",
      "[CV 1/5] END min_samples_leaf=2, min_samples_split=7, n_estimators=184;, score=0.491 total time=  57.4s\n",
      "[CV 2/5] END min_samples_leaf=7, min_samples_split=2, n_estimators=39;, score=0.471 total time=  12.8s\n",
      "[CV 1/5] END min_samples_leaf=6, min_samples_split=9, n_estimators=124;, score=0.468 total time=  37.5s\n",
      "[CV 4/5] END min_samples_leaf=13, min_samples_split=6, n_estimators=146;, score=0.390 total time=  44.2s\n",
      "[CV 1/5] END min_samples_leaf=11, min_samples_split=4, n_estimators=119;, score=0.446 total time=  34.3s\n",
      "[CV 5/5] END min_samples_leaf=11, min_samples_split=4, n_estimators=119;, score=0.278 total time=  36.9s\n",
      "[CV 3/5] END min_samples_leaf=15, min_samples_split=4, n_estimators=65;, score=0.343 total time=  18.6s\n",
      "[CV 1/5] END min_samples_leaf=13, min_samples_split=7, n_estimators=27;, score=0.326 total time=   7.5s\n",
      "[CV 3/5] END min_samples_leaf=13, min_samples_split=7, n_estimators=27;, score=0.389 total time=   7.9s\n",
      "[CV 4/5] END min_samples_leaf=10, min_samples_split=8, n_estimators=71;, score=0.390 total time=  21.5s\n",
      "[CV 2/5] END min_samples_leaf=14, min_samples_split=7, n_estimators=8;, score=0.437 total time=   2.3s\n",
      "[CV 5/5] END min_samples_leaf=14, min_samples_split=7, n_estimators=8;, score=0.271 total time=   2.4s\n",
      "[CV 1/5] END min_samples_leaf=5, min_samples_split=8, n_estimators=9;, score=0.347 total time=   3.0s\n",
      "[CV 2/5] END min_samples_leaf=5, min_samples_split=8, n_estimators=9;, score=0.407 total time=   2.9s\n",
      "[CV 3/5] END min_samples_leaf=5, min_samples_split=8, n_estimators=9;, score=0.325 total time=   2.9s\n",
      "[CV 4/5] END min_samples_leaf=5, min_samples_split=8, n_estimators=9;, score=0.304 total time=   3.0s\n",
      "[CV 5/5] END min_samples_leaf=5, min_samples_split=8, n_estimators=9;, score=0.305 total time=   3.0s\n",
      "[CV 2/5] END min_samples_leaf=9, min_samples_split=7, n_estimators=99;, score=0.453 total time=  30.7s\n",
      "[CV 1/5] END min_samples_leaf=10, min_samples_split=7, n_estimators=69;, score=0.462 total time=  21.0s\n",
      "[CV 2/5] END min_samples_leaf=1, min_samples_split=5, n_estimators=168;, score=0.459 total time=  53.5s\n",
      "[CV 5/5] END min_samples_leaf=1, min_samples_split=6, n_estimators=150;, score=0.193 total time=  47.9s\n",
      "[CV 3/5] END min_samples_leaf=10, min_samples_split=5, n_estimators=112;, score=0.376 total time=  33.7s\n",
      "[CV 1/5] END min_samples_leaf=14, min_samples_split=5, n_estimators=134;, score=0.350 total time=  40.0s\n",
      "[CV 4/5] END min_samples_leaf=10, min_samples_split=4, n_estimators=193;, score=0.362 total time=  58.6s\n",
      "[CV 1/5] END min_samples_leaf=16, min_samples_split=2, n_estimators=72;, score=0.374 total time=  19.9s\n",
      "[CV 4/5] END min_samples_leaf=16, min_samples_split=2, n_estimators=72;, score=0.354 total time=  21.0s\n",
      "[CV 2/5] END min_samples_leaf=9, min_samples_split=3, n_estimators=179;, score=0.408 total time=  58.6s\n",
      "[CV 1/5] END min_samples_leaf=1, min_samples_split=5, n_estimators=155;, score=0.426 total time=  48.0s\n",
      "[CV 3/5] END min_samples_leaf=1, min_samples_split=3, n_estimators=176;, score=0.411 total time=  57.5s\n",
      "[CV 1/5] END min_samples_leaf=8, min_samples_split=2, n_estimators=102;, score=0.516 total time=  32.3s\n",
      "[CV 4/5] END min_samples_leaf=8, min_samples_split=4, n_estimators=56;, score=0.390 total time=  18.2s\n",
      "[CV 2/5] END min_samples_leaf=12, min_samples_split=4, n_estimators=83;, score=0.457 total time=  25.2s\n",
      "[CV 5/5] END min_samples_leaf=12, min_samples_split=4, n_estimators=83;, score=0.316 total time=  25.5s\n",
      "[CV 3/5] END min_samples_leaf=8, min_samples_split=8, n_estimators=10;, score=0.322 total time=   3.1s\n",
      "[CV 1/5] END min_samples_leaf=5, min_samples_split=4, n_estimators=78;, score=0.481 total time=  22.1s\n",
      "[CV 4/5] END min_samples_leaf=5, min_samples_split=4, n_estimators=78;, score=0.421 total time=  24.8s\n",
      "[CV 1/5] END min_samples_leaf=8, min_samples_split=5, n_estimators=151;, score=0.519 total time=  42.4s\n",
      "[CV 1/5] END min_samples_leaf=3, min_samples_split=1, n_estimators=18;, score=nan total time=   0.1s\n",
      "[CV 2/5] END min_samples_leaf=3, min_samples_split=1, n_estimators=18;, score=nan total time=   0.1s\n",
      "[CV 3/5] END min_samples_leaf=3, min_samples_split=1, n_estimators=18;, score=nan total time=   0.1s\n",
      "[CV 4/5] END min_samples_leaf=3, min_samples_split=1, n_estimators=18;, score=nan total time=   0.1s\n",
      "[CV 5/5] END min_samples_leaf=3, min_samples_split=1, n_estimators=18;, score=nan total time=   0.1s\n",
      "[CV 1/5] END min_samples_leaf=11, min_samples_split=5, n_estimators=43;, score=0.440 total time=  12.0s\n",
      "[CV 2/5] END min_samples_leaf=4, min_samples_split=3, n_estimators=54;, score=0.444 total time=  16.5s\n",
      "[CV 3/5] END min_samples_leaf=2, min_samples_split=7, n_estimators=184;, score=0.437 total time=  59.7s\n",
      "[CV 4/5] END min_samples_leaf=7, min_samples_split=2, n_estimators=39;, score=0.366 total time=  13.1s\n",
      "[CV 5/5] END min_samples_leaf=6, min_samples_split=9, n_estimators=124;, score=0.271 total time=  39.2s\n",
      "[CV 3/5] END min_samples_leaf=4, min_samples_split=2, n_estimators=79;, score=0.421 total time=  24.2s\n",
      "[CV 4/5] END min_samples_leaf=4, min_samples_split=7, n_estimators=166;, score=0.399 total time=  53.0s\n",
      "[CV 5/5] END min_samples_leaf=15, min_samples_split=9, n_estimators=37;, score=0.381 total time=  11.2s\n",
      "[CV 1/5] END min_samples_leaf=15, min_samples_split=4, n_estimators=65;, score=0.341 total time=  18.4s\n",
      "[CV 4/5] END min_samples_leaf=15, min_samples_split=4, n_estimators=65;, score=0.298 total time=  19.2s\n",
      "[CV 2/5] END min_samples_leaf=13, min_samples_split=7, n_estimators=27;, score=0.476 total time=   8.0s\n",
      "[CV 4/5] END min_samples_leaf=13, min_samples_split=7, n_estimators=27;, score=0.391 total time=   8.0s\n",
      "[CV 1/5] END min_samples_leaf=8, min_samples_split=2, n_estimators=68;, score=0.472 total time=  19.5s\n",
      "[CV 4/5] END min_samples_leaf=14, min_samples_split=7, n_estimators=8;, score=0.304 total time=   2.4s\n",
      "[CV 5/5] END min_samples_leaf=6, min_samples_split=4, n_estimators=182;, score=0.267 total time=  58.7s\n",
      "[CV 5/5] END min_samples_leaf=10, min_samples_split=7, n_estimators=69;, score=0.303 total time=  21.6s\n",
      "[CV 3/5] END min_samples_leaf=1, min_samples_split=6, n_estimators=150;, score=0.422 total time=  46.8s\n",
      "[CV 3/5] END min_samples_leaf=14, min_samples_split=3, n_estimators=78;, score=0.349 total time=  23.3s\n",
      "[CV 1/5] END min_samples_leaf=10, min_samples_split=9, n_estimators=199;, score=0.454 total time=  57.9s\n",
      "[CV 2/5] END min_samples_leaf=14, min_samples_split=5, n_estimators=134;, score=0.457 total time=  41.8s\n",
      "[CV 5/5] END min_samples_leaf=10, min_samples_split=4, n_estimators=193;, score=0.267 total time=  56.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END min_samples_leaf=16, min_samples_split=2, n_estimators=72;, score=0.361 total time=  20.9s\n",
      "[CV 1/5] END min_samples_leaf=13, min_samples_split=1, n_estimators=84;, score=nan total time=   0.1s\n",
      "[CV 2/5] END min_samples_leaf=13, min_samples_split=1, n_estimators=84;, score=nan total time=   0.1s\n",
      "[CV 3/5] END min_samples_leaf=13, min_samples_split=1, n_estimators=84;, score=nan total time=   0.1s\n",
      "[CV 4/5] END min_samples_leaf=13, min_samples_split=1, n_estimators=84;, score=nan total time=   0.1s\n",
      "[CV 5/5] END min_samples_leaf=13, min_samples_split=1, n_estimators=84;, score=nan total time=   0.1s\n",
      "[CV 1/5] END min_samples_leaf=9, min_samples_split=3, n_estimators=179;, score=0.499 total time=  54.4s\n",
      "[CV 4/5] END min_samples_leaf=15, min_samples_split=3, n_estimators=171;, score=0.373 total time=  53.2s\n",
      "[CV 2/5] END min_samples_leaf=1, min_samples_split=3, n_estimators=176;, score=0.468 total time=  58.7s\n",
      "[CV 5/5] END min_samples_leaf=4, min_samples_split=4, n_estimators=158;, score=0.211 total time=  53.8s\n",
      "[CV 5/5] END min_samples_leaf=8, min_samples_split=4, n_estimators=56;, score=0.272 total time=  17.5s\n",
      "[CV 3/5] END min_samples_leaf=12, min_samples_split=4, n_estimators=83;, score=0.348 total time=  25.0s\n",
      "[CV 1/5] END min_samples_leaf=14, min_samples_split=4, n_estimators=198;, score=0.372 total time=  55.5s\n",
      "[CV 5/5] END min_samples_leaf=4, min_samples_split=4, n_estimators=4;, score=0.273 total time=   1.3s\n",
      "[CV 2/5] END min_samples_leaf=15, min_samples_split=3, n_estimators=189;, score=0.423 total time=  54.7s\n",
      "[CV 5/5] END min_samples_leaf=8, min_samples_split=5, n_estimators=151;, score=0.258 total time=  46.0s\n",
      "[CV 3/5] END min_samples_leaf=7, min_samples_split=6, n_estimators=101;, score=0.337 total time=  32.6s\n",
      "[CV 1/5] END min_samples_leaf=7, min_samples_split=2, n_estimators=39;, score=0.457 total time=  12.3s\n",
      "[CV 3/5] END min_samples_leaf=7, min_samples_split=2, n_estimators=39;, score=0.319 total time=  12.7s\n",
      "[CV 4/5] END min_samples_leaf=6, min_samples_split=9, n_estimators=124;, score=0.448 total time=  39.5s\n",
      "[CV 2/5] END min_samples_leaf=4, min_samples_split=2, n_estimators=79;, score=0.427 total time=  24.7s\n",
      "[CV 3/5] END min_samples_leaf=4, min_samples_split=7, n_estimators=166;, score=0.407 total time=  51.6s\n",
      "[CV 4/5] END min_samples_leaf=15, min_samples_split=9, n_estimators=37;, score=0.298 total time=  11.2s\n",
      "[CV 5/5] END min_samples_leaf=9, min_samples_split=7, n_estimators=185;, score=0.263 total time=  56.5s\n",
      "[CV 3/5] END min_samples_leaf=8, min_samples_split=2, n_estimators=68;, score=0.386 total time=  20.2s\n",
      "[CV 3/5] END min_samples_leaf=6, min_samples_split=4, n_estimators=182;, score=0.371 total time=  56.6s\n",
      "[CV 3/5] END min_samples_leaf=10, min_samples_split=7, n_estimators=69;, score=0.346 total time=  21.3s\n",
      "[CV 5/5] END min_samples_leaf=1, min_samples_split=5, n_estimators=168;, score=0.233 total time=  53.8s\n",
      "[CV 1/5] END min_samples_leaf=6, min_samples_split=5, n_estimators=31;, score=0.424 total time=   9.3s\n",
      "[CV 2/5] END min_samples_leaf=6, min_samples_split=5, n_estimators=31;, score=0.471 total time=   9.7s\n",
      "[CV 4/5] END min_samples_leaf=6, min_samples_split=5, n_estimators=31;, score=0.304 total time=   9.7s\n",
      "[CV 5/5] END min_samples_leaf=10, min_samples_split=9, n_estimators=199;, score=0.267 total time= 1.0min\n",
      "[CV 1/5] END min_samples_leaf=10, min_samples_split=4, n_estimators=193;, score=0.450 total time=  58.1s\n",
      "[CV 4/5] END min_samples_leaf=2, min_samples_split=9, n_estimators=112;, score=0.474 total time=  30.0s\n",
      "[CV 3/5] END min_samples_leaf=1, min_samples_split=7, n_estimators=178;, score=0.455 total time=  55.9s\n",
      "[CV 5/5] END min_samples_leaf=9, min_samples_split=3, n_estimators=179;, score=0.272 total time=  58.0s\n",
      "[CV 5/5] END min_samples_leaf=1, min_samples_split=5, n_estimators=155;, score=0.228 total time=  50.9s\n",
      "[CV 3/5] END min_samples_leaf=4, min_samples_split=4, n_estimators=158;, score=0.407 total time=  50.7s\n",
      "[CV 5/5] END min_samples_leaf=8, min_samples_split=2, n_estimators=102;, score=0.262 total time=  35.3s\n",
      "[CV 5/5] END min_samples_leaf=13, min_samples_split=9, n_estimators=175;, score=0.329 total time=  53.2s\n",
      "[CV 1/5] END min_samples_leaf=8, min_samples_split=8, n_estimators=10;, score=0.301 total time=   3.4s\n",
      "[CV 4/5] END min_samples_leaf=8, min_samples_split=8, n_estimators=10;, score=0.304 total time=   3.2s\n",
      "[CV 2/5] END min_samples_leaf=5, min_samples_split=4, n_estimators=78;, score=0.492 total time=  23.3s\n",
      "[CV 5/5] END min_samples_leaf=5, min_samples_split=4, n_estimators=78;, score=0.226 total time=  24.8s\n",
      "[CV 2/5] END min_samples_leaf=8, min_samples_split=5, n_estimators=151;, score=0.416 total time=  44.7s\n",
      "[CV 2/5] END min_samples_leaf=11, min_samples_split=5, n_estimators=43;, score=0.495 total time=  12.7s\n",
      "[CV 3/5] END min_samples_leaf=4, min_samples_split=3, n_estimators=54;, score=0.412 total time=  16.0s\n",
      "[CV 4/5] END min_samples_leaf=2, min_samples_split=7, n_estimators=184;, score=0.478 total time= 1.0min\n",
      "[CV 2/5] END min_samples_leaf=6, min_samples_split=9, n_estimators=124;, score=0.514 total time=  39.2s\n",
      "[CV 5/5] END min_samples_leaf=13, min_samples_split=6, n_estimators=146;, score=0.329 total time=  44.1s\n",
      "[CV 3/5] END min_samples_leaf=11, min_samples_split=4, n_estimators=119;, score=0.390 total time=  35.8s\n",
      "[CV 3/5] END min_samples_leaf=15, min_samples_split=9, n_estimators=37;, score=0.350 total time=  11.0s\n",
      "[CV 4/5] END min_samples_leaf=9, min_samples_split=7, n_estimators=185;, score=0.443 total time=  56.6s\n",
      "[CV 5/5] END min_samples_leaf=10, min_samples_split=8, n_estimators=71;, score=0.299 total time=  21.4s\n",
      "[CV 1/5] END min_samples_leaf=6, min_samples_split=4, n_estimators=182;, score=0.488 total time=  54.7s\n",
      "[CV 2/5] END min_samples_leaf=10, min_samples_split=7, n_estimators=69;, score=0.444 total time=  21.6s\n",
      "[CV 3/5] END min_samples_leaf=1, min_samples_split=5, n_estimators=168;, score=0.455 total time=  52.4s\n",
      "[CV 4/5] END min_samples_leaf=14, min_samples_split=3, n_estimators=78;, score=0.383 total time=  24.0s\n",
      "[CV 2/5] END min_samples_leaf=10, min_samples_split=9, n_estimators=199;, score=0.382 total time= 1.0min\n",
      "[CV 3/5] END min_samples_leaf=14, min_samples_split=5, n_estimators=134;, score=0.341 total time=  41.9s\n",
      "[CV 1/5] END min_samples_leaf=2, min_samples_split=9, n_estimators=112;, score=0.495 total time=  33.7s\n",
      "[CV 5/5] END min_samples_leaf=2, min_samples_split=9, n_estimators=112;, score=0.235 total time=  26.6s\n"
     ]
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    'n_estimators': randint(low=1, high=200),\n",
    "    'min_samples_split': randint(low = 1, high = 10),\n",
    "    'min_samples_leaf': randint(low = 1, high = 17)\n",
    "}\n",
    "\n",
    "GBM= GradientBoostingClassifier(random_state = 37)\n",
    "start = time.time()\n",
    "rand_cv = RandomizedSearchCV(GBM, \n",
    "                            param_distributions = param_distribs,\n",
    "                            cv = 5, \n",
    "                            n_iter = 50,\n",
    "                            scoring = 'f1_macro',\n",
    "                            n_jobs = -1,\n",
    "                            verbose = 3)\n",
    "rand_cv.fit(train_x, train_y)\n",
    "preds = rand_cv.predict(test_x)\n",
    "end = time.time()\n",
    "subGBM['Y_Class'] = preds\n",
    "subGBM.to_csv('./t21_GBM_random_dpo2.csv', index=False) #median으로 채우고 나머지 -100으로 채우고\n",
    "\n",
    "print(f'최적 하이퍼 파라미터: {rand_cv.best_params_}')\n",
    "print(f'최고 예측 정확도: {(rand_cv.best_score_)*100:.4f}')\n",
    "print(f'time elapsed: {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b7b86b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>310.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.912903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.443027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Y_Class\n",
       "count  310.000000\n",
       "mean     0.912903\n",
       "std      0.443027\n",
       "min      0.000000\n",
       "25%      1.000000\n",
       "50%      1.000000\n",
       "75%      1.000000\n",
       "max      2.000000"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subGBM.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "21275f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>310.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.274194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.835486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Y_Class\n",
       "count  310.000000\n",
       "mean     1.274194\n",
       "std      0.835486\n",
       "min      0.000000\n",
       "25%      1.000000\n",
       "50%      2.000000\n",
       "75%      2.000000\n",
       "max      2.000000"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subGBM.describe() #dp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f0341a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>310.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.880645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.592793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Y_Class\n",
       "count  310.000000\n",
       "mean     0.880645\n",
       "std      0.592793\n",
       "min      0.000000\n",
       "25%      1.000000\n",
       "50%      1.000000\n",
       "75%      1.000000\n",
       "max      2.000000"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subGBM_bf = pd.read_csv('./t10_GBM_RandomSearchCV_niter50.csv') #이전에 0.64 점수 받은 예측결과랑 비교\n",
    "subGBM_bf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f11346b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_df['Y_Quality']\n",
    "train_x2 = train_df['Y_Quality']\n",
    "train_y2 = train_df['Y_Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9970726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_df.drop(columns = ['PRODUCT_ID', 'TIMESTAMP', 'Y_Class', 'Y_Quality'])\n",
    "#모델 학습이 끝나고 예측에 쓰일 test데이터\n",
    "test_x = test_df.drop(columns=['PRODUCT_ID', 'TIMESTAMP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6c7f1aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# qualitative to quantitative\n",
    "qual_col = ['LINE', 'PRODUCT_CODE']\n",
    "\n",
    "for i in qual_col:\n",
    "    le = LabelEncoder()\n",
    "    le = le.fit(train_x[i]) #원래 column 값을 기준으로 fit.\n",
    "    train_x[i] = le.transform(train_x[i]) #수치화, 수치로 변형\n",
    "    \n",
    "    for label in np.unique(test_x[i]): \n",
    "        if label not in le.classes_: \n",
    "            le.classes_ = np.append(le.classes_, label)\n",
    "    test_x[i] = le.transform(test_x[i]) \n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f3bad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433c6dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e43dac7d",
   "metadata": {},
   "source": [
    "### RandomsearchCV로 RandomForestRegressor 파라미터 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "89842035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "최적 하이퍼 파라미터: {'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 21}\n",
      "최고 예측 정확도: 26.2010\n",
      "time elapsed: 150.85668992996216\n",
      "[CV 2/5] END max_depth=2, min_samples_leaf=1, min_samples_split=4, n_estimators=182;, score=0.318 total time=  10.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=4, min_samples_split=3, n_estimators=4;, score=0.111 total time=   0.4s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=2, min_samples_split=3, n_estimators=115;, score=0.276 total time=   8.1s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=4, min_samples_split=3, n_estimators=109;, score=0.168 total time=   8.3s\n",
      "[CV 3/5] END max_depth=2, min_samples_leaf=3, min_samples_split=4, n_estimators=131;, score=0.257 total time=   6.7s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=4, min_samples_split=2, n_estimators=54;, score=0.123 total time=   1.5s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=3, min_samples_split=4, n_estimators=168;, score=0.108 total time=   4.6s\n",
      "[CV 3/5] END max_depth=2, min_samples_leaf=4, min_samples_split=2, n_estimators=79;, score=0.252 total time=   4.0s\n",
      "[CV 5/5] END max_depth=2, min_samples_leaf=4, min_samples_split=2, n_estimators=79;, score=0.170 total time=   4.2s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=83;, score=0.246 total time=   5.8s\n",
      "[CV 5/5] END max_depth=2, min_samples_leaf=3, min_samples_split=1, n_estimators=32;, score=nan total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, min_samples_leaf=4, min_samples_split=2, n_estimators=8;, score=0.437 total time=   0.9s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=171;, score=0.361 total time=  12.3s\n",
      "[CV 1/5] END max_depth=2, min_samples_leaf=4, min_samples_split=4, n_estimators=17;, score=0.263 total time=   1.0s\n",
      "[CV 4/5] END max_depth=2, min_samples_leaf=4, min_samples_split=4, n_estimators=17;, score=-0.084 total time=   1.1s\n",
      "[CV 2/5] END max_depth=4, min_samples_leaf=1, min_samples_split=4, n_estimators=119;, score=0.406 total time=  12.1s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=3, min_samples_split=4, n_estimators=133;, score=0.113 total time=   4.2s\n",
      "[CV 1/5] END max_depth=4, min_samples_leaf=3, min_samples_split=4, n_estimators=125;, score=0.292 total time=  11.5s\n",
      "[CV 4/5] END max_depth=4, min_samples_leaf=4, min_samples_split=2, n_estimators=99;, score=0.086 total time=   9.9s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=4, min_samples_split=4, n_estimators=45;, score=0.212 total time=   1.3s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=4, min_samples_split=4, n_estimators=45;, score=0.118 total time=   1.3s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=4, min_samples_split=4, n_estimators=48;, score=0.136 total time=   1.3s\n",
      "[CV 1/5] END max_depth=2, min_samples_leaf=3, min_samples_split=1, n_estimators=193;, score=nan total time=   0.2s\n",
      "[CV 2/5] END max_depth=2, min_samples_leaf=3, min_samples_split=1, n_estimators=193;, score=nan total time=   0.2s\n",
      "[CV 4/5] END max_depth=2, min_samples_leaf=3, min_samples_split=1, n_estimators=193;, score=nan total time=   0.2s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=2, min_samples_split=1, n_estimators=181;, score=nan total time=   0.2s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=2, min_samples_split=1, n_estimators=181;, score=nan total time=   0.2s\n",
      "[CV 4/5] END max_depth=4, min_samples_leaf=1, min_samples_split=3, n_estimators=21;, score=0.099 total time=   2.2s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=2, min_samples_split=4, n_estimators=108;, score=0.164 total time=   8.5s\n",
      "[CV 2/5] END max_depth=2, min_samples_leaf=1, min_samples_split=2, n_estimators=126;, score=0.322 total time=   6.6s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=2, min_samples_split=2, n_estimators=35;, score=0.222 total time=   1.2s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=2, min_samples_split=2, n_estimators=35;, score=0.069 total time=   1.2s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=2, min_samples_split=3, n_estimators=40;, score=0.219 total time=   1.2s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=2, min_samples_split=3, n_estimators=40;, score=0.100 total time=   1.2s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=53;, score=0.299 total time=   3.7s\n",
      "[CV 2/5] END max_depth=4, min_samples_leaf=3, min_samples_split=1, n_estimators=139;, score=nan total time=   0.3s\n",
      "[CV 5/5] END max_depth=4, min_samples_leaf=3, min_samples_split=1, n_estimators=139;, score=nan total time=   0.2s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=3, min_samples_split=1, n_estimators=46;, score=nan total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=122;, score=0.256 total time=   8.6s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=122;, score=0.171 total time=   9.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=4, min_samples_split=3, n_estimators=109;, score=0.283 total time=   8.1s\n",
      "[CV 1/5] END max_depth=2, min_samples_leaf=3, min_samples_split=4, n_estimators=131;, score=0.271 total time=   6.4s\n",
      "[CV 1/5] END max_depth=2, min_samples_leaf=4, min_samples_split=1, n_estimators=67;, score=nan total time=   0.1s\n",
      "[CV 3/5] END max_depth=2, min_samples_leaf=4, min_samples_split=1, n_estimators=67;, score=nan total time=   0.1s\n",
      "[CV 5/5] END max_depth=2, min_samples_leaf=4, min_samples_split=1, n_estimators=67;, score=nan total time=   0.1s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=4, min_samples_split=2, n_estimators=54;, score=0.149 total time=   1.5s\n",
      "[CV 4/5] END max_depth=2, min_samples_leaf=1, min_samples_split=1, n_estimators=94;, score=nan total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=1, min_samples_split=1, n_estimators=15;, score=nan total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=1, min_samples_split=1, n_estimators=15;, score=nan total time=   0.1s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=3, min_samples_split=4, n_estimators=168;, score=0.158 total time=   4.6s\n",
      "[CV 5/5] END max_depth=4, min_samples_leaf=1, min_samples_split=2, n_estimators=87;, score=0.175 total time=   8.8s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=83;, score=0.290 total time=   6.0s\n",
      "[CV 4/5] END max_depth=4, min_samples_leaf=4, min_samples_split=2, n_estimators=8;, score=-0.055 total time=   0.8s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=2, min_samples_split=1, n_estimators=32;, score=nan total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=2, min_samples_split=1, n_estimators=32;, score=nan total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=2, min_samples_split=1, n_estimators=32;, score=nan total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=2, min_samples_split=1, n_estimators=32;, score=nan total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, min_samples_leaf=2, min_samples_split=3, n_estimators=185;, score=0.300 total time=  16.6s\n",
      "[CV 4/5] END max_depth=4, min_samples_leaf=1, min_samples_split=4, n_estimators=119;, score=0.080 total time=  12.1s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=4, min_samples_split=2, n_estimators=110;, score=0.144 total time=   3.2s\n",
      "[CV 1/5] END max_depth=2, min_samples_leaf=2, min_samples_split=4, n_estimators=80;, score=0.265 total time=   3.9s\n",
      "[CV 4/5] END max_depth=2, min_samples_leaf=2, min_samples_split=4, n_estimators=80;, score=0.005 total time=   4.1s\n",
      "[CV 2/5] END max_depth=4, min_samples_leaf=4, min_samples_split=2, n_estimators=99;, score=0.418 total time=   9.8s\n",
      "[CV 5/5] END max_depth=4, min_samples_leaf=2, min_samples_split=3, n_estimators=151;, score=0.172 total time=  14.8s\n",
      "[CV 3/5] END max_depth=4, min_samples_leaf=1, min_samples_split=3, n_estimators=145;, score=0.303 total time=  14.3s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=53;, score=0.002 total time=   3.8s\n",
      "[CV 3/5] END max_depth=4, min_samples_leaf=3, min_samples_split=1, n_estimators=139;, score=nan total time=   0.3s\n",
      "[CV 4/5] END max_depth=4, min_samples_leaf=3, min_samples_split=1, n_estimators=139;, score=nan total time=   0.2s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=3, min_samples_split=1, n_estimators=46;, score=nan total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=122;, score=0.359 total time=   9.3s\n",
      "[CV 1/5] END max_depth=2, min_samples_leaf=2, min_samples_split=1, n_estimators=107;, score=nan total time=   0.2s\n",
      "[CV 2/5] END max_depth=2, min_samples_leaf=2, min_samples_split=1, n_estimators=107;, score=nan total time=   0.2s\n",
      "[CV 5/5] END max_depth=2, min_samples_leaf=2, min_samples_split=1, n_estimators=107;, score=nan total time=   0.2s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=4, min_samples_split=3, n_estimators=109;, score=0.243 total time=   7.4s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=4, min_samples_split=3, n_estimators=109;, score=0.364 total time=   8.2s\n",
      "[CV 5/5] END max_depth=4, min_samples_leaf=4, min_samples_split=4, n_estimators=140;, score=0.175 total time=  13.3s\n",
      "[CV 4/5] END max_depth=4, min_samples_leaf=1, min_samples_split=2, n_estimators=87;, score=0.074 total time=   9.1s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=83;, score=0.040 total time=   6.2s\n",
      "[CV 5/5] END max_depth=4, min_samples_leaf=4, min_samples_split=2, n_estimators=8;, score=0.099 total time=   0.9s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=2, min_samples_split=1, n_estimators=32;, score=nan total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, min_samples_leaf=2, min_samples_split=3, n_estimators=185;, score=0.397 total time=  17.9s\n",
      "[CV 1/5] END max_depth=2, min_samples_leaf=1, min_samples_split=1, n_estimators=198;, score=nan total time=   0.2s\n",
      "[CV 2/5] END max_depth=2, min_samples_leaf=1, min_samples_split=1, n_estimators=198;, score=nan total time=   0.2s\n",
      "[CV 3/5] END max_depth=2, min_samples_leaf=1, min_samples_split=1, n_estimators=198;, score=nan total time=   0.2s\n",
      "[CV 4/5] END max_depth=2, min_samples_leaf=1, min_samples_split=1, n_estimators=198;, score=nan total time=   0.2s\n",
      "[CV 5/5] END max_depth=2, min_samples_leaf=1, min_samples_split=1, n_estimators=198;, score=nan total time=   0.2s\n",
      "[CV 1/5] END max_depth=4, min_samples_leaf=3, min_samples_split=1, n_estimators=13;, score=nan total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, min_samples_leaf=3, min_samples_split=1, n_estimators=13;, score=nan total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, min_samples_leaf=3, min_samples_split=1, n_estimators=13;, score=nan total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, min_samples_leaf=3, min_samples_split=1, n_estimators=13;, score=nan total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, min_samples_leaf=3, min_samples_split=1, n_estimators=13;, score=nan total time=   0.1s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=3, min_samples_split=4, n_estimators=133;, score=0.142 total time=   3.4s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=3, min_samples_split=4, n_estimators=133;, score=0.220 total time=   4.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=4, min_samples_split=2, n_estimators=110;, score=0.138 total time=   3.0s\n",
      "[CV 4/5] END max_depth=4, min_samples_leaf=3, min_samples_split=4, n_estimators=125;, score=0.039 total time=  12.4s\n",
      "[CV 2/5] END max_depth=4, min_samples_leaf=2, min_samples_split=3, n_estimators=151;, score=0.399 total time=  14.9s\n",
      "[CV 5/5] END max_depth=4, min_samples_leaf=1, min_samples_split=3, n_estimators=21;, score=0.145 total time=   2.2s\n",
      "[CV 1/5] END max_depth=4, min_samples_leaf=1, min_samples_split=3, n_estimators=145;, score=0.289 total time=  13.7s\n",
      "[CV 5/5] END max_depth=2, min_samples_leaf=1, min_samples_split=2, n_estimators=126;, score=0.161 total time=   6.6s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=53;, score=0.149 total time=   3.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END max_depth=2, min_samples_leaf=1, min_samples_split=4, n_estimators=182;, score=0.005 total time=  10.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=4, min_samples_split=3, n_estimators=4;, score=-0.088 total time=   0.4s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=2, min_samples_split=3, n_estimators=115;, score=0.357 total time=   8.7s\n",
      "[CV 2/5] END max_depth=4, min_samples_leaf=4, min_samples_split=4, n_estimators=140;, score=0.415 total time=  13.6s\n",
      "[CV 2/5] END max_depth=2, min_samples_leaf=4, min_samples_split=1, n_estimators=67;, score=nan total time=   0.1s\n",
      "[CV 4/5] END max_depth=2, min_samples_leaf=4, min_samples_split=1, n_estimators=67;, score=nan total time=   0.1s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=4, min_samples_split=2, n_estimators=54;, score=0.226 total time=   1.5s\n",
      "[CV 3/5] END max_depth=2, min_samples_leaf=1, min_samples_split=1, n_estimators=94;, score=nan total time=   0.1s\n",
      "[CV 5/5] END max_depth=2, min_samples_leaf=1, min_samples_split=1, n_estimators=94;, score=nan total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=1, min_samples_split=1, n_estimators=15;, score=nan total time=   0.1s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=3, min_samples_split=4, n_estimators=168;, score=0.220 total time=   4.6s\n",
      "[CV 1/5] END max_depth=2, min_samples_leaf=4, min_samples_split=2, n_estimators=79;, score=0.271 total time=   3.9s\n",
      "[CV 4/5] END max_depth=2, min_samples_leaf=4, min_samples_split=2, n_estimators=79;, score=0.011 total time=   4.2s\n",
      "[CV 4/5] END max_depth=2, min_samples_leaf=1, min_samples_split=3, n_estimators=51;, score=-0.015 total time=   2.8s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=3, min_samples_split=2, n_estimators=96;, score=0.222 total time=   2.7s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=3, min_samples_split=2, n_estimators=96;, score=0.108 total time=   2.7s\n",
      "[CV 3/5] END max_depth=4, min_samples_leaf=2, min_samples_split=3, n_estimators=185;, score=0.298 total time=  17.7s\n",
      "[CV 5/5] END max_depth=4, min_samples_leaf=1, min_samples_split=4, n_estimators=119;, score=0.164 total time=  12.3s\n",
      "[CV 3/5] END max_depth=4, min_samples_leaf=3, min_samples_split=4, n_estimators=125;, score=0.307 total time=  12.1s\n",
      "[CV 5/5] END max_depth=4, min_samples_leaf=4, min_samples_split=2, n_estimators=99;, score=0.179 total time=   9.7s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=4, min_samples_split=4, n_estimators=45;, score=0.127 total time=   1.2s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=4, min_samples_split=4, n_estimators=48;, score=0.139 total time=   1.2s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=4, min_samples_split=4, n_estimators=48;, score=0.069 total time=   1.3s\n",
      "[CV 3/5] END max_depth=2, min_samples_leaf=3, min_samples_split=1, n_estimators=193;, score=nan total time=   0.2s\n",
      "[CV 5/5] END max_depth=2, min_samples_leaf=3, min_samples_split=1, n_estimators=193;, score=nan total time=   0.2s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=2, min_samples_split=1, n_estimators=181;, score=nan total time=   0.2s\n",
      "[CV 3/5] END max_depth=4, min_samples_leaf=1, min_samples_split=3, n_estimators=21;, score=0.272 total time=   2.1s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=2, min_samples_split=4, n_estimators=108;, score=0.287 total time=   8.4s\n",
      "[CV 1/5] END max_depth=2, min_samples_leaf=1, min_samples_split=2, n_estimators=126;, score=0.260 total time=   6.2s\n",
      "[CV 4/5] END max_depth=2, min_samples_leaf=1, min_samples_split=2, n_estimators=126;, score=0.009 total time=   6.8s\n",
      "[CV 1/5] END max_depth=2, min_samples_leaf=3, min_samples_split=4, n_estimators=162;, score=0.265 total time=   6.7s\n",
      "[CV 1/5] END max_depth=4, min_samples_leaf=3, min_samples_split=1, n_estimators=139;, score=nan total time=   0.3s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=3, min_samples_split=1, n_estimators=46;, score=nan total time=   0.1s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=3, min_samples_split=1, n_estimators=46;, score=nan total time=   0.1s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=3, min_samples_split=1, n_estimators=46;, score=nan total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=122;, score=0.279 total time=   9.3s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=4, min_samples_split=3, n_estimators=4;, score=0.160 total time=   0.4s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=2, min_samples_split=3, n_estimators=115;, score=0.050 total time=   8.7s\n",
      "[CV 4/5] END max_depth=4, min_samples_leaf=4, min_samples_split=4, n_estimators=140;, score=0.080 total time=  13.8s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=4, min_samples_split=2, n_estimators=54;, score=0.141 total time=   1.4s\n",
      "[CV 1/5] END max_depth=2, min_samples_leaf=1, min_samples_split=1, n_estimators=94;, score=nan total time=   0.1s\n",
      "[CV 2/5] END max_depth=2, min_samples_leaf=1, min_samples_split=1, n_estimators=94;, score=nan total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=1, min_samples_split=1, n_estimators=15;, score=nan total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=1, min_samples_split=1, n_estimators=15;, score=nan total time=   0.1s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=3, min_samples_split=4, n_estimators=168;, score=0.141 total time=   4.3s\n",
      "[CV 3/5] END max_depth=4, min_samples_leaf=1, min_samples_split=2, n_estimators=87;, score=0.289 total time=   8.8s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=83;, score=0.369 total time=   6.2s\n",
      "[CV 3/5] END max_depth=4, min_samples_leaf=4, min_samples_split=2, n_estimators=8;, score=0.182 total time=   0.8s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=171;, score=0.012 total time=  12.4s\n",
      "[CV 3/5] END max_depth=2, min_samples_leaf=4, min_samples_split=4, n_estimators=17;, score=0.226 total time=   1.0s\n",
      "[CV 1/5] END max_depth=4, min_samples_leaf=1, min_samples_split=4, n_estimators=119;, score=0.292 total time=  11.2s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=3, min_samples_split=4, n_estimators=133;, score=0.152 total time=   4.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=4, min_samples_split=2, n_estimators=110;, score=0.215 total time=   3.2s\n",
      "[CV 5/5] END max_depth=4, min_samples_leaf=3, min_samples_split=4, n_estimators=125;, score=0.176 total time=  12.3s\n",
      "[CV 3/5] END max_depth=4, min_samples_leaf=2, min_samples_split=3, n_estimators=151;, score=0.303 total time=  14.4s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=2, min_samples_split=4, n_estimators=108;, score=0.265 total time=   8.1s\n",
      "[CV 4/5] END max_depth=4, min_samples_leaf=1, min_samples_split=3, n_estimators=145;, score=0.073 total time=  14.7s\n",
      "[CV 2/5] END max_depth=2, min_samples_leaf=3, min_samples_split=4, n_estimators=162;, score=0.319 total time=   7.0s\n",
      "[CV 3/5] END max_depth=2, min_samples_leaf=1, min_samples_split=4, n_estimators=182;, score=0.249 total time=   9.6s\n",
      "[CV 1/5] END max_depth=2, min_samples_leaf=2, min_samples_split=1, n_estimators=2;, score=nan total time=   0.1s\n",
      "[CV 2/5] END max_depth=2, min_samples_leaf=2, min_samples_split=1, n_estimators=2;, score=nan total time=   0.1s\n",
      "[CV 4/5] END max_depth=2, min_samples_leaf=2, min_samples_split=1, n_estimators=2;, score=nan total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=4, min_samples_split=3, n_estimators=4;, score=0.200 total time=   0.4s\n",
      "[CV 3/5] END max_depth=2, min_samples_leaf=2, min_samples_split=1, n_estimators=107;, score=nan total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=2, min_samples_split=3, n_estimators=115;, score=0.285 total time=   8.4s\n",
      "[CV 1/5] END max_depth=4, min_samples_leaf=4, min_samples_split=4, n_estimators=140;, score=0.304 total time=  12.7s\n",
      "[CV 4/5] END max_depth=2, min_samples_leaf=3, min_samples_split=4, n_estimators=131;, score=-0.004 total time=   6.6s\n",
      "[CV 1/5] END max_depth=4, min_samples_leaf=1, min_samples_split=2, n_estimators=87;, score=0.291 total time=   8.2s\n",
      "[CV 2/5] END max_depth=2, min_samples_leaf=1, min_samples_split=3, n_estimators=51;, score=0.333 total time=   2.8s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=83;, score=0.183 total time=   6.1s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=171;, score=0.169 total time=  12.1s\n",
      "[CV 2/5] END max_depth=2, min_samples_leaf=4, min_samples_split=4, n_estimators=17;, score=0.333 total time=   1.0s\n",
      "[CV 5/5] END max_depth=2, min_samples_leaf=4, min_samples_split=4, n_estimators=17;, score=0.156 total time=   1.0s\n",
      "[CV 3/5] END max_depth=4, min_samples_leaf=1, min_samples_split=4, n_estimators=119;, score=0.281 total time=  11.7s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=3, min_samples_split=4, n_estimators=133;, score=0.059 total time=   4.1s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=4, min_samples_split=2, n_estimators=110;, score=0.116 total time=   3.2s\n",
      "[CV 3/5] END max_depth=2, min_samples_leaf=2, min_samples_split=4, n_estimators=80;, score=0.249 total time=   4.2s\n",
      "[CV 5/5] END max_depth=2, min_samples_leaf=2, min_samples_split=4, n_estimators=80;, score=0.164 total time=   4.0s\n",
      "[CV 3/5] END max_depth=4, min_samples_leaf=4, min_samples_split=2, n_estimators=99;, score=0.280 total time=   9.7s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=4, min_samples_split=4, n_estimators=45;, score=0.137 total time=   1.2s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=4, min_samples_split=4, n_estimators=45;, score=0.069 total time=   1.2s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=4, min_samples_split=4, n_estimators=48;, score=0.224 total time=   1.3s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=4, min_samples_split=4, n_estimators=48;, score=0.120 total time=   1.3s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=2, min_samples_split=1, n_estimators=181;, score=nan total time=   0.2s\n",
      "[CV 1/5] END max_depth=4, min_samples_leaf=1, min_samples_split=3, n_estimators=21;, score=0.350 total time=   2.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=2, min_samples_split=4, n_estimators=108;, score=0.350 total time=   8.5s\n",
      "[CV 5/5] END max_depth=4, min_samples_leaf=1, min_samples_split=3, n_estimators=145;, score=0.167 total time=  14.4s\n",
      "[CV 3/5] END max_depth=2, min_samples_leaf=3, min_samples_split=4, n_estimators=162;, score=0.262 total time=   6.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END max_depth=2, min_samples_leaf=1, min_samples_split=4, n_estimators=182;, score=0.256 total time=   9.2s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=122;, score=0.033 total time=   9.2s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=4, min_samples_split=3, n_estimators=109;, score=0.031 total time=   8.3s\n",
      "[CV 2/5] END max_depth=2, min_samples_leaf=3, min_samples_split=4, n_estimators=131;, score=0.319 total time=   6.8s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=4, min_samples_split=2, n_estimators=54;, score=0.069 total time=   1.5s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=3, min_samples_split=4, n_estimators=168;, score=0.057 total time=   4.7s\n",
      "[CV 2/5] END max_depth=2, min_samples_leaf=4, min_samples_split=2, n_estimators=79;, score=0.331 total time=   4.1s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=4, min_samples_split=1, n_estimators=18;, score=nan total time=   0.1s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=4, min_samples_split=1, n_estimators=18;, score=nan total time=   0.1s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=4, min_samples_split=1, n_estimators=18;, score=nan total time=   0.1s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=4, min_samples_split=1, n_estimators=18;, score=nan total time=   0.1s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=4, min_samples_split=1, n_estimators=18;, score=nan total time=   0.1s\n",
      "[CV 1/5] END max_depth=2, min_samples_leaf=1, min_samples_split=3, n_estimators=51;, score=0.275 total time=   2.6s\n",
      "[CV 3/5] END max_depth=2, min_samples_leaf=1, min_samples_split=3, n_estimators=51;, score=0.236 total time=   2.8s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=3, min_samples_split=2, n_estimators=96;, score=0.139 total time=   2.5s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=3, min_samples_split=2, n_estimators=96;, score=0.046 total time=   2.6s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=171;, score=0.306 total time=  12.1s\n",
      "[CV 5/5] END max_depth=4, min_samples_leaf=2, min_samples_split=3, n_estimators=185;, score=0.175 total time=  18.6s\n",
      "[CV 2/5] END max_depth=4, min_samples_leaf=3, min_samples_split=4, n_estimators=125;, score=0.411 total time=  12.4s\n",
      "[CV 1/5] END max_depth=4, min_samples_leaf=2, min_samples_split=3, n_estimators=151;, score=0.292 total time=  13.8s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=2, min_samples_split=1, n_estimators=181;, score=nan total time=   0.2s\n",
      "[CV 2/5] END max_depth=4, min_samples_leaf=1, min_samples_split=3, n_estimators=21;, score=0.444 total time=   2.2s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=2, min_samples_split=4, n_estimators=108;, score=0.046 total time=   8.6s\n",
      "[CV 3/5] END max_depth=2, min_samples_leaf=1, min_samples_split=2, n_estimators=126;, score=0.247 total time=   6.5s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=2, min_samples_split=2, n_estimators=35;, score=0.138 total time=   1.1s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=2, min_samples_split=2, n_estimators=35;, score=0.160 total time=   1.1s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=2, min_samples_split=2, n_estimators=35;, score=0.101 total time=   1.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=2, min_samples_split=3, n_estimators=40;, score=0.152 total time=   1.2s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=53;, score=0.276 total time=   3.5s\n",
      "[CV 4/5] END max_depth=2, min_samples_leaf=3, min_samples_split=4, n_estimators=162;, score=-0.004 total time=   6.5s\n",
      "[CV 5/5] END max_depth=2, min_samples_leaf=1, min_samples_split=4, n_estimators=182;, score=0.152 total time=   9.8s\n",
      "[CV 3/5] END max_depth=2, min_samples_leaf=2, min_samples_split=1, n_estimators=2;, score=nan total time=   0.1s\n",
      "[CV 5/5] END max_depth=2, min_samples_leaf=2, min_samples_split=1, n_estimators=2;, score=nan total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=4, min_samples_split=3, n_estimators=4;, score=0.385 total time=   0.4s\n",
      "[CV 4/5] END max_depth=2, min_samples_leaf=2, min_samples_split=1, n_estimators=107;, score=nan total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=2, min_samples_split=3, n_estimators=115;, score=0.167 total time=   8.6s\n",
      "[CV 3/5] END max_depth=4, min_samples_leaf=4, min_samples_split=4, n_estimators=140;, score=0.282 total time=  13.4s\n",
      "[CV 5/5] END max_depth=2, min_samples_leaf=3, min_samples_split=4, n_estimators=131;, score=0.155 total time=   6.6s\n",
      "[CV 2/5] END max_depth=4, min_samples_leaf=1, min_samples_split=2, n_estimators=87;, score=0.398 total time=   8.9s\n",
      "[CV 5/5] END max_depth=2, min_samples_leaf=1, min_samples_split=3, n_estimators=51;, score=0.147 total time=   2.8s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=3, min_samples_split=2, n_estimators=96;, score=0.147 total time=   2.6s\n",
      "[CV 1/5] END max_depth=2, min_samples_leaf=3, min_samples_split=1, n_estimators=32;, score=nan total time=   0.1s\n",
      "[CV 2/5] END max_depth=2, min_samples_leaf=3, min_samples_split=1, n_estimators=32;, score=nan total time=   0.1s\n",
      "[CV 3/5] END max_depth=2, min_samples_leaf=3, min_samples_split=1, n_estimators=32;, score=nan total time=   0.1s\n",
      "[CV 4/5] END max_depth=2, min_samples_leaf=3, min_samples_split=1, n_estimators=32;, score=nan total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, min_samples_leaf=4, min_samples_split=2, n_estimators=8;, score=0.306 total time=   0.8s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=171;, score=0.262 total time=  11.4s\n",
      "[CV 4/5] END max_depth=4, min_samples_leaf=2, min_samples_split=3, n_estimators=185;, score=0.073 total time=  19.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=4, min_samples_split=2, n_estimators=110;, score=0.054 total time=   3.4s\n",
      "[CV 2/5] END max_depth=2, min_samples_leaf=2, min_samples_split=4, n_estimators=80;, score=0.328 total time=   4.3s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=4, min_samples_split=1, n_estimators=32;, score=nan total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=4, min_samples_split=1, n_estimators=32;, score=nan total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=4, min_samples_split=1, n_estimators=32;, score=nan total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=4, min_samples_split=1, n_estimators=32;, score=nan total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=4, min_samples_split=1, n_estimators=32;, score=nan total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, min_samples_leaf=4, min_samples_split=2, n_estimators=99;, score=0.301 total time=   9.0s\n",
      "[CV 4/5] END max_depth=4, min_samples_leaf=2, min_samples_split=3, n_estimators=151;, score=0.075 total time=  14.8s\n",
      "[CV 2/5] END max_depth=4, min_samples_leaf=1, min_samples_split=3, n_estimators=145;, score=0.412 total time=  15.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=2, min_samples_split=3, n_estimators=40;, score=0.134 total time=   1.1s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=2, min_samples_split=3, n_estimators=40;, score=0.066 total time=   1.2s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=53;, score=0.372 total time=   3.8s\n",
      "[CV 5/5] END max_depth=2, min_samples_leaf=3, min_samples_split=4, n_estimators=162;, score=0.150 total time=   6.3s\n"
     ]
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    'n_estimators' : randint(low=1, high=200),\n",
    "    'max_depth' : randint(low = 1, high = 5),\n",
    "    'min_samples_split': randint(low = 1.0, high = 5.0),\n",
    "    'min_samples_leaf': randint(low = 1, high = 5)\n",
    "}\n",
    "\n",
    "rf_rgr= RandomForestRegressor(random_state=37)\n",
    "start = time.time()\n",
    "rand_cv = RandomizedSearchCV(rf_rgr, \n",
    "                            param_distributions=param_distribs,\n",
    "                            cv = 5, \n",
    "                            n_iter = 50,\n",
    "#                             scoring = 'binary',\n",
    "                            n_jobs = -1,\n",
    "                            verbose=3)\n",
    "rand_cv.fit(train_x, train_y)\n",
    "test_x2 = rand_cv.predict(test_x)\n",
    "end = time.time()\n",
    "\n",
    "print(f'최적 하이퍼 파라미터: {rand_cv.best_params_}')\n",
    "print(f'최고 예측 정확도: {(rand_cv.best_score_)*100:.4f}')\n",
    "print(f'time elapsed: {end-start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34037b51",
   "metadata": {},
   "source": [
    "### SVM randomsearch로 파라미터 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4d398314",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LINE</th>\n",
       "      <th>PRODUCT_CODE</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>X_5</th>\n",
       "      <th>X_6</th>\n",
       "      <th>X_7</th>\n",
       "      <th>X_8</th>\n",
       "      <th>...</th>\n",
       "      <th>X_2866</th>\n",
       "      <th>X_2867</th>\n",
       "      <th>X_2868</th>\n",
       "      <th>X_2869</th>\n",
       "      <th>X_2870</th>\n",
       "      <th>X_2871</th>\n",
       "      <th>X_2872</th>\n",
       "      <th>X_2873</th>\n",
       "      <th>X_2874</th>\n",
       "      <th>X_2875</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.34</td>\n",
       "      <td>40.89</td>\n",
       "      <td>32.56</td>\n",
       "      <td>34.09</td>\n",
       "      <td>77.77</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.89</td>\n",
       "      <td>42.82</td>\n",
       "      <td>43.92</td>\n",
       "      <td>35.34</td>\n",
       "      <td>72.55</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.19</td>\n",
       "      <td>36.65</td>\n",
       "      <td>42.47</td>\n",
       "      <td>36.53</td>\n",
       "      <td>78.35</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>37.74</td>\n",
       "      <td>39.17</td>\n",
       "      <td>52.17</td>\n",
       "      <td>30.58</td>\n",
       "      <td>71.78</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.70</td>\n",
       "      <td>41.89</td>\n",
       "      <td>46.93</td>\n",
       "      <td>33.09</td>\n",
       "      <td>76.97</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>49.47</td>\n",
       "      <td>53.07</td>\n",
       "      <td>50.89</td>\n",
       "      <td>55.10</td>\n",
       "      <td>66.49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>598 rows × 2877 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LINE  PRODUCT_CODE    X_1    X_2    X_3    X_4    X_5    X_6    X_7  \\\n",
       "0       2             0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0   \n",
       "1       3             0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0   \n",
       "2       2             0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0   \n",
       "3       3             0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0   \n",
       "4       2             0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0   \n",
       "..    ...           ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "593     5             2    2.0   95.0    0.0   45.0   10.0    0.0   50.0   \n",
       "594     2             0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0   \n",
       "595     2             0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0   \n",
       "596     4             1   40.0   94.0    0.0   45.0   11.0    0.0   45.0   \n",
       "597     5             1   21.0   87.0    0.0   45.0   10.0    0.0   61.0   \n",
       "\n",
       "       X_8  ...  X_2866  X_2867  X_2868  X_2869  X_2870  X_2871  X_2872  \\\n",
       "0   -100.0  ...   39.34   40.89   32.56   34.09   77.77  -100.0  -100.0   \n",
       "1   -100.0  ...   38.89   42.82   43.92   35.34   72.55  -100.0  -100.0   \n",
       "2   -100.0  ...   39.19   36.65   42.47   36.53   78.35  -100.0  -100.0   \n",
       "3   -100.0  ...   37.74   39.17   52.17   30.58   71.78  -100.0  -100.0   \n",
       "4   -100.0  ...   38.70   41.89   46.93   33.09   76.97  -100.0  -100.0   \n",
       "..     ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "593   10.0  ... -100.00 -100.00 -100.00 -100.00 -100.00  -100.0  -100.0   \n",
       "594 -100.0  ...   49.47   53.07   50.89   55.10   66.49     1.0  -100.0   \n",
       "595 -100.0  ... -100.00 -100.00 -100.00 -100.00 -100.00     1.0  -100.0   \n",
       "596   10.0  ... -100.00 -100.00 -100.00 -100.00 -100.00  -100.0  -100.0   \n",
       "597   10.0  ... -100.00 -100.00 -100.00 -100.00 -100.00  -100.0  -100.0   \n",
       "\n",
       "     X_2873  X_2874  X_2875  \n",
       "0    -100.0  -100.0  -100.0  \n",
       "1    -100.0  -100.0  -100.0  \n",
       "2    -100.0  -100.0  -100.0  \n",
       "3    -100.0  -100.0  -100.0  \n",
       "4    -100.0  -100.0  -100.0  \n",
       "..      ...     ...     ...  \n",
       "593  -100.0  -100.0  -100.0  \n",
       "594  -100.0  -100.0  -100.0  \n",
       "595  -100.0  -100.0  -100.0  \n",
       "596  -100.0  -100.0  -100.0  \n",
       "597  -100.0  -100.0  -100.0  \n",
       "\n",
       "[598 rows x 2877 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d80ad9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x2 = pd.DataFrame(test_x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e0f3be40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x2 = pd.DataFrame(train_x2)\n",
    "train_y2 = pd.DataFrame(train_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6662b882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "최적 하이퍼 파라미터: {'C': 2}\n",
      "최고 예측 정확도: 98.2553\n",
      "time elapsed: 3.735036849975586\n"
     ]
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    'C' : randint(low= 0, high=3)\n",
    "}\n",
    "\n",
    "clf = svm.SVC(random_state = 37, kernel='rbf')\n",
    "start = time.time()\n",
    "rand_cv2 = RandomizedSearchCV(clf, \n",
    "                            param_distributions=param_distribs,\n",
    "                            cv = 5, \n",
    "                            n_iter = 50,\n",
    "                            scoring = 'f1_macro',\n",
    "                            n_jobs = -1,\n",
    "                            verbose=3)\n",
    "rand_cv2.fit(train_x2, train_y2)\n",
    "preds = rand_cv2.predict(test_x2)\n",
    "subRFSVM['Y_Class'] = preds\n",
    "subRFSVM.to_csv('./t21_RFRegressor_SVM_dpo2.csv', index = False)\n",
    "end = time.time()\n",
    "\n",
    "print(f'최적 하이퍼 파라미터: {rand_cv2.best_params_}')\n",
    "print(f'최고 예측 정확도: {(rand_cv2.best_score_)*100:.4f}')\n",
    "print(f'time elapsed: {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0e9d529e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>310.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.022581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.148803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Y_Class\n",
       "count  310.000000\n",
       "mean     1.022581\n",
       "std      0.148803\n",
       "min      1.000000\n",
       "25%      1.000000\n",
       "50%      1.000000\n",
       "75%      1.000000\n",
       "max      2.000000"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subRFSVM.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2d93a2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>310.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.025806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.158814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Y_Class\n",
       "count  310.000000\n",
       "mean     1.025806\n",
       "std      0.158814\n",
       "min      1.000000\n",
       "25%      1.000000\n",
       "50%      1.000000\n",
       "75%      1.000000\n",
       "max      2.000000"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subRFSVM.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "98a627bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>310.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.022581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.148803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Y_Class\n",
       "count  310.000000\n",
       "mean     1.022581\n",
       "std      0.148803\n",
       "min      1.000000\n",
       "25%      1.000000\n",
       "50%      1.000000\n",
       "75%      1.000000\n",
       "max      2.000000"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...............................C=1;, score=0.934 total time=   0.0s\n",
      "[CV 1/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=1;, score=0.934 total time=   0.0s\n",
      "[CV 1/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...............................C=1;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=1;, score=0.978 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=1;, score=0.934 total time=   0.0s\n",
      "[CV 1/5] END ...............................C=1;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...............................C=1;, score=0.978 total time=   0.0s\n",
      "[CV 3/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...............................C=1;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...............................C=2;, score=0.989 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=2;, score=0.978 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=2;, score=0.978 total time=   0.0s\n",
      "[CV 2/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=2;, score=0.978 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=2;, score=0.946 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=2;, score=0.946 total time=   0.0s\n",
      "[CV 1/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=2;, score=0.978 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=2;, score=0.946 total time=   0.0s\n",
      "[CV 1/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...............................C=2;, score=0.989 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=2;, score=0.978 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=2;, score=0.978 total time=   0.0s\n",
      "[CV 4/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...............................C=1;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ...............................C=1;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...............................C=1;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...............................C=2;, score=0.989 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=2;, score=0.978 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=2;, score=0.946 total time=   0.0s\n",
      "[CV 1/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...............................C=1;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...............................C=1;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=1;, score=0.978 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=1;, score=0.934 total time=   0.0s\n",
      "[CV 3/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...............................C=1;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...............................C=1;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...............................C=1;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=1;, score=0.978 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=1;, score=0.934 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=2;, score=0.946 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=1;, score=0.978 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=2;, score=0.978 total time=   0.0s\n",
      "[CV 3/5] END ...............................C=1;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=1;, score=0.978 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=1;, score=0.934 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=2;, score=0.978 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=2;, score=0.946 total time=   0.0s\n",
      "[CV 1/5] END ...............................C=1;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...............................C=2;, score=0.989 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=2;, score=0.946 total time=   0.0s\n",
      "[CV 1/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...............................C=2;, score=0.989 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=2;, score=0.978 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=2;, score=0.946 total time=   0.0s\n",
      "[CV 2/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...............................C=2;, score=0.989 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=2;, score=0.978 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=2;, score=0.946 total time=   0.0s\n",
      "[CV 4/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...............................C=1;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...............................C=1;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...............................C=1;, score=0.934 total time=   0.0s\n",
      "[CV 4/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...............................C=1;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END ...............................C=2;, score=0.989 total time=   0.0s\n",
      "[CV 3/5] END ...............................C=1;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END ...............................C=1;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END ...............................C=1;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...............................C=1;, score=0.978 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=2;, score=0.946 total time=   0.0s\n",
      "[CV 3/5] END ...............................C=2;, score=0.989 total time=   0.0s\n",
      "[CV 3/5] END ...............................C=1;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=2;, score=0.978 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=2;, score=0.946 total time=   0.0s\n",
      "[CV 3/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...............................C=2;, score=0.989 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=2;, score=0.978 total time=   0.0s\n",
      "[CV 5/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...............................C=2;, score=0.989 total time=   0.0s\n",
      "[CV 2/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...............................C=2;, score=0.989 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=2;, score=0.978 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=2;, score=0.946 total time=   0.0s\n",
      "[CV 5/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...............................C=2;, score=0.989 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=2;, score=0.978 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=2;, score=0.946 total time=   0.0s\n",
      "[CV 1/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...............................C=1;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...............................C=1;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...............................C=1;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...............................C=1;, score=1.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...............................C=1;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...............................C=2;, score=0.989 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=1;, score=0.978 total time=   0.0s\n",
      "[CV 3/5] END ...............................C=2;, score=0.989 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=2;, score=0.978 total time=   0.0s\n",
      "[CV 1/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...............................C=2;, score=0.989 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=2;, score=0.978 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=2;, score=0.946 total time=   0.0s\n",
      "[CV 1/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=2;, score=0.946 total time=   0.0s\n",
      "[CV 1/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...............................C=2;, score=0.989 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=2;, score=0.978 total time=   0.0s\n",
      "[CV 3/5] END ...............................C=2;, score=0.989 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=2;, score=0.978 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=2;, score=0.946 total time=   0.0s\n",
      "[CV 1/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...............................C=2;, score=0.989 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=2;, score=0.978 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=2;, score=0.946 total time=   0.0s\n",
      "[CV 1/5] END ...............................C=1;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ...............................C=1;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ...............................C=1;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...............................C=2;, score=0.946 total time=   0.0s\n",
      "[CV 1/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...............................C=2;, score=0.989 total time=   0.0s\n",
      "[CV 1/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=1;, score=0.978 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=1;, score=0.934 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=1;, score=0.934 total time=   0.0s\n",
      "[CV 3/5] END ...............................C=1;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...............................C=1;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=2;, score=0.946 total time=   0.0s\n",
      "[CV 1/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...............................C=2;, score=0.989 total time=   0.0s\n",
      "[CV 4/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...............................C=1;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...............................C=1;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...............................C=1;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=1;, score=0.978 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=1;, score=0.934 total time=   0.0s\n",
      "[CV 1/5] END ...............................C=2;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .................................C=0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...............................C=1;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...............................C=1;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...............................C=1;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=1;, score=0.934 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=2;, score=0.946 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=1;, score=0.934 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=1;, score=0.978 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=1;, score=0.978 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kimminyoung/opt/anaconda3/envs/pas/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "subFRSVM_bf = pd.read_csv('./t20_RFRegressor_SVM_random.csv') #이전에 한 것\n",
    "subFRSVM_bf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4645a39a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c1891a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0494a0b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7bdfe307",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = GradientBoostingClassifier(random_state = 37, min_samples_leaf = 2, min_samples_split = 8, n_estimators = 22)\n",
    "gbm.fit(train_x, train_y)\n",
    "pred = gbm.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a52c3276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = train_df.columns[63:115]\n",
    "importances = gbm.feature_importances_[63:115]\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.title('Feature Importances by GBM')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6c34de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e31f28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e49c3a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0efedc32",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>Y_Class</th>\n",
       "      <th>Y_Quality</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>LINE</th>\n",
       "      <th>PRODUCT_CODE</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>...</th>\n",
       "      <th>X_2866</th>\n",
       "      <th>X_2867</th>\n",
       "      <th>X_2868</th>\n",
       "      <th>X_2869</th>\n",
       "      <th>X_2870</th>\n",
       "      <th>X_2871</th>\n",
       "      <th>X_2872</th>\n",
       "      <th>X_2873</th>\n",
       "      <th>X_2874</th>\n",
       "      <th>X_2875</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_022</td>\n",
       "      <td>0</td>\n",
       "      <td>0.517719</td>\n",
       "      <td>2022-06-14 8:53</td>\n",
       "      <td>T100304</td>\n",
       "      <td>T_31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_023</td>\n",
       "      <td>0</td>\n",
       "      <td>0.519090</td>\n",
       "      <td>2022-06-14 9:01</td>\n",
       "      <td>T100304</td>\n",
       "      <td>T_31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_028</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521249</td>\n",
       "      <td>2022-06-19 20:26</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_034</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521524</td>\n",
       "      <td>2022-06-21 17:36</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>55.03</td>\n",
       "      <td>52.24</td>\n",
       "      <td>55.33</td>\n",
       "      <td>57.49</td>\n",
       "      <td>67.31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_066</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524408</td>\n",
       "      <td>2022-06-25 21:38</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>TRAIN_583</td>\n",
       "      <td>0</td>\n",
       "      <td>0.522340</td>\n",
       "      <td>2022-09-05 8:34</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>51.71</td>\n",
       "      <td>59.64</td>\n",
       "      <td>54.61</td>\n",
       "      <td>57.05</td>\n",
       "      <td>63.18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>TRAIN_584</td>\n",
       "      <td>0</td>\n",
       "      <td>0.519519</td>\n",
       "      <td>2022-09-05 11:09</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>TRAIN_585</td>\n",
       "      <td>0</td>\n",
       "      <td>0.515214</td>\n",
       "      <td>2022-09-05 11:17</td>\n",
       "      <td>T010306</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>TRAIN_594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524022</td>\n",
       "      <td>2022-09-08 22:38</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>49.47</td>\n",
       "      <td>53.07</td>\n",
       "      <td>50.89</td>\n",
       "      <td>55.10</td>\n",
       "      <td>66.49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>TRAIN_595</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521289</td>\n",
       "      <td>2022-09-08 22:47</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 2881 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PRODUCT_ID  Y_Class  Y_Quality         TIMESTAMP     LINE PRODUCT_CODE  \\\n",
       "0   TRAIN_022        0   0.517719   2022-06-14 8:53  T100304         T_31   \n",
       "1   TRAIN_023        0   0.519090   2022-06-14 9:01  T100304         T_31   \n",
       "2   TRAIN_028        0   0.521249  2022-06-19 20:26  T010305         A_31   \n",
       "3   TRAIN_034        0   0.521524  2022-06-21 17:36  T050304         A_31   \n",
       "4   TRAIN_066        0   0.524408  2022-06-25 21:38  T010305         A_31   \n",
       "..        ...      ...        ...               ...      ...          ...   \n",
       "83  TRAIN_583        0   0.522340   2022-09-05 8:34  T050304         A_31   \n",
       "84  TRAIN_584        0   0.519519  2022-09-05 11:09  T010305         A_31   \n",
       "85  TRAIN_585        0   0.515214  2022-09-05 11:17  T010306         A_31   \n",
       "86  TRAIN_594        0   0.524022  2022-09-08 22:38  T050304         A_31   \n",
       "87  TRAIN_595        0   0.521289  2022-09-08 22:47  T050304         A_31   \n",
       "\n",
       "    X_1    X_2  X_3   X_4  ...  X_2866  X_2867  X_2868  X_2869  X_2870  \\\n",
       "0   2.0  102.0  0.0  45.0  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "1   2.0  102.0  0.0  45.0  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "2   NaN    NaN  NaN   NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "3   NaN    NaN  NaN   NaN  ...   55.03   52.24   55.33   57.49   67.31   \n",
       "4   NaN    NaN  NaN   NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "..  ...    ...  ...   ...  ...     ...     ...     ...     ...     ...   \n",
       "83  NaN    NaN  NaN   NaN  ...   51.71   59.64   54.61   57.05   63.18   \n",
       "84  NaN    NaN  NaN   NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "85  NaN    NaN  NaN   NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "86  NaN    NaN  NaN   NaN  ...   49.47   53.07   50.89   55.10   66.49   \n",
       "87  NaN    NaN  NaN   NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "    X_2871  X_2872  X_2873  X_2874  X_2875  \n",
       "0      NaN     NaN     NaN     NaN     NaN  \n",
       "1      NaN     NaN     NaN     NaN     NaN  \n",
       "2      NaN     NaN     NaN     NaN     NaN  \n",
       "3      1.0     NaN     NaN     NaN     NaN  \n",
       "4      NaN     NaN     NaN     NaN     NaN  \n",
       "..     ...     ...     ...     ...     ...  \n",
       "83     1.0     NaN     NaN     NaN     NaN  \n",
       "84     NaN     NaN     NaN     NaN     NaN  \n",
       "85     NaN     NaN     NaN     NaN     NaN  \n",
       "86     1.0     NaN     NaN     NaN     NaN  \n",
       "87     1.0     NaN     NaN     NaN     NaN  \n",
       "\n",
       "[88 rows x 2881 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #train_df_0 index 재설정\n",
    "# train_df_0 = train_df_0.reset_index(inplace = False, drop = True)\n",
    "# train_df_0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pas",
   "language": "python",
   "name": "pas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
